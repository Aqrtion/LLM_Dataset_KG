{
    "entities": [
        {
            "id": "20250318214228P1",
            "name": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Alex Wang",
                    "Amanpreet Singh",
                    "Julian Michael",
                    "Felix Hill",
                    "Omer Levy",
                    "Samuel R. Bowman"
                ],
                "institutions": [
                    "New York University",
                    "University of Washington",
                    "DeepMind"
                ]
            }
        },
        {
            "id": "20250318214228D1",
            "name": "GLUE",
            "type": "Dataset",
            "attributes": {
                "number_of_tasks": 9,
                "domains": [
                    "diverse"
                ],
                "diagnostic_suite": "included"
            }
        },
        {
            "id": "20250318214228D2",
            "name": "CoLA",
            "type": "Dataset",
            "attributes": {
                "size": "8.5k train, 1k test",
                "task": "acceptability classification",
                "metrics": "Matthews correlation",
                "domain": "miscellaneous"
            }
        },
        {
            "id": "20250318214228D3",
            "name": "SST-2",
            "type": "Dataset",
            "attributes": {
                "size": "67k train, 1.8k test",
                "task": "sentiment analysis",
                "metrics": "accuracy",
                "domain": "movie reviews"
            }
        },
        {
            "id": "20250318214228D4",
            "name": "MRPC",
            "type": "Dataset",
            "attributes": {
                "size": "3.7k train, 1.7k test",
                "task": "paraphrase detection",
                "metrics": "accuracy/F1",
                "domain": "news"
            }
        },
        {
            "id": "20250318214228D5",
            "name": "STS-B (Semantic Textual Similarity Benchmark)",
            "type": "Dataset",
            "attributes": {
                "size": "7k train, 1.4k test",
                "task": "sentence similarity",
                "metrics": "Pearson/Spearman correlation",
                "domain": "miscellaneous"
            }
        },
        {
            "id": "20250318214228D6",
            "name": "QQP (Quora Question Pairs)",
            "type": "Dataset",
            "attributes": {
                "size": "364k train, 391k test",
                "task": "paraphrase detection",
                "metrics": "accuracy/F1",
                "domain": "social"
            }
        },
        {
            "id": "20250318214228D7",
            "name": "MNLI (Multi-Genre Natural Language Inference Corpus)",
            "type": "Dataset",
            "attributes": {
                "size": "393k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "multiple"
            }
        },
        {
            "id": "20250318214228D8",
            "name": "QNLI (Question-answering NLI)",
            "type": "Dataset",
            "attributes": {
                "size": "105k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "Wikipedia"
            }
        },
        {
            "id": "20250318214228D9",
            "name": "RTE (Recognizing Textual Entailment)",
            "type": "Dataset",
            "attributes": {
                "size": "2.5k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "news, Wikipedia"
            }
        },
        {
            "id": "20250318214228D10",
            "name": "WNLI (Winograd NLI)",
            "type": "Dataset",
            "attributes": {
                "size": "634 train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "fiction"
            }
        },
        {
            "id": "20250318214228D11",
            "name": "SNLI (Stanford Natural Language Inference)",
            "type": "Dataset",
            "attributes": {
                "size": "550k examples",
                "task": "textual entailment"
            }
        },
        {
            "id": "20250318214228D12",
            "name": "GLUE Diagnostic Dataset",
            "type": "Dataset",
            "attributes": {
                "purpose": "linguistic analysis",
                "phenomena": [
                    "lexical semantics",
                    "predicate-argument structure",
                    "logic",
                    "knowledge"
                ]
            }
        },
        {
            "id": "20250318214228R1",
            "name": "https://gluebenchmark.com",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318214228T1",
            "name": "natural language understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T2",
            "name": "sentiment analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T3",
            "name": "textual entailment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T4",
            "name": "paraphrase detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T5",
            "name": "sentence similarity",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T6",
            "name": "acceptability classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T7",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        }
    ]
}