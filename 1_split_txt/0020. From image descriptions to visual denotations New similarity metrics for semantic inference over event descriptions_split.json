{
    "title_author_abstract_introduction": "Transactions of the Association for Computational Linguistics, 2 (2014) 67–78. Action Editor: Lillian Lee. Submitted 6/2013; Revised 10/2013; Published 2/2014. c 2014 Association for Computational Linguistics. (cid:13)\nFromimagedescriptionstovisualdenotations:NewsimilaritymetricsforsemanticinferenceovereventdescriptionsPeterYoungAliceLaiMicahHodoshJuliaHockenmaierDepartmentofComputerScienceUniversityofIllinoisatUrbana-Champaign{pyoung2,aylai2,mhodosh2,juliahmr}@illinois.eduAbstractWeproposetousethevisualdenotationsoflinguisticexpressions(i.e.thesetofimagestheydescribe)todeﬁnenoveldenotationalsimilaritymetrics,whichweshowtobeatleastasbeneﬁcialasdistributionalsimilaritiesfortwotasksthatrequiresemanticinference.Tocomputethesedenotationalsimilarities,weconstructadenotationgraph,i.e.asubsump-tionhierarchyoverconstituentsandtheirde-notations,basedonalargecorpusof30Kim-agesand150Kdescriptivecaptions.1IntroductionTheabilitytodrawinferencesfromtextisaprereq-uisiteforlanguageunderstanding.Theseinferencesarewhatmakesitpossibleforevenbriefdescrip-tionsofeverydayscenestoevokerichmentalim-ages.Forexample,wewouldexpectanimageofpeopleshoppinginasupermarkettodepictaislesofproduceorothergoods,andwewouldexpectmostofthesepeopletobecustomerswhoareeitherstandingorwalkingaround.Butsuchinferencesrequireagreatdealofcommonsenseworldknowl-edge.Standarddistributionalapproachestolexicalsimilarity(Section2.1)areveryeffectiveatiden-tifyingwhichwordsarerelatedtothesametopic,andcanprovideusefulfeaturesforsystemsthatper-formsemanticinferences(Mirkinetal.,2009),butarenotsuitedtocapturepreciseentailmentsbetweencomplexexpressions.Inthispaper,weproposeanovelapproachfortheautomaticacquisitionofde-notationalsimilaritiesbetweendescriptionsofev-erydaysituations(Section2).Wedeﬁnethe(visual)denotationofalinguisticexpressionasthesetofim-agesitdescribes.Wecreateacorpusofimagesofeverydayactivities(eachpairedwithmultiplecap-tions;Section3)toconstructalargescalevisualde-notationgraphwhichassociatesimagedescriptionswiththeirdenotations(Section4).Thealgorithmthatconstructsthedenotationgraphusespurelysyn-tacticandlexicalrulestoproducesimplercaptions(whichhavealargerdenotation).Butsinceeachimageisoriginallyassociatedwithseveralcaptions,thegraphcanalsocapturesimilaritiesbetweensyn-tacticallyandlexicallyunrelateddescriptions.Weapplythesesimilaritiestotwodifferenttasks(Sec-tions6and7):anapproximateentailmentrecogni-tiontaskforourdomain,wherethegoalistodecidewhetherthehypothesis(abriefimagecaption)referstothesameimageasthepremises(fourlongercap-tions),andtherecentlyintroducedSemanticTextualSimilaritytask(Agirreetal.,2012),whichcanbeviewedasagraded(ratherthanbinary)versionofparaphrasedetection.Bothtasksrequiresemanticinference,andourresultsindicatethatdenotationalsimilaritiesareatleastaseffectiveasstandardap-proachestosimilarity.Ourcodeanddataset,aswellasthedenotationgraphitselfandthelexicalsimilaritieswedeﬁneoveritareavailableforre-searchpurposesathttp://nlp.cs.illinois.edu/Denotation.html.2TowardsDenotationalSimilarities2.1DistributionalSimilaritiesThedistributionalhypothesispositsthatlinguisticexpressionsthatappearinsimilarcontextshavea\f68\nGrayhairedmaninblacksuitandyellowtieworkinginaﬁnancialenvironment.Agrayingmaninasuitisperplexedatabusinessmeeting.Abusinessmaninayellowtiegivesafrustratedlook.Amaninayellowtieisrubbingthebackofhisneck.Amanwithayellowtielooksconcerned.Abutchercuttingananimaltosell.Agreen-shirtedmanwithabutcher’sapronusesaknifetocarveoutthehangingcarcassofacow.Amanatwork,butcheringacow.Amaninagreent-shirtandlongtanapronhacksapartthecarcassofacowwhileanothermanhosesawaytheblood.Twomenworkinabutchershop;onecutsthemeatfromabutcheredcow,whiletheotherhosestheﬂoor.Figure1:Twoimagesfromourdatasetandtheirﬁvecaptionssimilarmeaning(Harris,1954).Thishasledtothedeﬁnitionofvector-baseddistributionalsimilarities,whichrepresenteachwordwasavectorwderivedfromcountsofw’sco-occurrencewithotherwords.Thesevectorscanbeuseddirectlytocomputethelexicalsimilaritiesofwords,eitherviathecosineoftheanglebetweenthem,orviaother,morecom-plexmetrics(Lin,1998).Morerecently,asymmetricsimilaritieshavebeenproposedasmoresuitableforsemanticinferencetaskssuchasentailment(WeedsandWeir,2003;SzpektorandDagan,2008;Clarke,2009;Kotlermanetal.,2010).Distributionalwordvectorscanalsobeusedtodeﬁnethecompositionalsimilarityoflongerstrings(MitchellandLapata,2010).Tocomputethesimilarityoftwostrings,thelexicalvectorsofthewordsineachstringareﬁrstcombinedintoasinglevector(e.g.byelement-wiseadditionormultiplication),andthenanappropriatevectorsimilarity(e.g.cosine)isappliedtothere-sultingpairofvectors.2.2VisualDenotationsOurapproachisinspiredbytruth-conditionalse-mantictheoriesinwhichthedenotationofadeclar-ativesentenceisassumedtobethesetofallsitua-tionsorpossibleworldsinwhichthesentenceistrue(Montague,1974;Dowtyetal.,1981;BarwiseandPerry,1980).Restrictingourattentiontovisuallydescriptivesentences,i.e.non-negative,episodic(Carlson,2005)sentencesthatcanbeusedtode-scribeanimage(Figure1),weproposetoinstantiatetheabstractnotionsofpossibleworldsorsituationswithconcretesetsofimages.TheinterpretationfunctionJ·Kmapssentencestotheirvisualdenota-tionsJsK,whichisthesetofimagesi∈Us⊆Uina‘universe’ofimagesUthatsdescribes:JsK={i∈U|sisatruthfuldescriptionofi}(1)Similarly,wemapnounsandnounphrasestothesetofimagesthatdepicttheobjectstheydescribe,andverbsandverbphrasestothesetofimagesthatdepicttheeventstheydescribe.2.3DenotationGraphsDenotationsinduceapartialorderingoverdescrip-tions:ifs(e.g.“apoodlerunsonthebeach”)en-tailsadescriptions0(e.g.“adogruns”),itsdenota-tionisasubsetofthedenotationofs0(JsK⊆Js0K),andwesaythats0subsumesthemorespeciﬁcs(s0vs).Inourdomainofdescriptivesentences,wecanobtainmoregenericdescriptionsbysimplesyntacticandlexicaloperationsω∈O⊂S×Sthatpreserveupwardentailment,sothatifω(s)=s0,JsK⊆Js0K.Weconsiderthreetypesofoper-ations:theremovalofoptionalmaterial(e.gPPslikeonthebeach),theextractionofsimplercon-stituents(NPs,VPs,orsimpleSs),andlexicalsub-stitutionsofnounsbytheirhypernyms(poodle→dog).Theseoperationsareakintotheatomiced-itsofMacCartneyandManning(2008)’sNatLogsystem,andallowustoconstructlargesubsump-tionhierarchiesoverimagedescriptions,whichwecalldenotationgraphs.Givenasetof(upwardentailment-preserving)operationsO⊂S×S,thedenotationgraphDG=hE,ViofasetofimagesIandasetofstringsSrepresentsasubsumptionhier-archyinwhicheachnodeV=hs,JsKicorrespondstoastrings∈SanditsdenotationJsK⊆I.Di-rectededgese=(s,s0)∈E⊆V×Vindicateasubsumptionrelationsvs0betweenamoregenericexpressionsanditschilds0.Anedgefromstos0\f69\nexistsifthereisanoperationω∈Othatreducesthestrings0tos(i.e.ω(s0)=s)anditsinverseω−1expandsthestringstos0(i.e.ω−1(s)=s0).2.4DenotationalSimilaritiesGivenadenotationgraphoverNimages,weesti-matethedenotationalprobabilityofanexpressionswithadenotationofsize|JsK|asPJK(s)=|JsK|/N,andthejointprobabilityoftwoexpressionsanalo-gouslyasPJK(s,s0)=|JsK∩Js0K|/N.Thecondi-tionalprobabilityPJK(s|s0)indicateshowlikelysistobetruewhens0holds,andyieldsasimpledirecteddenotationalsimilarity.The(normalized)pointwisemutualinformation(PMI)(ChurchandHanks,1990)deﬁnesasymmetricsimilarity:nPMIJK(s,s0)=log(cid:16)PJK(s,s0)PJK(s)PJK(s0)(cid:17)−log(PJK(s,s0))WesetPJK(s|s)=nPMIJK(s,s)=1,and,ifsors0arenotinthedenotationgraph,nPMIJK(s,s0)=PJK(s,s0)=0.3OurDataSetOurdataset(Figure1)consistsof31,783pho-tographsofeverydayactivities,eventsandscenes(allharvestedfromFlickr)and158,915captions(obtainedviacrowdsourcing).Itcontainsandex-tendsHodoshetal.(2013)’scorpusof8,092im-ages.WefollowedHodoshetal.(2013)’sapproachtocollectimages.Wealsousetheirannotationguidelines,andusesimilarqualitycontrolstocor-rectspellingmistakes,eliminateungrammaticalornon-descriptivesentences.Almostalloftheim-agesthatweaddtothosecollectedbyHodoshetal.(2013)havebeenmadeavailableunderaCre-ativeCommonslicense.Eachimageisdescribedin-dependentlybyﬁveannotatorswhoarenotfamiliarwiththespeciﬁcentitiesandcircumstancesdepictedinthem,resultingincaptionssuchas“Threepeoplesettingupatent”,ratherthanthekindofcaptionspeopleprovidefortheirownimages(“OurtriptotheOlympicPeninsula”).Moreover,differentan-notatorsusedifferentlevelsofspeciﬁcity,fromde-scribingtheoverallsituation(performingamusicalpiece)tospeciﬁcactions(bowingonaviolin).Thisvarietyofdescriptionsassociatedwiththesameim-ageiswhatallowsustoinducedenotationalsimilari-tiesbetweenexpressionsthatarenottriviallyrelatedbysyntacticrewriterules.4ConstructingtheDenotationGraphTheconstructionofthedenotationgraphconsistsofthefollowingsteps:preprocessingandlinguisticanalysisofthecaptions,identiﬁcationofapplicabletransformations,andgenerationofthegraphitself.PreprocessingandLinguisticAnalysisWeusetheLinuxspellchecker,theOpenNLPtok-enizer,POStaggerandchunker(http://opennlp.apache.org),andtheMaltparser(Nivreetal.,2006)toanalyzethecaptions.Sincethevocabularyofourcorpusdifferssigniﬁcantlyfromthedatathesetoolsaretrainedon,weresorttoanumberofheuris-ticstoimprovetheanalysestheyprovide.Sincesomeheuristicsrequireustoidentifydifferententitytypes,wedevelopedalexiconofthemostcommonentitytypesinourdomain(people,clothing,bodilyappearance(e.g.hairorbodyparts),containersofliquids,fooditemsandvehicles).Afterspell-checking,wenormalizecertainwordsandcompoundswithseveralspellingvariations,e.g.barbecue(barbeque,BBQ),gray(grey),waterski(waterski),brown-haired(brownhaired),andto-kenizethecaptionsusingtheOpenNLPtokenizer.TheOpenNLPPOStaggermakesanumberofsys-tematicerrorsonourcorpus(e.g.mistaggingmainverbsasnouns).Sincetheseerrorsarehighlysys-tematic,weareabletocorrectthemautomaticallybyapplyingdeterministicrules(e.g.climbsisneveranouninourcorpus,standisanounifitispre-cededbyvegetablebutaverbwhenprecededbyanounthatreferstopeople).Theseﬁxesapplyto27,784(17%ofthe158,915imagecaptions).Next,weusetheOpenNLPchunkertocreateashallowparse.Fixingits(systematic)errorsaffects28,587captions.WethenanalyzethestructureofeachNPchunktoidentifyheads,determinersandpre-nominalmodiﬁers.TheheadmayincludemorethanasingletokenifWordNet(orourhypernymlexi-con,describedbelow)containsacorrespondingen-try(e.g.littlegirl).Determinersincludephrasessuchasacoupleorafew.AlthoughweusetheMaltparser(Nivreetal.,2006)toidentifysubject-verb-objectdependencies,wehavefounditmoreac-curatetodevelopdeterministicheuristicsandlexi-\f70\ncalrulestoidentifytheboundariesofcomplex(e.g.conjoined)NPs,allowingustotreat“amanwithredshoesandawhitehat”asanNPfollowedbyasin-glePP,but“amanwithredshoesandawhite-hairedwoman”astwoNPs,andtotransforme.g.“stand-ingbyamanandawoman”into“standing”andnot“standingandawoman”whendroppingthePP.HypernymLexiconWeuseourcorpusandWord-Nettoconstructahypernymlexiconthatallowsustoreplaceheadnounswithmoregenericterms.Weonlyconsiderhypernymsthatoccurthemselveswithsufﬁcientfrequencyintheoriginalcaptions(replac-ing“adult”with“person”,butnotwith“organ-ism”).Sincethelanguageinourcorpusisveryconcrete,eachnountendstohaveasinglesense,al-lowingustoalwaysreplaceitwiththesamehyper-nyms.1ButsinceWordNetprovidesuswithmul-tiplesensesformostnouns,weﬁrsthavetoiden-tifywhichsenseisusedinourcorpus.Todothis,weusetheheuristiccross-captioncoreferencealgo-rithmofHodoshetal.(2010)toidentifycoreferentNPchunksamongtheoriginalﬁvecaptionsofeachimage.2Foreachambiguousheadnoun,wecon-sidereverynon-singletoncoreferencechainsitap-pearsin,andreduceitssynsetstothosethatstandinahypernym-hyponymrelationwithatleastoneotherheadnouninthechain.Finally,weapplyagreedymajorityvotingalgorithmtoiterativelynar-rowdowneachterm’ssensestoasinglesynsetthatiscompatiblewiththelargestnumberofcoreferencechainsitoccursin.CaptionNormalizationInordertoincreasetherecallofthedenotationswecapture,wedropallpunctuationmarks,andlemmatizenouns,verbs,andadjectivesthatendin“-ed”or“-ing”beforegener-1Descriptionsofpeoplethatrefertobothageandgen-der(e.g.“man”)canhavemultipledistincthypernyms(“adult”/’“male”).Becauseourannotatorsneverdescribeyoungchildrenorbabiesas“persons”,weonlyallowtermsthatarelikelytodescribeadultsorteenagers(includingoccu-pations)tobereplacedbytheterm“person”.Thismeansthattheterm“girl”hastwosenses:afemalechild(thedefault)orayoungerwoman.Wedistinguishthetwosensesinapreprocess-ingstep:iftheothercaptionsofthesameimagedonotmentionchildren,butrefertoteenagedoradultwomen,weassigngirlthewoman-sense.Somenounsthatendin-er(e.g.“diner”,“pitcher”alsoviolateourmonosemyassumption.2CoreferenceresolutionhasalsobeenusedforwordsensedisambiguationbyPreiss(2001)andHuandLiu(2011).atingthedenotationgraph.Inordertodistinguishbetweenfrequentlyoccurringhomonymswherethenounisunrelatedtotheverb,wechangeallformsoftheverbdresstodressed,allformsoftheverbstandtostandingandallformsoftheverbparktopark-ing.Finally,wedropsentence-initialthere/here/thisis/are(asinthereisadogsplashinginthewater),andnormalizetheexpressionsinXanddressed(up)inX(whereXisanarticleofclothingoracolor)towearX.Wereducepluraldeterminersto{two,three,some},anddropsingulardeterminersexceptforno.4.1RuleTemplatesThedenotationgraphcontainsadirectededgefromstos0ifthereisaruleωthatreducess0tos,withaninverseω−1thatexpandsstos0.Reductionrulescandropoptionalmaterial,extractsimplerconstituents,orperformlexicalsubstitutions.DropPre-NominalModiﬁers:“redshirt”→“shirt”InanNPoftheform“XYZ”,whereXandYbothmodifytheheadZ,weonlyallowXandYtobedroppedseparatelyif“XZ”and“YZ”bothoccurelsewhereinthecorpus.Since“whitebuilding”and“stonebuilding”occurelse-whereinthecorpus,wegenerateboth“whitebuild-ing”and“stonebuilding”fromtheNP“whitestonebuilding”.Butsince“iceplayer”isnotused,wereplace“icehockeyplayer”onlywith“hockeyplayer”(whichdoesoccur)andthen“player”.DropOtherModiﬁers“runquickly”→“run”WedropADVPchunksandadverbsinVPchunks.Wealsoallowaprepositionalphrase(apreposi-tionfollowedbyapossiblyconjoinedNPchunk)tobedroppediftheprepositionislocational(“in”,“on”,“above”,etc.),directional(“towards”,“through”,“across”,etc.),orinstrumental(“by”,“for”,“with”).Similarly,wealsoallowthedrop-pingofall“wearNP”constructions.Sincethedis-tinctionbetweenparticlesandprepositionsisoftendifﬁcult,wealsouseapredeﬁnedlistofphrasalverbsthatcommonlyoccurinourcorpustoidentifyconstructionssuchas“climbupamountain”,whichistransformedinto“climbamountain”or“walkdownastreet”,whichistransformedinto“walk”.ReplaceNounsbyHypernyms:“redshirt”→“redclothing”Weiterativelyuseourhypernym\f71\nGENERATEGRAPH():Q,Captions,Rules←∅forallc∈ImageCorpusdoRules(c)←GenerateRules(sc)pushAll(Q,{c}×RootNodes(sc,Rules(c)))while¬empty(Q)do(c,s)←pop(Q)Captions(s)←Captions(s)∪{c}if|Captions(s)|=2thenforallc0∈Captions(s)dopushAll(Q,{c0}×Children(s,Rules(c0)))elseif|Captions(s)|>2thenpushAll(Q,{c}×Children(s,Rules(c)))Figure2:Generatingthegraphlexicontomakeheadnounsmoregeneric.Weonlyallowheadnounstobereplacedbytheirhypernymsifanyagebasedmodiﬁershavealreadybeenre-moved:“toddler”canbereplacedwith“child”,butnot“oldertoddler”with“olderchild”.HandlePartitiveNPs:cupoftea→“cup”,“tea”InmostpartitiveNP1-of-NP2constructions(“cupoftea”,“ateamoffootballplayers”)thecorrespond-ingentitycanbereferredtobyboththeﬁrstorthesecondNP.Exceptionsincludethephrase“bodyofwater”,andexpressionssuchas“akind/type/sortof”,whichwetreatsimilartodeterminers.HandleVP1-to-VP2CasesDependingontheﬁrstverb,wereplaceVPsoftheformXtoYwithbothXandYifXisamovementorposture(jumptocatch,etc.).OtherwisewedistinguishbetweencaseswecanonlyreplacewithX(waittojump)andthosewecanonlyreplacewithY(seemtojump).ExtractSimplerConstituentsAnynounphraseorverbphrasecanalsobeusedasanodeinthegraphandsimpliﬁedfurther.WeusetheMaltde-pendencies(andthepersontermsintheentitytypelexicon)toidentifyandextractsubject-verb-objectchunkswhichcorrespondtosimplersentencesthatwewouldotherwisenotbeabletoobtain:from“manlaugh(s)whiledrink(ing)”,weextract“manlaugh”and“mandrink”,andthenfurthersplitthoseinto“man”,“laugh(s)”,and“drink”.4.2GraphGenerationThenaiveapproachtographgenerationwouldbetogenerateallpossiblestringsforeachcaption.How-ever,thiswouldproducefarmorestringsthancanbeprocessedinareasonableamountoftime,andmostofthesestringswouldhaveuninformativedenota-tions,consistingofonlyasingleimage.Tomakegraphgenerationtractable,weuseatop-downal-gorithmwhichgeneratesthegraphfromthemostgeneric(root)nodes,andstopsatnodesthathaveasingletondenotation(Figure2).Weﬁrstidentifythesetofrulesthatcanapplytoeachoriginalcaption(GenerateRules).Theserulesarethenusedtore-duceeachcaptionasmuchaspossible.Theresulting(maximallygeneric)stringsareaddedasrootnodestothegraph(RootNodes),andaddedtothequeueQ.Qkeepstrackofallcurrentlypossiblenodeex-pansions.Itcontainsitemshc,si,whichpairtheIDofanoriginalcaptionanditsimage(c)withastring(s)thatcorrespondstoanexistingnodeinthegraphandcanbederivedfromc’scaption.Whenhc,siisprocessed,wecheckhowmanycaptionshavegen-eratedssofar(Captions(s)).Ifshasmorethanasinglecaption,weuseeachoftheapplicablerewriterulesofc’scaptiontocreatenewstringss0thatcor-respondtothechildrenofsinthegraph,andpushallresultinghc,s0iontoQ.Ifcisthesecondcaptionofs,wealsousealloftheapplicablerewriterulesfromtheﬁrstcaptionc0tocreateitschildren.Apost-processingstep(notshowninFigure2)attacheseachoriginalcaptiontoallleafnodesofthegraphtowhichitcanbereduced.Finally,weobtainthedenotationofeachnodesfromthesetofimageswhosecaptionsareinCaptions(s).5TheDenotationGraphSizeandCoverageOnourcorpusof158,439uniquecaptionsand31,783images,thedenotationgraphcontains1,749,097captions,outofwhich230,811describemorethanasingleimage.Ta-ble1providesthedistributionofthesizeofdeno-tations.Itisperhapssurprisingthatthe161cap-tionswhichdescribeeachover1,000imagesdonotjustconsistofnounssuchasperson,butalsocontainsimplesentencessuchaswomanstanding,adultwork,personwalkstreet,orpersonplayin-strument.Sincethegraphisderivedfromtheorigi-nalcaptionsbyverysimplesyntacticoperations,thedenotationsitcapturesaremostlikelyincomplete:JsoccerplayerKcontains251images,JplaysoccerKcontains234images,andJsoccergameKcontains\f72\nSizeofdenotations|JsK|≥1|JsK|≥2|JsK|≥5|JsK|≥10|JsK|≥100|JsK|≥1000Nr.ofcaptions1,749,096230,81153,34122,6831,921161Table1:Distributionofthesizeofdenotationsinourgraph119images.Wehavenotyetattemptedtoiden-tifyvariantsinwordorder(“sticktongueout”vs.“stickouttongue”)orequivalentchoicesofprepo-sition(“lookintomirror”vs.“lookinmirror”).De-spitethisbrittleness,thecurrentgraphalreadygivesusalargenumberofsemanticassociations.DenotationalSimilaritiesThefollowingexam-plesofthesimilaritiesfoundbynPMIJKandPJKshowthatdenotationalsimilaritiesdonotsimplyﬁndtopicallyrelatedevents,butinsteadﬁndeventsthatarerelatedbyentailment:PJK(x|y)xy0.962siteatlunch0.846playguitarstrum0.811surfcatchwave0.800ridehorseropecalf0.700listensitinclassroomIfsomeoneiseatinglunch,itislikelythattheyaresitting,andpeoplewhositinaclassroomarelikelytobelisteningtosomebody.Theseentail-mentscanbeveryprecise:“walkupstair”entails“ascend”,butnot“descend”;thereverseistruefor“walkdownstair”:PJK(x|y)x=ascendx=descendy=walkupstair32.00.0y=walkdownstair0.030.8nPMIJKcapturesparaphrasesaswellascloselyrelatedevents:peoplelookinamirrorwhenshav-ingtheirface,andbaseballplayersmaytrytotagsomeonewhoisslidingintobase:nPMIJKxy0.835openpresentunwrap0.826lassotrytorope0.791getreadytokickruntowardsball0.785trytotagslideintobase0.777shavefacelookinmirrorComparingtheexpressionsthataremostsimilarto“playbaseball”or“playfootball”accordingtothedenotationalnPMIJKandthecompositionalΣsimilaritiesrevealsthatthedenotationalsimilarityﬁndsanumberofactionsthatarepartofthepartic-ularsport,whilethecompositionalsimilarityﬁndseventsthataresimilartoplayingbaseball(football):playbaseballnPMIJKΣ0.674taghim0.859playsoftball0.637holdbat0.782playgame0.616trytotag0.768playball0.569slideintobase0.741playcatch0.516pitchball0.739playcricketplayfootballnPMIJKΣ0.623tackleperson0.826playgame0.597holdfootball0.817playrugby0.545rundownﬁeld0.811playsoccer0.519wearwhitejersey0.796playonﬁeld0.487avoid0.773playball6Task1:ApproximateEntailmentAcaptionneverprovidesacompletedescriptionofthedepictedscene,butcommonsenseknowledgeoftenallowsustodrawimplicitinferences:whensomebodymentionsabride,itisquitelikelythatthepictureshowsawomaninaweddingdress;apic-tureofaparentmostlikelyalsohasachildorbaby,etc.Inordertocomparetheutilityofdenotationalanddistributionalsimilaritiesfordrawingthesein-ferences,weapplythemtoanapproximateentail-menttask,whichislooselymodeledaftertheRec-ognizingTextualEntailmentproblem(Daganetal.,2006),andconsistsofdecidingwhetherabriefcap-tionh(thehypothesis)candescribethesameimageasasetofcaptionsP={p1,...,pN}knowntode-scribethesameimage(thepremises).DataWegeneratepositiveandnegativeitemshP,h,±i(Figure3)asfollows:Givenanimage,anysubsetoffourofitscaptionsformasetofpremises.Ahypothesisiseitherashortverbphraseorsentencethatcorrespondstoanodeinthedeno-tationgraph.Byfocusingonshorthypotheses,weminimizethepossibilitythattheycontainextrane-ousdetailsthatcannotbeinferredfromthepremises.Positiveexamplesaregeneratedbychoosinganodehashypothesisandanimagei∈JhKsuchthatex-actlyonecaptionofigenerateshandtheotherfourcaptionsofiarenotdescendantsofhandhencedonottriviallyentailh,givinganunfairadvantagetodenotationalapproaches.Negativeexamplesaregeneratedbychoosinganodehashypothesisandselectingfourofthecaptionsofanimagei6∈JhK.\f73\nPremises:Awomanwithdarkhairinbending,openmouthed,towardsthebackofadarkheadedtoddler’shead.Adark-hairedwomanhashermouthopenandishuggingalittlegirlwhilesittingonaredblanket.Agrownladyissnugglingonthecouchwithayounggirlandtheladyhasafrightenedlook.Amomholdingherchildonaredsofawhiletheyarebothhavingfun.VPHypothesis:makefacePremises:Amaneditingablackandwhitephotoatacomputerwithapencilinhisear.Amaninawhiteshirtisworkingatacomputer.Aguyinwhitet-shirtonamaccomputer.AyoungmainisusinganApplecomputer.SHypothesis:mansitFigure3:PositiveexamplesfromtheApproximateEntailmenttasks.Sinceouritemsarecreatedautomatically,aposi-tivehypothesisisnotnecessarilylogicallyentailedbyitspremises.Wehaveperformedasmall-scalehumanevaluationon300items(200positive,100negative),eachjudgedindependentlybythesamethreejudges(inter-annotatoragreement:Fleiss-κ=0.74).Ourresultsindicatethatoverhalf(55%)ofthepositivehypothesescanbeinferredfromtheirpremisesalonewithoutlookingattheoriginalim-age,whilealmostnoneofthenegativehypotheses(100%forsentences,96%forverbphrases)canbeinferredfromtheirpremises.Thetrainingitemsaregeneratedfromthecaptionsof25,000images,andthetestitemsaregeneratedfromadisjointsetof3,000images.TheVPdatasetconsistsof290,000trainingitemsand16,000testitems,whiletheSdatasetconsistsof400,000trainingitemsand22,000testitems.Halfoftheitemsineachsetarepositive,andtheotherhalfarenegative.ModelsAllofourmodelsarebinaryMaxEntclas-siﬁers,trainedusingMALLET(McCallum,2002).Wehavetwobaselinemodels:aplainbag-of-wordsmodel(BOW)andabag-of-wordsmodelwhereweaddallhypernymsinourlexicontothecaptionsbe-forecomputingtheiroverlap(BOW-H).Thisisin-tendedtominimizetheadvantagethedenotationalfeaturesobtainfromthehypernymlexiconusedtoconstructthedenotationgraph.Inbothcases,aglobalBOWfeaturecapturesthefractionoftokensinthehypothesisthatarecontainedinthepremises.Word-speciﬁcBOWfeaturescapturetheproductofthefrequenciesofeachwordinhandP.AllothermodelsextendtheBOW-Hmodel.DenotationalSimilarityFeaturesWecomputedenotationalsimilaritiesnPMIJKandPJK(Sec-tion2.4)overthepairsofnodesinadenotationgraphthatisrestrictedtothetrainingimages.Weonlyconsiderpairsofnodesn,n0iftheirdenota-tionscontainatleast10imagesandtheirintersectioncontainsatleast2images.TomapanitemhP,hitodenotationalsimi-larityfeatures,werepresentthepremisesasthesetofallnodesPthatareancestorsofitscap-tions.AsententialhypothesisisrepresentedasthesetofnodesH={hS,hsbj,hVP,hv,hdobj}thatcorrespondtothesentence(hitself),itssub-ject,itsVPanditsdirectobject.AVPhypothe-sishasonlythenodesH={hVP,hv,hdobj}.Inbothcases,hdobjmaybeempty.Bothofthede-notationalsimilaritiesnPMIJK(h,p)andPJK(h|p)forh∈H,p∈Pleadtotwoconstituent-speciﬁcfeatures,sumxandmaxx,(e.g.sumsbj=Ppsim(hsbj,p),maxdobj=maxpsim(hdobj,p))andtwoglobalfeaturessump,h=Pp,hsim(h,p)andmaxp,h=maxp,hsim(h,p).Eachconstituenttypealsohasasetofnode-speciﬁcsumx,sandmaxx,sfeaturesthatareonwhenconstituentxinhisequaltothestringsandwhosevalueisequaltotheconstituent-basedfeature.ForPJK,eachcon-stituent(andeachconstituent-nodepair)hasanad-ditionalfeatureP(h|P)=1−Qn(1−PJK(h|pn))thatestimatestheprobabilitythathisgeneratedbysomenodeinthepremise.LexicalSimilarityFeaturesWeusetwosym-metriclexicalsimilarities:standardcosinedistance(cos),andLin(1998)’ssimilarity(Lin):cos(w,w0)=w·w0kwkkw0kLin(w,w0)=Pi:w(i)>0∧w0(i)>0w(i)+w0(i)Piw(i)+Piw0(i)\f74\nWeusetwodirectedlexicalsimilarities:Clarke(2009)’ssimilarity(Clk),andSzpektorandDagan(2008)’sbalancedprecision(Bal),whichbuildsonLinandonWeedsandWeir(2003)’ssimilarity(W):Clk(w|w0)=Pi:w(i)>0∧w0(i)>0min(w(i),w0(i))Piw(i)Bal(w|w0)=pW(w|w0)×Lin(w,w0)W(w|w0)=Pi:w(i)>0∧w0(i)>0w(i)Piw(i)Wealsousetwopubliclyavailableresourcesthatprovideprecomputedsimilarities,Kotlermanetal.(2010)’sDIRECTnounandverbrulesandChklovskiandPantel(2004)’sVERBOCEANrules.Botharemotivatedbytheneedfornumericallyquantiﬁablesemanticinferencesbetweenpredicates.Weonlyuseentriesthatcorrespondtosingletokens(ignor-inge.g.phrasalverbs).Eachlexicalsimilarityresultsinthefollow-ingfeatures:wordsintheoutputarerepresentedbyamax-simwfeaturewhichcapturesitsmax-imumsimilaritywithanywordinthepremises(max-simw=maxw0∈Psim(w,w0))andbyasum-simwfeaturewhichcapturesthesumofitssim-ilaritiestothewordsinthepremises(sum-simw=Pw0∈Psim(w,w0)).Globalmaxsimandsumsimfeaturescapturethemaximal(resp.total)similarityofanywordinthehypothesistothepremise.Wecomputedistributionalandcompositionalsimilarities(cos,Lin,Bal,Clk,Σ,Π)onourim-agecaptions(“cap”),theBNCandGigaword.ForeachcorpusC,wemapeachwordwthatappearsatleast10timesinCtoavectorwCofthenon-negativenormalizedpointwisemutualinformationscores(Section2.4)ofwandthe1,000words(ex-cludingstopwords)thatoccurinthemostsentencesofC.WegenerallydeﬁneP(w)(andP(w,w0))asthefractionofsentencesinCinwhichw(andw0)occur.Toallowadirectcomparisonbetweendis-tributionalanddenotationalsimilarities,weﬁrstde-ﬁneP(w)(andP(w,w0))overindividualcaptions(“cap”),andthen,toleveltheplayingﬁeld,werede-ﬁneP(w)(andP(w,w0))asthefractionofimagesinwhosecaptionsw(andw0)occur(“img”),andthenweuseourlexicontoaugmentcaptionswithallhypernyms(“+hyp”).Finally,weincludeBNCandGigawordsimilarityfeatures(“all”).VPtaskStaskBaseline1:BoW58.771.2Baseline2:BoW-H59.073.6External1:DIRECT59.273.5External2:VerbOcean60.874.0CapAllCapAllDistributionalcos67.571.976.178.9DistributionalLin62.670.275.477.8DistributionalBal62.369.674.775.3DistributionalClk62.469.275.477.5CompositionalΠ68.470.375.377.3CompositionalΣ67.871.476.979.2CompositionalΠ,Σ69.872.777.079.6DenotationalnPMIJK74.980.2DenotationalPJK73.879.5nPMIJK,PJK75.581.2Combinedcos,Π,Σ71.172.677.479.2nPMIJK,PJK,Π,Σ75.675.980.280.7nPMIJK,PJK,cos75.675.780.281.2nPMIJK,PJK,cos,Π,Σ75.875.981.280.5Table2:TestaccuracyonApproximateEntailment.CompositionalSimilarityFeaturesWeusetwostandardcompositionalbaselinestocombinethewordvectorsofasentenceintoasinglevector:ad-dition(sP=w1+...+wn,whichcanbeinter-pretedasadisjunctiveoperation),andelement-wise(Hadamard)multiplication(sQ=w1(cid:12)...(cid:12)wn,whichcanbeseenasaconjunctiveoperation).Inbothcases,werepresentthepremises(whichcon-sistoffourcaptions)asathesumofeachcaption’svectorp=p1+...p4.Thisgivestwocomposi-tionalsimilarityfeatures:Σ=cos(pΣ,hΣ),andΠ=cos(pΠ,hΠ).6.1ExperimentalResultsTable2providesthetestaccuracyofourmod-elsontheVPandStasks.Addinghypernyms(BOW-H)yieldsaslightimprovementovertheba-sicBOWmodel.Amongtheexternalresources,VERBOCEANismorebeneﬁcialthanDIRECT,butneitherhelpasmuchasin-domaindistributionalsimilarities(thismaybeduetosparsity).Table2showsonlythesimplest(“Cap”)andthemostcomplex(“all”)distributionalandcom-positionalmodels,butTable3providesaccuraciesofthesemodelsaswegofromstandardsentence-basedco-occurrencecountstowardsmoredenota-tiongraph-likeco-occurrencecountsthatarebasedonallcaptionsdescribingthesameimage(“Img”),\f75",
    "data_related_paragraphs": [
        "VPtaskStaskCapImg+HypAllCapImg+HypAllcos67.569.369.871.976.176.877.578.9Lin62.663.461.370.075.474.875.277.8Bal62.361.962.869.674.775.575.175.3Clk62.467.368.069.275.475.576.077.5Π68.470.570.570.375.376.677.177.3Σ67.871.471.671.476.978.179.179.2Π,Σ69.872.772.972.777.078.679.379.6nPMIJK74.980.2PJK73.879.5nPMIJK,PJK75.581.2Table3:Accuracyonhypothesesasvariousadditionsaremadetothevectorcorpora.Capistheimagecorpuswithcaptionco-occurrence.Imgistheimagecorpuswithim-ageco-occurrence.+Hypaugmentstheimagecorpuswithhypernymsandusesimageco-occurrence.AlladdstheBNCandGigawordcorporato+Hyp.VPtaskStaskWordsinh123+234+%ofitems72.813.913.365.322.811.9BoW-H52.075.080.169.180.884.4cos(All)68.879.481.175.983.985.7P(All)68.180.879.576.583.985.1nPMIJK72.082.982.277.385.486.2Table4:Accuracyonhypothesesofvaryinglength.includehypernyms(“+Hyp”),andaddinforma-tionfromothercorpora(“All”).The“+Hyp”col-umninTable3showsthatthedenotationalmetricsclearlyoutperformanydistributionalmetricwhenbothhaveaccesstothesameinformation.Al-thoughthedistributionalmodelsbeneﬁtfromtheBNCandGigaword-basedsimilarities(“All”),theirperformanceisstillbelowthatofthedenotationalmodels.Amongthedistributionalmodel,thesimplecosperformsbetterthanLin,orthedirectedClkandBalsimilarities.Inallcases,givingmodelsaccesstodifferentsimilarityfeaturesimprovesperformance.Table4showstheresultsbyhypothesislength.Asthelengthofhincreases,classiﬁersthatusesim-ilaritiesbetweenpairsofwords(BOW-Handcos)continuetoimproveinperformancerelativetotheclassiﬁersthatusesimilaritiesbetweenphrasesandsentences(ΣandnPMIJK).Mostlikely,thisisduetothelexicalsimilaritieshavingalargersetoffea-turestoworkwithforlongerh.nPMIJKdoesespe-ciallywellonshorterh,likelyduetotheshorterhhavinglargerdenotations.7Task2:SemanticTextualSimilarityToassesshowthedenotationalsimilaritiesperformonamoreestablishedtaskanddomain,weapplythemtothe1500sentencepairsfromtheMSRVideoDescriptionCorpus(ChenandDolan,2011)thatwereannotatedfortheSemEval2012SemanticTex-tualSimilarity(STS)task(Agirreetal.,2012).Thegoalofthistaskistoassignscoresbetween0and5toapairofsentences,where5indicatesequivalence,and0unrelatedness.Sincethisisasymmetrictask,wedonotconsiderdirectedsimilarities.Andbe-causethegoalofthisexperimentisnottoachievethebestpossibleperformanceonthistask,buttocomparetheeffectivenessofdenotationalandmoreestablishedsimilarities,weonlycomparetheimpactofdenotationalsimilaritieswithcompositionalsim-ilaritiescomputedonourowncorpus.SincetheMSRVideocorpusassociateseachvideowithmul-tiplesentences,itisinprinciplealsoamenabletoadenotationaltreatment,buttheSTStaskdescriptionexplicitlyforbidsitsuse.7.1ModelsBaselineandCompositionalFeaturesOurstart-ingpointisB¨aretal.(2013)’sDKProSimilarity,oneofthetop-performingmodelsfromthe2012STSsharedtask,whichisavailableandeasilymod-iﬁed.Itconsistsofalog-linearregressionmodeltrainedonmultipletextfeatures(wordandcharac-tern-grams,longestcommonsubstringandlongestcommonsubsequence,GabrilovichandMarkovitch(2007)’sExplicitSemanticAnalysis,andResnik(1995)’sWordNet-basedsimilarity).Weinvestigatetheeffectsofaddingcompositional(computedonthevectorsobtainedfromtheimage-captiontrain-ingdata)anddenotationalsimilarityfeaturestothisstate-of-the-artsystem.DenotationalFeaturesSincetheSTStaskissymmetric,weonlyconsidernPMIJKsimilari-ties.Weagainrepresenteachsentencesbyfea-turesbasedon5typesofconstituents:S={sS,ssbj,sVP,sv,sdobj}.Sincesentencesmightbecomplex,theymightcontainmultipleconstituentsofthesametype,andwethereforethinkofeachfeatureasafeatureoversetsofnodes.ForeachconstituentCweconsidertwosetsofnodesinthedenotationgraph:Citself(typicallyleafnodes),\f76",
        "DKPro+Σ,Π(img)+nPMIJK+bothPearsonr0.8680.8800.8880.890Table5:PerformanceontheSTSMSRvidtask:DKPro(B¨aretal.,2013)pluscompositional(Σ,Π)and/ordeno-tationalsimilarities(nPMIJK)fromourcorpusandCanc,theirparentsandgrandparents.Foreachpairofsentences,C-Csimilaritiescomputethesimilarityoftheconstituentsofthesametype,whileC-allsimilaritiescomputethesimilarityofaCconstituentinonesentenceagainstallcon-stituentsintheothersentence.Foreachpairofconstituentsweconsiderthreesimilarityfeatures:sim(C1,C2),max(sim(C1Canc2),sim(Canc1,C2)),sim(Canc1,Canc2).Thesimilarityoftwosetsofnodesisdeterminedbythemaximalsimilarityofanypairoftheirelements:sim(C1,C2)=maxc1∈C1,c2∈C2nPMIJK(c1,c2).Thisgivesus15C-Cfeaturesand15C-allfeatures.7.2ExperimentsWeusetheSTS2012train/testdata,normalizedinthesamewayastheimagecaptionsforthedeno-tationgraph(i.e.were-tokenize,lemmatize,andremovedeterminers).Table5showsexperimentalresultsforfourmodels:DKProistheoff-the-shelfDKProSimilaritymodel(B¨aretal.,2013).Fromourcorpus,weeitheraddadditiveandmultiplicativecompositionalfeatures(Σ,Π)fromSection6(img),theC-CandC-AlldenotationalfeaturesbasedonnPMIJK,orbothcompositionalanddenotationalfeatures.SystemsareevaluatedbythePearsoncor-relation(r)oftheirpredictedsimilarityscorestothehuman-annotatedones.Weseethatthedenotationalsimilaritiesoutperformthecompositionalsimilari-ties,andthatincludingcompositionalsimilarityfea-turesinadditiontodenotationalsimilarityfeatureshaslittleeffect.Foradditionalcomparison,thepublishednumbersfortheTakeLabSemanticTextSimilaritySystem(ˇSari´cetal.,2012),anothertop-performingmodelfromthe2012sharedtask,arer=0.880onthisdataset.8ConclusionSummaryofContributionsWehavedeﬁnednoveldenotationalmetricsoflinguisticsimilarity(Section2),andhaveshownthemtobeatleastcompetitivewith,ifnotsuperiorto,distributionalsimilaritiesfortwotasksthatrequiresimplese-manticinferences(Sections6,7),eventhoughourcurrentmethodofcomputingthemissomewhatbrittle(Section5).Wehavealsointroducedtwonewresources:alargedatasetofimagespairedwithdescriptivecaptions,andadenotationgraphthatpairsgeneralizedversionsofthesecaptionswiththeirvisualdenotations,i.e.thesetsofim-agestheydescribe.Bothoftheseresourcesarefreelyavailable(http://nlp.cs.illinois.edu/Denotation.html)Althoughtheaimofthispaperistoshowtheirutilityforapurelylinguistictask,webelievethattheyshouldalsobeofgreatinterestforpeoplewhoaimtobuildsystemsthatautomat-icallyassociateimagewithsentencesthatdescribethem(Farhadietal.,2010;Kulkarnietal.,2011;Lietal.,2011;Yangetal.,2011;Mitchelletal.,2012;Kuznetsovaetal.,2012;Guptaetal.,2012;Hodoshetal.,2013).RelatedWorkandResourcesWebelievethattheworkreportedinthispaperhasthepotentialtoopenuppromisingnewresearchdirections.Thereareotherdatasetsthatpairimagesorvideowithde-scriptivelanguage,butwehavenotyetappliedourapproachtothem.ChenandDolan(2011)’sMSRVideoDescriptionCorpus(ofwhichtheSTSdataisasubset)ismostsimilartoours,butitscuratedpartissigniﬁcantlysmaller.Insteadofseveralin-dependentcaptions,Grubingeretal.(2006)’sIAPRTC-12datasetcontainslongerdescriptions.Or-donezetal.(2011)harvested1millionimagesandtheiruser-generatedcaptionsfromFlickrtocreatetheSBUCaptionedPhotoDataset.Thesecaptionstendtobelessdescriptiveoftheimage.Thede-notationgraphissimilartoBerantetal.(2012)’s‘entailmentgraph’,butdiffersfromitintwoways:ﬁrst,entailmentrelationsinthedenotationgrapharedeﬁnedextensionallyintermsoftheimagesde-scribedbytheexpressionsateachnode,andsec-ond,nodesinBerantetal.’sentailmentgraphcorre-spondtogenericpropositionaltemplates(XtreatsY),whereasnodesinourdenotationgraphcorre-spondtocompletepropositions(adogruns).\f77",
        "AcknowledgementsWegratefullyacknowledgethesupportoftheNationalScienceFoundationunderNSFawards0803603“INT2-Medium:Understandingthemean-ingofimages”,1053856“CAREER:BayesianMod-elsforLexicalizedGrammars”,and1205627“CI-P:CollaborativeResearch:VisualentailmentdatasetandchallengefortheLanguageandVisionCom-munity”,aswellasviaanNSFGraduateResearchFellowshiptoAliceLai.ReferencesEnekoAgirre,MonaDiab,DanielCer,andAitorGonzalez-Agirre.2012.SemEval-2012task6:apilotonsemantictextualsimilarity.InProceedingsoftheFirstJointConferenceonLexicalandComputationalSemantics-Volume1:Proceedingsofthemainconfer-enceandthesharedtask,andVolume2:ProceedingsoftheSixthInternationalWorkshoponSemanticEval-uation,SemEval’12,pages385–393.DanielB¨ar,TorstenZesch,andIrynaGurevych.2013.DKProSimilarity:AnOpenSourceFrameworkforTextSimilarity.InProceedingsofthe51stAnnualMeetingoftheAssociationforComputationalLinguis-tics:SystemDemonstrations,pages121–126,Soﬁa,Bulgaria,August.JonBarwiseandJohnPerry.1980.Situationsandatti-tudes.JournalofPhilosophy,78:668–691.JonathanBerant,IdoDagan,andJacobGoldberger.2012.Learningentailmentrelationsbyglobalgraphstructureoptimization.ComputationalLinguistics,38(1):73–111.GregCarlson,2005.TheEncyclopediaofLanguageandLinguistics,chapterGenerics,HabitualsandIteratives.Elsevier,2ndedition.DavidChenandWilliamDolan.2011.Collectinghighlyparalleldataforparaphraseevaluation.InPro-ceedingsofthe49thAnnualMeetingoftheAssocia-tionforComputationalLinguistics:HumanLanguageTechnologies,pages190–200,Portland,Oregon,USA,June.TimothyChklovskiandPatrickPantel.2004.Verbo-cean:Miningthewebforﬁne-grainedsemanticverbrelations.InProceedingsofthe2004ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages33–40,Barcelona,Spain,July.KennethWardChurchandPatrickHanks.1990.Wordassociationnorms,mutualinformation,andlexicogra-phy.ComputationalLinguistics,16(1):22–29.DaoudClarke.2009.Context-theoreticsemanticsfornaturallanguage:anoverview.InProceedingsoftheWorkshoponGeometricalModelsofNaturalLan-guageSemantics,pages112–119,Athens,Greece,March.IdoDagan,OrenGlickman,andBernardoMagnini.2006.ThePASCALRecognisingTextualEntailmentchallenge.InMachineLearningChallenges,volume3944ofLectureNotesinComputerScience,pages177–190.Springer.DavidDowty,RobertWall,andStanleyPeters.1981.In-troductiontoMontagueSemantics.Reidel,Dordrecht.AliFarhadi,MohsenHejrati,MohammadAminSadeghi,PeterYoung,CyrusRashtchian,JuliaHockenmaier,andDavidForsyth.2010.Everypicturetellsastory:Generatingsentencesfromimages.InProceed-ingsoftheEuropeanConferenceonComputerVision(ECCV),PartIV,pages15–29,Heraklion,Greece,September.EvgeniyGabrilovichandShaulMarkovitch.2007.Com-putingsemanticrelatednessusingwikipedia-basedex-plicitsemanticanalysis.InProceedingsofthe20thinternationaljointconferenceonArtiﬁcalintelligence,IJCAI’07,pages1606–1611.MichaelGrubinger,PaulClough,HenningM¨uller,andThomasDeselaers.2006.TheIAPRbenchmark:Anewevaluationresourceforvisualinformationsys-tems.InOntoImage2006,WorkshoponLanguageResourcesforContent-basedImageRetrievalduringLREC2006,pages13–23,Genoa,Italy,May.AnkushGupta,YashaswiVerma,andC.Jawahar.2012.Choosinglinguisticsovervisiontodescribeimages.InProceedingsoftheTwenty-SixthAAAIConferenceonArtiﬁcialIntelligence,Toronto,Ontario,Canada,July.ZelligSHarris.1954.Distributionalstructure.Word,10:146–162.MicahHodosh,PeterYoung,CyrusRashtchian,andJuliaHockenmaier.2010.Cross-captioncoreferencereso-lutionforautomaticimageunderstanding.InProceed-ingsoftheFourteenthConferenceonComputationalNaturalLanguageLearning,pages162–171,Uppsala,Sweden,July.MicahHodosh,PeterYoung,andJuliaHockenmaier.2013.Framingimagedescriptionasarankingtask:Data,modelsandevaluationmetrics.JournalofArti-ﬁcialIntelligenceResearch(JAIR),47:853–899.ShangfengHuandChengfeiLiu.2011.Incorporatingcoreferenceresolutionintowordsensedisambigua-tion.InAlexanderF.Gelbukh,editor,ComputationalLinguisticsandIntelligentTextProcessing,volume6608ofLectureNotesinComputerScience,pages265–276.SpringerBerlinHeidelberg.\f78",
        "LiliKotlerman,IdoDagan,IdanSzpektor,andMaayanZhitomirsky-Geffet.2010.Directionaldistributionalsimilarityforlexicalinference.NaturalLanguageEn-gineering,16(4):359–389.GirishKulkarni,VisruthPremraj,SagnikDhar,SimingLi,YejinChoi,AlexanderC.Berg,andTamaraL.Berg.2011.Babytalk:Understandingandgenerat-ingsimpleimagedescriptions.InProceedingsofthe2011IEEEConferenceonComputerVisionandPat-ternRecognition(CVPR),pages1601–1608.PolinaKuznetsova,VicenteOrdonez,AlexanderBerg,TamaraBerg,andYejinChoi.2012.Collectivegener-ationofnaturalimagedescriptions.InProceedingsofthe50thAnnualMeetingoftheAssociationforCom-putationalLinguistics(Volume1:LongPapers),pages359–368,JejuIsland,Korea,July.SimingLi,GirishKulkarni,TamaraL.Berg,Alexan-derC.Berg,andYejinChoi.2011.Composingsim-pleimagedescriptionsusingweb-scalen-grams.InProceedingsoftheFifteenthConferenceonCompu-tationalNaturalLanguageLearning(CoNLL),pages220–228,Portland,OR,USA,June.DekangLin.1998.Aninformation-theoreticdeﬁni-tionofsimilarity.InProceedingsoftheFifteenthIn-ternationalConferenceonMachineLearning(ICML),pages296–304,Madison,WI,USA,July.BillMacCartneyandChristopherD.Manning.2008.Modelingsemanticcontainmentandexclusioninnat-urallanguageinference.InProceedingsofthe22ndInternationalConferenceonComputationalLinguis-tics(Coling2008),pages521–528,Manchester,UK,August.AndrewKachitesMcCallum.2002.Mal-let:Amachinelearningforlanguagetoolkit.http://www.cs.umass.edu/mccallum/mallet.ShacharMirkin,IdoDagan,andEyalShnarch.2009.Evaluatingtheinferentialutilityoflexical-semanticresources.InProceedingsofthe12thConferenceoftheEuropeanChapteroftheACL(EACL2009),pages558–566,Athens,Greece,March.JeffMitchellandMirellaLapata.2010.Compositionindistributionalmodelsofsemantics.CognitiveScience,34(8):1388–1429.MargaretMitchell,JesseDodge,AmitGoyal,KotaYa-maguchi,KarlStratos,XufengHan,AlyssaMensch,AlexBerg,TamaraBerg,andHalDaumeIII.2012.Midge:Generatingimagedescriptionsfromcomputervisiondetections.InProceedingsofthe13thConfer-enceoftheEuropeanChapteroftheAssociationforComputationalLinguistics(EACL),pages747–756,Avignon,France,April.RichardMontague.1974.Formalphilosophy:papersofRichardMontague.YaleUniversityPress,NewHaven.EditedbyRichmondH.Thomason.JoakimNivre,JohanHall,andJensNilsson.2006.Malt-parser:Adata-drivenparser-generatorfordependencyparsing.InProceedingsoftheInternationalConfer-enceonLanguageResourcesandEvaluation(LREC),pages2216–2219.VicenteOrdonez,GirishKulkarni,andTamaraL.Berg.2011.Im2text:Describingimagesusing1millioncaptionedphotographs.InAdvancesinNeuralInfor-mationProcessingSystems24,pages1143–1151.JuditaPreiss.2001.Anaphoraresolutionwithwordsensedisambiguation.InProceedingsofSENSEVAL-2SecondInternationalWorkshoponEvaluatingWordSenseDisambiguationSystems,pages143–146,Toulouse,France,July.PhilipResnik.1995.Usinginformationcontenttoevalu-atesemanticsimilarityinataxonomy.InProceedingsofthe14thinternationaljointconferenceonArtiﬁcialintelligence-Volume1,IJCAI’95,pages448–453.IdanSzpektorandIdoDagan.2008.Learningentailmentrulesforunarytemplates.InProceedingsofthe22ndInternationalConferenceonComputationalLinguis-tics(Coling2008),pages849–856,Manchester,UK,August.Coling2008OrganizingCommittee.FraneˇSari´c,GoranGlavaˇs,MladenKaran,JanˇSnajder,andBojanaDalbeloBaˇsi´c.2012.Takelab:Sys-temsformeasuringsemantictextsimilarity.InPro-ceedingsoftheSixthInternationalWorkshoponSe-manticEvaluation(SemEval2012),pages441–448,Montr´eal,Canada,7-8June.JulieWeedsandDavidWeir.2003.Ageneralframe-workfordistributionalsimilarity.InProceedingsofthe2003ConferenceonEmpiricalMethodsinNaturalLanguageProcessing(EMNLP),pages81–88.YezhouYang,ChingTeo,HalDaumeIII,andYiannisAloimonos.2011.Corpus-guidedsentencegenera-tionofnaturalimages.InProceedingsofthe2011ConferenceonEmpiricalMethodsinNaturalLan-guageProcessing(EMNLP),pages444–454,Edin-burgh,UK,July."
    ]
}