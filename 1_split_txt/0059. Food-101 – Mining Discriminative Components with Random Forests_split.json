{
    "title_author_abstract_introduction": "Food-101 – Mining Discriminative Components with Random Forests\nLukas Bossard1, Matthieu Guillaumin1, and Luc Van Gool1,2\n1 Computer Vision Lab, ETH Z¨urich, Switzerland lastname@vision.ee.ethz.ch 2 ESAT, PSI-VISICS, K.U. Leuven, Belgium vangool@esat.kuleuven.be\nAbstract. In this paper we address the problem of automatically recognizing pictured dishes. To this end, we introduce a novel method to mine discriminative parts using Random Forests (rf), which allows us to mine for parts simultaneously for all classes and to share knowledge among them. To improve eﬃciency of mining and classiﬁcation, we only consider patches that are aligned with image superpixels, which we call components. To measure the performance of our rf component mining for food recognition, we introduce a novel and challenging dataset of 101 food categories, with 101’000 images. With an average accuracy of 50.76%, our model outperforms alternative classiﬁcation methods except for cnn, including svm classiﬁcation on Improved Fisher Vectors and existing discriminative part-mining algorithms by 11.88% and 8.13%, respectively. On the challenging mit-Indoor dataset, our method compares nicely to other s-o-a component-based classiﬁcation methods.\nKeywords: Image classiﬁcation, Discriminative part mining, Random Forest, Food recognition.\nIntroduction\nFood is an important part of everyday life. This clearly ripples through into digital life, as illustrated by the abundance of food photography in social networks, dedicated photo sharing sites and mobile applications.1 Automatic recognition of dishes would not only help users eﬀortlessly organize their extensive photo collections but would also help online photo repositories make their content more accessible. Additionally, mobile food photography is now used to help patients estimate and track their daily calory intake, outside of any constraining clinical environment. However, current systems resort to nutrition experts [27] or Amazon Mechanical Turk [30] to label food items.\nDespite these numerous applications, the problem of recognizing dishes and the composition of their ingredients has not been fully addressed by the computer vision community. This is not due to the lack of challenges. In contrast to scene classiﬁcation or object detection, food typically does not exhibit any distinctive\n1 E.g.: foodspotting.com, sharedappetite.com, foodgawker.com, etc.\nD. Fleet et al. (Eds.): ECCV 2014, Part VI, LNCS 8694, pp. 446–461, 2014. c(cid:2) Springer International Publishing Switzerland 2014\nFood-101 – Mining Discriminative Components with Random Forests\nFig.1. Typical examples of our dataset and corresponding mined components. From left to right: baby back ribs, chocolate cake, hot and sour soup, caesar salad, eggs benedict. [All our ﬁgures are best viewed in color]\nspatial layout: while we can decompose an outdoor scene with a ground plane, a horizon and a sky region, or a human as a trunk with a head and limbs, we cannot ﬁnd similar patterns relating ingredients of a mixed salad. The point of view, the lighting conditions, but also (and not least) the very realization of a recipe are among the sources of high intra-class variations. On the bright side, the nature of dishes is often deﬁned by the diﬀerent colors and textures of its diﬀerent local components, such that humans can identify them reasonably well from a single image, regardless of the above variations. Hence, food recognition is a speciﬁc classiﬁcation problem calling for models that can exploit local information.\nAs a consequence, we aim at identifying discriminative image regions which help distinguish each type of dish from the others. We refer to those as components and show a few examples in Fig. 1. To mine for such components, we introduce a weakly-supervised mining method which relies on Random Forests [14,4]. It is similar in spirit to previously proposed mid-level discriminative patch mining work [7,35,38,25,8,19,34,40]. Our Random Forest mining framework diﬀers from all these works in the following points: First, it mines for discriminative components simultaneously for all classes, compared to independently. This speeds up the training process and allows to share knowledge between classes. Second, we restrict the search space for discriminative parts to patches aligned with superpixels, instead of sampling random image patches, in a spirit similar to what has been successfully proposed in the context of object detection [36,12]. As a consequence, not only do we manipulate regions that are consistent in color and texture, but we can aﬀord extracting stronger visual features to improve classiﬁcation. This also dramatically reduces the classiﬁcation complexity on test images as the numbers of component classiﬁers/detectors can be fairly large (hundreds to several ten thousands): we typically use only a few dozens of superpixels per image, compared to tens of thousands of sliding windows.\nThe paper also introduces a new, publicly available dataset for real-world food recognition with 101’000 images. We coin this dataset Food-101, as it consists of 101 categories. To the best of our knowledge, this is the ﬁrst public database of its kind. So far, research on food recognition has been either performed on closed, proprietary datasets [15] or on small-scale image sets taken in a controlled laboratory environment [5,39].\nIn summary, this paper makes the following contributions: (i) A novel discriminative part mining method based on Random Forests. (ii) A superpixelbased patch sampling strategy that prevents running many detectors on sliding\nL. Bossard, M. Guillaumin, and L. Van Gool\nwindows. (iii) A novel, large scale and publicly available dataset for food recognition. (iv) Experiments showing that our approach outperforms the state-of-theart Improved Fisher Vectors classiﬁer [32] and the part-based mining approach of [34] on Food-101. On the mit-Indoor dataset, our method compares nicely to very recent mining methods and is competitive with ifv.\nWe discuss related work in the next section. Our novel dataset is described in Section 3. In Section 4, we introduce our component mining and classiﬁcation framework. Our method is evaluated in Section 5, and we conclude in Section 6.",
    "data_related_paragraphs": [
        "Image classiﬁcation is a core problem for computer vision, with many recent advances coming from object recognition. Classical approaches exploit interest point descriptors, extracted locally or on a dense grid, then pooled into a vectorial representation to use svm for classiﬁcation. Recent advances highlight the importance of nonlinear feature encoding, e.g., Fisher Vectors [32] and spatial pooling [24]. A very recent and successful trend in classiﬁcation is to try and identify discriminative object (or scene) parts (or patches) [7,35,38,25,8,19,34,40], drawing on the success of deformable part-based models (dpm) for object detection [9]. This can consist of (a) ﬁnding prototypes for regions of interest [31,40], (b) mining patches whose associated binary svm obtains good classiﬁcation accuracy on a validation set [34], (c) clustering patches with a multi-instance svm (mi-svm) [38] on a external dataset [25], (d) optimizing part detectors in a latent svm framework [35], (e) evaluating many exemplar-svms [8,19] on sliding windows, exploiting discriminative decorrelation [13] to speed-up the process, or (f) identifying discriminative modes in the hog feature space [7].",
        "While this work represents a variant of discriminative part mining, it diﬀers in various ways from previous work. In contrast to all other discriminative part mining methods, we eﬃciently and simultaneously mine for discriminative parts for all the categories in our dataset thanks to the multi-class nature of Random Forests. Secondly, while all other methods employ a computationally expensive (often multi scale) sliding window detection approach to produce the part score maps for the ﬁnal classiﬁcation step, our approach employs a simple yet eﬀective window selection by exploiting image superpixels.",
        "Concerning food recognition, most works follow a classical recognition pipeline, focusing on feature combination and on specialized datasets. [18] uses a private dataset of Japanese food, later augmented with more features and classes [20]. Similarly, [6] jointly classiﬁes and estimates quantity of 50 Chinese food categories using private data. [28] uses dpm to locally pool features. Food images obtained in a controlled environment are also popular in the literature. The Pittsburgh food dataset [5] contains 101 classes, but with only 3 instances per class and 8 images per instance. Yang et al. [39] propose to learn spatial relationships between ingredients using pairwise features. This approach is bound to work only for standardized meals.",
        "Fig.2. Here we show one example for 100 out of the 101 classes in our dataset. Note the high variance in food type, color, exposure and level of detail, but also visually and semantically similar food types.",
        "3 Dataset: Food-101",
        "As noted above, to date, only the pfid dataset [5] is publicly available. However, it contains only standardized fast food images taken under laboratory conditions. Therefore, we have collected a novel real-world food dataset by downloading images from foodspotting.com. The site allows users to take images of what they are eating, annotate place and type of food and upload these information online. We chose the top 101 most popular and consistently named dishes and randomly sampled 750 training images. Additionally, 250 test images were collected for each class, and were manually cleaned. On purpose, the training images were not cleaned, and thus still contain some amount of noise. This comes mostly in the form of intense colors and sometimes wrong labels. We believe that real-world computer vision algorithms should be able to cope with such weakly labeled data if they are meant to scale well with the number of classes to recognise. All images were rescaled to have a maximum side length of 512 pixels and smaller ones were excluded from the whole process. This leaves us with a dataset of 101’000 realworld images in total, including very diverse but also visually and semantically similar food classes such as Apple pie, Waﬄes, Escargots, Sashimi, Onion rings, Mussels, Edamame, Paella, Risotto, Omelette, Bibimbap, Lobster bisque, Eggs benedict, Macarons to name a few. Examples are shown in Fig. 2. The dataset is available for download at http://www.vision.ee.ethz.ch/datasets/food-101/.",
        "Based on the training data, each leaf l is associated with an empirical distribution of class labels p(y|l). Using a validation set, we classify each sample s using the forest, and we deﬁne δl,s = 1 if the sample has reached the leaf l, and 0 otherwise. For each sample, we can easily derive its class conﬁdence score p(y|s) from the statistics of the leaves it reached: (cid:4)",
        "In the following, we refer to our approach as Random Forest Discriminant Components (rfdc) and evaluate it against various methods. For our novel Food-101 dataset (Sect. 3), 750 images of each class are used for training and the remaining 250 for testing. We measure performance with average accuracy, i.e. the fraction of test images that are correctly classiﬁed. We ﬁrst give details of our implementation in Sect. 5.1 and analyze then the robustness of our approach with respect to its diﬀerent parameters in Sect. 5.2. In Sect. 5.3, we compare to baselines and alternative state-of-the-art component-mining algorithms for classiﬁcation. As our approach is generic and can be directly applied to other classiﬁcation problems as well, we also evaluate on the mit-Indoor dataset [31] in Sect. 5.4.",
        "Fig.5. Inﬂuence of diﬀerent parameters of rfdc on classiﬁcation performance on the Food-101 dataset",
        "Convolutional Neural Networks (CNN). We also compare our approach with convolutional neural networks. To this end, we train a deep cnn on our dataset using the architecture of [23] as provided by the Caﬀe [16] library until it converged (450’000 iterations).",
        "Quantitative Results. We report in Tab. 2 the classiﬁcation accuracies obtained by the diﬀerent methods discussed above on the Food-101 dataset. Among global classiﬁers, ifv signiﬁcantly outperforms the standard bow approach by 10%. Switching to local classiﬁcation is clearly beneﬁcial for the Food-101 dataset. The mlds approach [34] using strong features on superpixels already gives an improvement of 3.75% with respect to ifv. Looking at the results of Random Forests, we ﬁrst observe that using them directly for classiﬁcation performs similar to bow (about 33% accuracy). The bagging of the random trees is not able to recover from the potentially noisy leaves. Also Randomized Clustering Forests perform at a similar accuracy level. As the number of samples is very limited,",
        "the intermediate binary representation is probably too sparse. When using the discriminative component mining together with multi-class svm classiﬁcation, we measure an accuracy of 50.76%, an improvement of 8.13% and 11.88% compared to mlds and ifv, respectively. Also on this dataset, cnn set the state of the art and rfdc are outperformed by a margin of 5.64%. This is paid by a considerably longer training time of six days on a nvidia Tesla K20X.",
        "5.4 Results on MIT-Indoor For running the experiments on the mit-Indoor dataset, we use the same settings as for Food-101 except, that we sample 100’000 samples per bag. Additionally, we horizontally ﬂip the images in the training set to generate a higher number of samples. For conducting the experiments, we follow the original protocol of [31] with approximately 80 training and 20 testing images per class (restricted train set). As this is a rather low number of training examples, we also report the",
        "Compared to other recent approaches, rfdc signiﬁcantly outperforms [34] as well as all the other very recent sliding window methods of [19,25,38,35]. Note that some of them train their components on external data [25] or have a higher number of components ([35] uses 73 components per class). Clearly, one of the reasons for the achieved performance is the use of stronger features. On the other hand, stronger features can be used here only because our approach needs to evaluate only a small number of superpixels compared to thousands of sliding windows. Still, the full classiﬁcation time (including feature extraction and Fisher encoding) of one image is around 0.8 seconds using 8 cores, where 70% of the time is spent on encoding and 25% for evaluating the part models.",
        "Interestingly, most previously proposed part-based classiﬁcation approaches based on sliding windows (or patches) and hog features typically did not outperform ifv on other datasets until very recently [7]. Our Food-101 dataset (where rfdc outperforms ifv) therefore presents a bias signiﬁcantly diﬀerent from available sets, highlighting its interest as a novel benchmark.",
        "Table 3. Recent results of discriminate part mining approaches and global approaches on the mit-Indoor dataset",
        "In this paper, we have introduced a novel large-scale benchmark dataset for recognition of food. We have also presented a novel method based on Random Forests to mine discriminative visual components and eﬃcient classiﬁcation. We have shown it to outperform state-of-the-art methods on food recognition except for cnn and obtaining competitive results compared to alternative recent partbased classiﬁcation approaches on the challenging mit-Indoor dataset.",
        "burgh fast-food image dataset. In: ICIP (2009)"
    ]
}