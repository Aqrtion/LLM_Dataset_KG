{
    "title_author_abstract_introduction": "Automated ﬂower classiﬁcation over a large number of classes\nMaria-Elena Nilsback and Andrew Zisserman Visual Geometry Group, Department of Engineering Science University of Oxford, United Kingdom men,az@robots.ox.ac.uk\nAbstract\nWe investigate to what extent combinations of features can improve classiﬁcation performance on a large dataset of similar classes. To this end we introduce a 103 class ﬂower dataset. We compute four different features for the ﬂowers, each describing different aspects, namely the local shape/texture, the shape of the boundary, the overall spatial distribution of petals, and the colour. We combine the features using a multiple kernel framework with a SVM classiﬁer. The weights for each class are learnt using the method of Varma and Ray [16], which has achieved state of the art performance on other large dataset, such as Caltech 101/256. Our dataset has a similar challenge in the number of classes, but with the added difﬁculty of large between class similarity and small within class similarity. Results show that learning the optimum kernel combination of multiple features vastly improves the performance, from 55.1% for the best single feature to 72.8% for the combination of all features.\n1 Introduction\nAs image based classiﬁcation systems are improving the task of classifying objects is moving onto datasets with far more categories, such as Caltech256 [8]. Recent work [2, 8, 9, 16, 17, 18] has seen much success in this area. In this paper, instead of recognizing a large number of disparate categories, we investigate the problem of recognizing a large number of classes within one category – that of ﬂowers. Classifying ﬂowers poses an extra challenge over categories such as bikes, cars and cats, because of the In addition, ﬂowers are large similarity between classes. non-rigid objects that can deform in many ways, and consequently there is also a large variation within classes. Previous work on ﬂower classiﬁcation has dealt with a small number of classes [12, 14] ranging from 10 to 30. Here we introduce a 103 class dataset for ﬂower classiﬁcation. Images from the dataset are shown in ﬁgure 1.\nWhat distinguishes one ﬂower from another can sometimes be the colour, e.g. blue-bell vs sunﬂower, sometimes the shape, e.g. daffodil vs dandelion, and sometimes patterns on the petals, e.g. pansies vs tigerlilies etc. The difﬁculty lies in ﬁnding suitable features to represent colour, shape, patterns etc, and also for the classiﬁer having the capacity to learn which feature or features to use.\nIn the case of the Caltech 101/256 image datasets [7, 8], stateoftheartperformancehasbeenachievedbyusingmultiple features [18] and a linear combination of kernels in a SVM classiﬁer [2, 3, 16]: a base kernel is computed for each feature (e.g. shape, appearance) and the ﬁnal kernel is composed of a weighted linear combination of these base kernels [3] with a different set of weights learnt for each class. Varma and Ray [16] showed that the weights could be learnt by solving a convex optimization problem.\nIn this paper we investigate this multiple kernel learning approach for ﬂower images acquired under fairly uncontrolled image situations – the images are mainly downloaded from the web and vary considerably in scale, resolution, lighting, clutter, quality, etc. The link we make is to automatically segment each image (section 2) so that the ﬂower is isolated in the image. This makes the recognition challenge somewhat similar in nature to that of Caltech 101/256 – in that there is only a single (or very few) instances of the object in each image (excepting ﬁelds of ﬂowers like bluebells) – i.e. the background clutter has been removed, and there are a similar number (103 vs 101) of classes to be classiﬁed. On the other hand ﬂowers have the additional challenges (compared to Caltech101) of scale variation, pose variation and also greater between class similarity.\nWe design features, and corresponding kernels, suited to the ﬂower class which capture the colour, texture, and shape (local and global) of the petals and their arrangement. This is presented in section 3. The image dataset and experimental procedure are described in section 4, and results on the test set given in section 5.\nalpine sea holly\nanthurium\nartichoke\nazalea\nball moss\nballoon ﬂower\nbarbeton daisy\nbearded iris\nbee balm\nbird of paradise\nbishop of llandaff\nblack-eyed susan\nblackberry lily\nblanket ﬂower\nbolero deep blue\nbougainvillea\nbromelia\nbuttercup\ncalifornian poppy\ncamellia\ncanna lily\ncanterbury bells\ncape ﬂower\ncarnation\ncautleya spicata\nclematis\ncolt’s foot\ncolumbine\ncommon dandelion\ncorn poppy\ncyclamen\ndaffodil\ndesert-rose\nenglish marigold\nﬁre lily\nfoxglove\nfrangipani\nfritillary\ngarden phlox\ngazania\ngeranium\ngiant white arum lily\nglobe thistle globe-ﬂower\ngrape hyacinth\ngreat masterwort\nhard-leaved pocket orchid\nhibiscus\nhippeastrum\njapanese anemone\nking protea\nlenten rose\nlove in the mist\nmagnolia\nmallow\nmarigold mexican aster\nmexican petunia\nmonkshood moon orchid\nmorning glory\norange dahlia osteospermum oxeye daisy\npassion ﬂower\npelargonium peruvian lily\npetunia\npetunia\npincushion ﬂower\npink primrose\npink-yellow dahlia?\npoinsettia\nprimula\nprince of wales feathers\npurple coneﬂower\nred ginger\nruby-lipped cattleya\nsiam tulip\nsilverbush\nsnapdragon\nspear thistle spring crocus\nstemless gentian\nsunﬂower\nsweet pea\nsweet william\nsword lily\nthorn apple\ntiger lily\ntoad lily\ntree mallow tree poppy\ntrumpet creeper\nwallﬂower\nwater lily\nwatercress\nwild pansy windﬂower\nyellow iris\nSIFT int\nSIFT bdy\nFigure 1: The 103 class ﬂower dataset. Each image is an instance of a different class. They are sorted alphabetically. The colour bar below each image shows the magnitude of the features weights learnt for each class, as described in section 4.",
    "data_related_paragraphs": [
        "The scheme of [13] proceeds in an iterative manner: ﬁrst an initial ﬂower segmentation is obtained using general (non-class speciﬁc) foreground and background colour distributions. These distributions are learnt by labelling pixels in a few training images of each class in the dataset as foreground (i.e. part of the ﬂower), or background (i.e. part of the greenery), and then averaging the distributions across all classes. Given these general foreground and background distributions, the initial binary segmentation is obtained using the contrast dependent prior MRF cost function of [4], optimized with graph cuts. This segmentation may not be perfect, but is often sufﬁcient to extract at least part of the external boundary of the ﬂower. A generic ﬂower shape model is then ﬁtted to this initial segmentation in order to detect petals. The model selects petals which have a loose geometric consistency using an afﬁne invariant Hough like procedure. The image regions for the petals deemed to be geometrically consistent are used to obtain a new image speciﬁc foreground colour model. The foreground colour model is then updated by blending the image speciﬁc foreground model with the general foreground model. The MRF segmentation is repeated using this new colour model. In cases where the initial segmentation was not perfect, the use of the image speciﬁc foreground often harvests more of the ﬂower. The steps of shape model ﬁtting and image speciﬁc foreground learning can then be iterated until convergence, when no or very little change has occurred between two consecutive iterations.",
        "The scheme was introduced using a 13 class ﬂower dataset, a subset of the 17 class ﬂower dataset of [12]. Figure 2 shows example segmentations obtained using this scheme on our 103 class dataset. It can be seen that it also works well for ﬂowers very different in shape to those used in [13].",
        "The classiﬁer is a SVM [15] using multiple kernels [1]. A weighted linear combination of kernels is used, one kernel corresponding to each feature. The ﬁnal kernel has the following form for two data points i and j:",
        "4 The dataset and experimental procedure",
        "In this paper we introduce a dataset consisting of 8189 images divided into 103 ﬂower classes. Figure 1 shows one example of each class. These are chosen to be ﬂowers commonly occurring in the United Kingdom. Most of the images were collected from the web. A small number of images were acquired by taking the pictures ourselves. Each class consists of between 40 and 250 images. Figure 3 shows the distribution of the number of images over all the classes. Passion ﬂower has the greatest number of images and eustoma, mexican aster, celosia, moon orchid, canterbury bells and primrose have the least, i.e. 40 per class. The images are rescaled so that the smallest dimension is 500 pixels.",
        "Once the parameters have been determined on the validation set, the classiﬁers are retrained using all the available training data (both the training and validation sets). At this stage the weights βf are determined using the optimization method of Varma and Ray [16].",
        "The dataset is divided into a training set, a validation set and a test set. The training set and validation set each consistof10imagesperclass(totalling1030imageseach). The test set consist of the remaining 6129 images (minimum 20 per class). The validation set is used to optimize the number of visual words for each of the features, and the radius and spacing of the SIFT features.",
        "For example for the internal SIFT features, the classiﬁer is trained on the training data using only the kernel for this one feature. The optimum number of words in the vocabulary is determined by searching over a range between 1000 and 10000 and ﬁnding the maximum classiﬁcation performance on the validation set. Each k-means clustering is repeated 3 times, and the best results kept. For colour the search is over the range 100 to 5000, because colour features have much fewer dimensions than SIFT, so we expect tobeabletousefewerwordstodescribethem. Boththegrid spacing M and the circular support patches R, are searched over a range of 5 to 50 pixels. Maximization of the performance on the validation set is carried out separately for each variable.",
        "In this section we compare the performance of our method on the publicly available 17 class ﬂower dataset",
        "http://www.robots.ox.ac.uk/∼vgg/data/ flowers/index.html, which was introduced in [12], with the two previous publications that have classiﬁed this dataset: Nilsback and Zisserman [12], and Varma and Ray [16]. Again, we report a class average classiﬁcation for the overall recognition performance. Note, in [12] the performance measure was a weighted rank, aimed at",
        "[8] G. Grifﬁn, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical Report 7694, California Institute of Technology, 2007.",
        "We also do a comparison using the iterative segmentation scheme used in this paper (from [13]). We recompute the shape, colour and texture descriptors of [12] on the new segmentations. The weights are again optimized as in [12]. This gives a recognition performance of 73.14 ± 1.76%. Again performance is improved by using a multiple kernel classiﬁer, which gives a recognition performance of 83.33±1.39%. Finally, using the features computed in this paper and the multiple kernel classiﬁer leads to a performance of 88.33±0.3%. This is the best performance todate reported on the 17 class ﬂower dataset.",
        "We have shown that by combining features in an optimized kernel framework we can improve the classiﬁcation performance of a large dataset of very similar classes. The learning of different weights for different classes enables us to use an optimum feature combination for each classiﬁcation. This allows us to incorporate, for example, that someclassesareverysimilarinshapebut different in colour and that some classes are better distinguished by the overall shape than the internal shape and vice versa. The principal challenge now lies in the large variations within a class and the relatively few samples of images. Future work should include using visually similar classes to jointly train the classiﬁer."
    ]
}