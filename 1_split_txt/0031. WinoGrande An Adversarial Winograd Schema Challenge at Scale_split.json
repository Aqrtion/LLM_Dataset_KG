{
    "title_author_abstract_introduction": "WINOGRANDE: An Adversarial Winograd Schema Challenge at Scale\nKeisuke Sakaguchi∗, Ronan Le Bras∗, Chandra Bhagavatula∗, Yejin Choi∗† ∗Allen Institute for Artiﬁcial Intelligence †University of Washington {keisukes, ronanlb, chandrab, yejinc}@allenai.org\nAbstract\nThe Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), a benchmark for commonsense reasoning, is a set of 273 expert-crafted pronoun resolution problems originally designed to be unsolvable for statistical models that rely on selectional preferences or word associations. However, recent advances in neural language models have already reached around 90% accuracy on variants of WSC. This raises an important question whether these models have truly acquired robust commonsense capabilities or whether they rely on spurious biases in the datasets that lead to an overestimation of the true capabilities of machine commonsense. To investigate this question, we introduce WINOGRANDE, a large-scale dataset of 44k problems, inspired by the original WSC design, but adjusted to improve both the scale and the hardness of the dataset. The key steps of the dataset construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) systematic bias reduction using a novel AFLITE algorithm that generalizes human-detectable word associations to machine-detectable embedding associations. The best state-of-the-art methods on WINOGRANDE achieve 59.4 – 79.1%, which are ∼15-35% (absolute) below human performance of 94.0%, depending on the amount of the training data allowed (2% – 100% respectively). Furthermore, we establish new state-of-the-art results on ﬁve related benchmarks — WSC (→ 90.1%), DPR (→ 93.1%), COPA(→ 90.6%), KnowRef (→ 85.6%), and Winogender (→97.1%).Theseresultshavedualimplications:ononehand, they demonstrate the effectiveness of WINOGRANDE when used as a resource for transfer learning. On the other hand, they raise a concern that we are likely to be overestimating the true capabilities of machine commonsense across all these benchmarks. We emphasize the importance of algorithmic bias reduction in existing and future benchmarks to mitigate such overestimation.\nIntroduction\nThe Winograd Schema Challenge (WSC) (Levesque, Davis, and Morgenstern 2011), proposed as an alternative to the Turing Test (Turing 1950), has been used as a benchmark for evaluating commonsense reasoning. WSC are designed to be pronoun resolution problems (see examples in Table 1) that are trivial for humans but hard for machines that merely\nrely on statistical patterns without true capabilities of commonsense reasoning. However, recent advances in neural language models have already reported around 90% accuracy on a variant of WSC dataset.1 This raises an important question:\nHave neural language models successfully acquired commonsense or are we overestimating the true capabilities of machine commonsense?\nThis question about the potential overestimation leads to another crucial question regarding potential unwanted biases that the large-scale neural language models might be exploiting, essentially solving the problems right, but for wrong reasons. While WSC questions are expert-crafted, recent studies have shown that they are nevertheless prone to incidental biases. Trichelair et al. (2018) have reported word-association (13.5% of the cases, see Table 1 for examples) as well as other types of dataset-speciﬁc biases. While such biases and annotation artifacts are not apparent for individual instances, they get introduced in the dataset as problem authors subconsciously repeat similar problem-crafting strategies.\nTo investigate this question about the true estimation of the machine commonsense capabilities, we introduce WINOGRANDE, a new dataset with 44k problems that are inspired by the original design of WSC, but modiﬁed to improve both the scale and hardness of the problems. The key steps in WINOGRANDE construction consist of (1) a carefully designed crowdsourcing procedure, followed by (2) a novel algorithm AFLITE that generalizes human-detectable biases based on word occurrences to machine-detectable biases based on embedding occurrences. The key motivation of our approach is that it is difﬁcult for humans to write problems without accidentally inserting unwanted biases.\nWhile humans ﬁnd WINOGRANDE problems trivial with 94% accuracy, best state-of-the-art results, including those from RoBERTa (Liu et al. 2019) are considerably lower, ranging between 59.4% - 79.1% depending on the amount of training data provided (from 800 to 41k instances), which falls 15 - 35% (absolute) below the human-level performance.\n1https://github.com/pytorch/fairseq/tree/master/examples/ roberta. We note that this variant aggregates the original WSC, PDP (Morgenstern, Davis, and Ortiz 2016) and additional PDP-style examples, and recasts them into True/False binary problems.\nTwin sentences\n(cid:51) (1)\n(cid:51) (2)\n(cid:55) (3)\n(cid:55) (4)\nThe trophy doesn’t ﬁt into the brown suitcase because it’s too large. a The trophy doesn’t ﬁt into the brown suitcase because it’s too small. b a Ann asked Mary what time the library closes, because she had forgotten. b Ann asked Mary what time the library closes, but she had forgotten. a b a b\nThe tree fell down and crashed through the roof of my house. Now, I have to get it removed. The tree fell down and crashed through the roof of my house. Now, I have to get it repaired. The lions ate the zebras because they are predators. The lions ate the zebras because they are meaty.\nOptions (answer) trophy / suitcase trophy / suitcase Ann / Mary Ann / Mary tree / roof tree / roof lions / zebras lions / zebras\nTable 1: WSC problems are constructed as pairs (called twin) of nearly identical questions with two answer choices. The questions include a trigger word that ﬂips the correct answer choice between the questions. Examples (1)-(3) are drawn from WSC (Levesque, Davis, and Morgenstern 2011) and (4) from DPR (Rahman and Ng 2012)). Examples marked with (cid:55) have language-based bias that current language models can easily detect. Example (4) is undesirable since the word “predators” is more often associated with the word “lions”, compared to “zebras”\nFurthermore, we also demonstrate that WINOGRANDE provides transfer learning to other existing WSC and related benchmarks, achieving new SOTA performances on ﬁve of them, including the original WSC (Levesque, Davis, and Morgenstern 2011) (→ 90.1%), DPR (Rahman and Ng 2012) (→ 93.1%), COPA (Roemmele, Bejan, and Gordon 2011) (→ 90.6%), KnowRef (Emami et al. 2019) (→ 85.6%), and Winogender (Rudinger et al. 2018) (→ 97.1%).\nAlthough the improvements of SOTA over multiple challenging benchmarks are exciting, we cautiously note that these positive results must be taken with a grain of salt. The result might also indicate the extent to which spurious effects are prevalent in existing datasets, which runs the risk of overestimating the true capabilities of machine intelligence on commonsense reasoning. More generally, human-crafted problems and tasks (regardless of whether they are crowdsourced or by experts) contains annotation artifacts in many cases, and algorithmic bias reduction such as AFLITE is essential to mitigate such dataset-speciﬁc bias.",
    "data_related_paragraphs": [
        "2 Crowdsourcing WINOGRANDE at Scale WSC problems have been considered challenging to craft by crowdsourcing due to the structural constraints of twins and the requirement of linguistic knowledge (Table 1). Nevertheless,wepresentaneffectiveapproachtocreatingalarge-scale dataset (WINOGRANDE) of WSC problems while maintaining its original properties – i.e. trivial for humans but hard for AI systems. Our approach consists of a carefully designed crowdsourcing task followed by a novel adversarial ﬁltering algorithm (§3) that systematically removes biases in the data.",
        "Enhancing Crowd Creativity Creating twin sentences from scratch puts a high cognitive load on crowd workers who thereby subconsciously resort to writing pairs that are lexically and stylistically repetitive. To encourage creativity and reduce their cognitive load, we employed creativity from constraints (Stokes 2005) – a psychological notion which suggests that appropriate constraints can help structure and drive creativity. In practice, crowd workers are primed by a randomly chosen topic as a suggestive context (details below), while they are asked to follow precise guidelines on the structure of the curated data.",
        "Data Validation We validate each collected question through a distinct set of three crowd workers. Following a rigorous process, a question is deemed valid if (1) the majority of the three workers chooses the correct answer option, (2) they agree that the two answer options are unambiguous (one option is clearly more plausible than the other) and (3) the question cannot be answered simply by word association in which local context around the target pronoun is given (e.g., “because it was going so fast.” (race car / school bus)).5 As a result, 68% of the questions (53k) were deemed valid and we discarded the invalid questions.",
        "2Our datasets, crowdsourcing interface, and models are available",
        "still possible that the constructed dataset has dataset-speciﬁc biases – especially after it has been scaled up. To address this challenge, we propose a method for systematic bias reduction.",
        "3 Algorithmic Data Bias Reduction Several recent studies (Gururangan et al. 2018; Poliak et al. 2018; Tsuchiya 2018; Niven and Kao 2019; Geva, Goldberg, and Berant 2019) have reported the presence of annotation artifacts in large-scale datasets. Annotation artifacts are unintentional patterns in the data that leak information about the target label in an undesired way. State-of-the-art neural models are highly effective at exploiting such artifacts to solve problems correctly, but for incorrect reasons. To tackle this persistentchallengewithdatasetbiases,wepropose AFLITE – a novel algorithm that can systematically reduce biases using state-of-the-art contextual representation of words.",
        "Light-weight adversarial ﬁltering Our approach builds upon the adversarial ﬁltering (AF) algorithm proposed by Zellers et al. (2018), but makes two key improvements: (1) AFLITE is much more broadly applicable (by not requiring over generation of data instances) and (2) it is considerably more lightweight (not requiring re-training a model at each iteration of AF). Overgenerating machine text from a language model to use in test instances runs the risk of distributional bias where a discriminator can learn to distinguish between machine generated instances and human-generated ones. In addition, AF depends on training a model at each iteration, which comes at extremely high computation cost when being adversarial to a model like BERT (Devlin et al. 2018).6",
        "features, we adopt a dense representation of instances using their precomputed neural network embeddings. In this work, we use RoBERTa (Liu et al. 2019) ﬁne-tuned on a small subset of the dataset. Concretely, we use 6k instances (5k for training and 1k for validation) from the dataset (containing 53k instances in total) to ﬁne-tune RoBERTa (referred to as RoBERTaembed). We use RoBERTaembed to pre-compute the embeddings for the rest of the instances (47k) as the input for AFLITE. We discard the 6k instances from the ﬁnal dataset.",
        "Next, we use an ensemble of linear classiﬁers (logistic regressions) trained on random subsets of the data to determine whether the representation used in RoBERTaembed is strongly indicative of the correct answer option. If so, we discard the corresponding instances and proceed iteratively.",
        "Algorithm 1 provides the implementation of AFLITE. The algorithm takes as input the pre-computed embeddings X and labels y, along with the size n of the ensemble, the training size m for the classiﬁers in the ensemble, the size k of the ﬁltering cutoff, and the ﬁltering threshold τ. At each ﬁltering phase, we train n linear classiﬁers on different random partitions of the data and we collect their predictions",
        "6AFLITE is designed for ﬁltering instances so that the resulting dataset is less biased, whereas the original AF algorithm (Zellers et al. 2018) is designed for “generating and modifying” individual instances, such as by creating better distractors. AFLITE and AF are therefore different in their goals and hence difﬁcult to compare directly.",
        "Input: dataset D = (X,y), ensemble size n, training set size",
        "Output: dataset D(cid:48)",
        "This approach is also reminiscent of recent work in NLP on adversarial learning (Chen and Cardie 2018; Belinkov et al. 2019; Elazar and Goldberg 2018). Belinkov et al. (2019) propose an adversarial removal technique for NLI which encourages models to learn representations that are free of hypothesis-only biases. When proposing a new benchmark, however, we cannot enforce that any future model will purposefully avoid learning spurious correlations in the data. In addition, while the hypothesis-only bias is an insightful bias in NLI, we make no assumption about the possible sources of bias in WINOGRANDE. Instead, we adopt a more proactive form of bias reduction by relying on state-of-the-art (statistical) methods to uncover undesirable dataset shortcuts.",
        "Assessment of AFLITE We assess the impact of AFLITE relative to two baselines: random data reduction and PMIbased ﬁltering. In random data reduction, we randomly subsample the dataset to evaluate how a decrease in dataset size affects the bias. In PMI-based ﬁltering, we compute the difference (f) of PMIs for each twin (t) as follows:",
        "Technically, we ﬁrst pre-computed PMI between a word and the label y = 1 for each word in the dataset, following a method proposed by Gururangan et al. (2018). The sum of PMI value of each token in a given sentence indicates the",
        "Figure 1: The effect of debiasing by AFLITE. RoBERTa pre-computed embeddings (applied PCA for dimension reduction) are shown in two-dimensional space (top row) and histograms regarding d1 (bottom row) with the bin size being 100. Data points are colored depending on the label (i.e., the answer y is option 1 (blue) or 2 (red)). In the histograms, we show the KL-divergence between p(d1,y=1) and q(d1,y=2).",
        "Table 2: Examples that have dataset-speciﬁc bias detected by AFLITE (marked with (cid:55)). The words that include (dataset-speciﬁc) polarity bias (§3) are highlighted (positive and negative). For comparison, we show examples selected from WINOGRANDEdebiased (marked with (cid:51)).",
        "Figure 1 plots RoBERTa pre-computed embeddings whose dimension is reduced to 2D (top) and 1D (bottom) using Principal Component Analysis (PCA). We observe that WINOGRANDEall and the two baselines exhibit distinct components between the two correct answer options (i.e., y ∈ 1,2), whereas such distinction becomes less salient in WINOGRANDEdebiased, which implies that AFLITE successfully reduces the spurious correlation in the dataset (between instancesandlabels).Toquantifytheeffect,wecomputetheKL divergence between the samples with answer options. We ﬁnd that the random data reduction does not reduce the KL diver-",
        "gence (2.53 → 2.51). It is interesting to see that PMI-ﬁltering marginally reduces the KL divergence (→ 2.42), although the principal component analysis on the PMI-ﬁltered subset still leads to a signiﬁcant separation between the labels. On the other hand, in WINOGRANDEdebiased, AFLITE reduces the KL divergence dramatically (→ 0.12) which suggests that this debiased dataset should be challenging for statistical models that solely rely on spurious correlation.",
        "What bias has been actually detected by AFLITE? Is the bias really spurious and undesirable according to the original WSC’s goal? Table 2 presents examples that AFLITE has detected as a dataset-speciﬁc bias. We see a structural pattern inthe ﬁrsttwotwins,wherethe sentimentbetweentheanswer option and the target pronoun are highly correlated. In other words, these problems can be easily answered by simply exploiting the pattern of the polarity (positive or negative). Importantly, this dataset-speciﬁc bias is structural rather than at the token level, contrasting with the biases that have been",
        "After applying the AFLITE algorithm, we obtain a debiased dataset of 12,282 instances split into training (9,248), development (1,267), and test (1,767) sets. We also release 31k problems that are ﬁltered out by AFLITE for additional training set (§4) and resource (§5), resulting in a total number of problems in WINOGRANDEall to be 43,972 (40,938 for training, 1,267 for development, and 1,767 for test).",
        "3.1 WINOGRANDE V.S. the Original WSC While WINOGRANDE is inspired by the original WSC, we make a few design choices that deviate from the original design guidelines of WSC in order to scale up the dataset considerably while ensuring the hardness of the dataset.",
        "RoBERTa RoBERTa (Liu et al. 2019) is an improved variant of BERT that adds more training data with larger batch sizes and training time, as well as other reﬁnements such as dynamic masking. RoBERTa performs consistently better than BERT across many benchmark datasets.",
        "Word association baseline Using BERT and RoBERTa, we also run the word association baseline (local-contextonly) to check if the dataset can be solved by language-based bias. In this baseline, the model is trained with only local contexts (wt−2:EOS) surrounding the blank to be ﬁlled (wt) [SEP] is too large. [SEP]). This is (e.g., because the analogous to the hypothesis-only baseline in NLI (Poliak et al. 2018), where the task (dataset) does not require the full context to achieve high performance.",
        "Finetuning on DPR dataset DPR (Deﬁnite Pronoun Resolusiton Dataset), collected by Rahman and Ng (2012), consists of 1,886 WSC style problems written by 30 undergraduate students. Kocijan et al. (2019) have recently shown that BERT ﬁnetuned with DPR boosts the performance on WCS (72.2% accuracy). As additional baselines, we ﬁnetune BERT and RoBERTa with DPR and evaluate on WINOGRANDE. This allows us to compare the difﬁculty of WSC and WINOGRANDE empirically.",
        "Table 3: Performance of several baseline systems on WINOGRANDEdebiased (dev and test). The star ((cid:63)) denotes that it is zero-shot setting (e.g., BERT-DPR(cid:63) is a BERT model ﬁne-tuned with the DPR dataset and evaluated on WINOGRANDEdebiased.)",
        "Learning Curve In order to see the effect of training size, Table 4 shows the performance by RoBERTa trained on different training sizes from 160 to 40k questions. Figure 2 shows the learning curve of the best model, RoBERTa, on the WINOGRANDEdebiased dev set. RoBERTa’s performance ranges from 59% to 79% when the size of training data is varied from 800 (2% of the training data) to 41K (100% of the training data) instances. To achieve human-level performance, current state-of-the-art models would need over 118K training instances.",
        "Importantly, the lower end of the available training data (∼800) in the learning curve roughly matches the size of the training data made available in previous variants of WSC (see Table 5). For most of these datasets, state-of-the-art already reaches around 90% (§5). In contrast, when we control for the training set size in WINOGRANDE, RoBERTa’s performance is considerably lower (59%) – demonstrating that our dataset",
        "construction method is able to compose WSC problems that are collectively considerably harder than previous datasets.",
        "5 Transfer Learning from WINOGRANDE WINOGRANDE contains a large number of WSC style questions. In addition to serving as a benchmark dataset, we use WINOGRANDE as a resource – we apply transfer learning by ﬁrst ﬁne-tuning a model on our dataset and evaluating its performance on related datasets: WSC, PDP, SuperGLUE-WSC, DPR, KnowRef, KnowRef, and Winogender). We establish state-of-the-art results across several of these existing benchmark datasets.",
        "5.1 Existing WSC and Related Datasets We brieﬂy describe existing WSC variants and other related datasets. Table 5 provides their summary statistics.",
        "WSC (Levesque, Davis, and Morgenstern 2011) This is the original Winograd Schema Challenge dataset, which consists of 273 problems. The problems are manually crafted by the authors to avoid word association bias as much as possible, although Trichelair et al. (2018) later report that 13.5% of the questions may still have word-association bias.",
        "PDP (Morgenstern, Davis, and Ortiz 2016) PDP (Pronoun Disambiguation Problems) dataset is closely related to the original WSC, and used in the 2016 running of the Winograd Schema Challenge. The dataset consists of 80 pronoun disambiguation problems. It is formulated as a multiple choice task, in which a pronoun must be resolved to one of up to 5 (but mostly binary) possible antecedents.",
        "SuperGLUE-WSC (Wang et al. 2019) SuperGLUE contains multiple datasets including a modiﬁed version of WSC, which we will refer to as SuperGLUE-WSC. This dataset aggregates the original WSC, PDP and additional PDP-style examples, and recasts them into True/False binary problems (e.g., “Pete envies Martin because he is very successful.” Q:",
        "Accuracy on Dev Set (%)405060708090100No. of Training Examples100100010000100000y = 4.8463ln(x) + 26.21594\fDataset WSC PDP SuperGLUE-WSC DPR KnowRef COPA Winogender WINOGRANDEdebiased WINOGRANDEall",
        "Table 5: Statistics on WSC and related datasets (§5.1).",
        "DPR (Rahman and Ng 2012) DPR (Deﬁnite Pronoun Resolution Dataset) introduces 1,886 additional WSC problems authored by 30 undergraduate students. Trichelair et al. (2018) point out that this dataset is overall less challenging than the original WSC due to an increased level of languagebased or dataset-speciﬁc biases. We split the original training set (1,332) into training (1,200) and development (122) sets, DPR does not have an ofﬁcial split for it.",
        "COPA (Roemmele, Bejan, and Gordon 2011) This dataset introduces 1,000 problems that aim to test commonsense reasoning focusing on script knowledge, formulated as a binary choice about causes and effects of given premises. Since COPA does not provide a training set, we split the original development set (500) into training (400) and development (100) sets in the same way as SuperGLUECOPA (Wang et al. 2019).",
        "Winogender (Rudinger et al. 2018) This dataset introduces 720 problems focusing on pronouns resolution with respect to people, with distinct goal of measuring gender bias in coreference resolution systems.",
        "Additional Human Evaluation We also report human performance for WSC, PDP, and DPR to calibrate the quality of our crowd worker pool as well as to support previous ﬁndings. To our knowledge, this is the ﬁrst work to report human performance on the DPR dataset.",
        "Table 6: Accuracy (%) on existing WSC-related tasks (test set). The star ((cid:63)) denotes that it is zero-shot setting. ‘-ft’ indicates ﬁne-tuning on the targeted dataset (train and dev). RoBERTa-X-ft denotes sequential ﬁne-tuning with dataset X followed by the targeted dataset. The daggers (†) indicate that the evaluation data is not exactly the same from ours. The double dagger (‡) denotes that we could not reproduce the same number as in SuperGLUE leaderboard (Wang et al. 2019).",
        "Table 7: Accuracy (%) and gender bias on Winogender dataset. “Gotcha” indicates whether the target gender pronoun (e.g., she) is minority in the correct answer option (e.g., doctor). |∆F| and |∆M| show the system performance gap between “Gotcha” and “non-Gotcha” for each gender (lower the better). The ﬁrst three baselines are adopted from Rudinger et al. (2018); RULE is Lee et al. (2011), STATS is Durrett and Klein (2013), and NEURAL is Clark and Manning (2016).",
        "While improvements on some related datasets (particularly WSC, PDP, and DPR) might seem expected, the signiﬁcant improvement on COPA is not so. The COPA task – identifying causes and effects – is very different from that in WINOGRANDE. This signiﬁcant improvement on an unrelated task indicates that WINOGRANDE can serve as a resource for commonsense knowledge transfer.",
        "Important Implications We consider that while these positive results over multiple challenging benchmarks are highly encouraging, they may need to be taken with a grain of salt. In particular, these results might also indicate the extent to which spurious dataset biases are prevalent in existing datasets, which runs the risk of overestimating the true capabilities of machine intelligence on commonsense reasoning. Our results and analysis indicate the importance of continued research on debiasing benchmarks and the increasing need for algorithmic approaches for systematic bias reduction, which allows for the benchmarks to evolve together with evolving state of the art. We leave it as a future research question to further investigate how much of our improvements are due to dataset biases of the existing benchmarks as opposed to true strides in improving commonsense intelligence.",
        "6 Conclusions We introduce WINOGRANDE, a new collection of 44k WSCinspired problems that is signiﬁcantly larger than existing variants of the WSC dataset. To create a dataset that is robust against spurious dataset-speciﬁc bias, we also present AFLITE – a novel light-weight adversarial ﬁltering algorithm for systematic bias reduction. The resulting dataset is considerably more challenging for existing state-of-the-art models while still being trivially easy for humans. In addition, using WINOGRANDE as a resource, we demonstrate effective transfer learning and achieve state-of-the-art results on several related benchmarks.",
        "Our work suggests a new perspective for designing benchmarks for measuring progress in AI. Unlike past decades where the community constructed a static benchmark dataset to work on for many years to come, we now need AI algorithms to compose challenges that are hard enough for AI, which requires dynamic datasets that evolve together with the evolving state-of-the-art.",
        "Bender, D. 2015. Establishing a human baseline for the winograd schema challenge. MAICS. Chen, X., and Cardie, C. 2018. Multinomial adversarial networks for multi-domain text classiﬁcation. NAACL. Clark, K., and Manning, C. D. 2016. Deep reinforcement learning for mention-ranking coreference models. EMNLP. Davis, E.; Morgenstern, L.; and Ortiz, C. 2016. Human tests of materials for the winograd schema challenge 2016. Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018. BERT: Pre-training of deep bidirectional transformers for language understanding. arXiv:1810.04805. Durrett, G., and Klein, D. 2013. Easy victories and uphill battles in coreference resolution. EMNLP. Elazar, Y., and Goldberg, Y. 2018. Adversarial removal of demographic attributes from text data. EMNLP. Emami, A.; Trischler, A.; Suleman, K.; and Cheung, J. C. K. 2018. A generalized knowledge hunting framework for the winograd schema challenge. NAACL: SRW. Emami, A.; Trichelair, P.; Trischler, A.; Suleman, K.; Schulz, H.; and Cheung, J. C. K. 2019. The KnowRef coreference corpus: Removing gender and number cues for difﬁcult pronominal anaphora resolution. ACL. Geva, M.; Goldberg, Y.; and Berant, J. 2019. Are we modeling the task or the annotator? an investigation of annotator bias in natural language understanding datasets. arXiv:1908.07898. Gordon, A. S.; Bejan, C. A.; and Sagae, K. 2011. Commonsense causal reasoning using millions of personal stories. AAAI. Gordon, A.; Kozareva, Z.; and Roemmele, M. 2012. SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning. *SEM. Gururangan, S.; Swayamdipta, S.; Levy, O.; Schwartz, R.; Bowman, S.; and Smith, N. A. 2018. Annotation artifacts in natural language inference data. NAACL. 2019. A hyHe, P.; Liu, X.; Chen, W.; and Gao, J. brid neural network model for commonsense reasoning. arXiv:1907.11983. Kobdani, H.; Schuetze, H.; Schiehlen, M.; and Kamp, H. 2011. Bootstrapping coreference resolution using word associations. ACL. Kocijan, V.; Cretu, A.-M.; Camburu, O.-M.; Yordanov, Y.; and Lukasiewicz, T. 2019. A surprisingly robust trick for the winograd schema challenge. ACL. Lee, H.; Peirsman, Y.; Chang, A.; Chambers, N.; Surdeanu, M.; and Jurafsky, D. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. CoNLL: Shared Task. Levesque, H. J.; Davis, E.; and Morgenstern, L. 2011. The winograd schema challenge. AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning. Liu, Q.; Jiang, H.; Ling, Z.-H.; Zhu, X.; Wei, S.; and Hu, Y. 2016. Commonsense knowledge enhanced embeddings for solving pronoun disambiguation problems in winograd schema challenge. arXiv:1611.04146.",
        "Liu, Y.; Ott, M.; Goyal, N.; Du, J.; Joshi, M. S.; Chen, D.; Levy, O.; Lewis, M.; Zettlemoyer, L. S.; and Stoyanov, V. 2019. Roberta: A robustly optimized bert pretraining approach. ArXiv abs/1907.11692. Morgenstern, L.; Davis, E.; and Ortiz, C. L. 2016. Planning, executing, and evaluating the winograd schema challenge. AI Magazine 37(1):50–54. Niven, T., and Kao, H.-Y. 2019. Probing neural network comprehension of natural language arguments. ACL. Peng, H.; Khashabi, D.; and Roth, D. 2015. Solving hard coreference problems. NAACL. Poliak, A.; Naradowsky, J.; Haldar, A.; Rudinger, R.; and Van Durme, B. 2018. Hypothesis only baselines in natural language inference. *SEM. Radford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.; and Sutskever, I. 2019. Language models are unsupervised multitask learners. OpenAI Blog. Rahman, A., and Ng, V. 2012. Resolving complex cases of deﬁnite pronouns: The winograd schema challenge. EMNLPCoNLL. Ratinov, L., and Roth, D. 2012. Learning-based multi-sieve co-reference resolution with knowledge. EMNLP-CoNLL. Roemmele,M.;Bejan,C.A.;andGordon,A.S. 2011. Choice of plausible alternatives: An evaluation of commonsense causal reasoning. AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning. Rudinger, R.; Naradowsky, J.; Leonard, B.; and Van Durme, B. 2018. Gender bias in coreference resolution. NAACL. Sasaki, S.; Takase, S.; Inoue, N.; Okazaki, N.; and Inui, K. 2017. Handling multiword expressions in causality estimation. IWCS. Stokes, P. D. 2005. Creativity from constraints: The psychology of breakthrough. Springer Publishing Company. Trichelair, P.; Emami, A.; Cheung, J. C. K.; Trischler, A.; Suleman, K.; and Diaz, F. 2018. On the evaluation of common-sense reasoning in natural language understanding. arXiv:1811.01778. Trinh, T. H., and Le, Q. V. 2018. A simple method for commonsense reasoning. arXiv:1806.02847. Tsuchiya, M. 2018. Performance impact caused by hidden bias of training data for recognizing textual entailment. LREC. Turing, A. M. 1950. Computing machinery and intelligence. Mind. Wang, A.; Pruksachatkun, Y.; Nangia, N.; Singh, A.; Michael, J.; Hill, F.; Levy, O.; and Bowman, S. R. 2019. Superglue: A stickier benchmark for general-purpose language understanding systems. arXiv:1905.00537. Zellers, R.; Bisk, Y.; Schwartz, R.; and Choi, Y. 2018. Swag: A large-scale adversarial dataset for grounded commonsense inference. EMNLP. Zheng, J.; Vilnis, L.; Singh, S.; Choi, J. D.; and McCallum, A. 2013. Dynamic knowledge-base alignment for coreference resolution. CoNLL."
    ]
}