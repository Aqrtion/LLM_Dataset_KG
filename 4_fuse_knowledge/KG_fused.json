{
    "entities": [
        {
            "id": "20250318214228P1",
            "name": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Alex Wang",
                    "Amanpreet Singh",
                    "Julian Michael",
                    "Felix Hill",
                    "Omer Levy",
                    "Samuel R. Bowman"
                ],
                "institutions": [
                    "New York University",
                    "University of Washington",
                    "DeepMind"
                ]
            }
        },
        {
            "id": "20250318214228D1",
            "name": "GLUE",
            "type": "Dataset",
            "attributes": {
                "number_of_tasks": 9,
                "domains": [
                    "diverse"
                ],
                "diagnostic_suite": "included"
            }
        },
        {
            "id": "20250318214228D2",
            "name": "CoLA",
            "type": "Dataset",
            "attributes": {
                "size": "8.5k train, 1k test",
                "task": "acceptability classification",
                "metrics": "Matthews correlation",
                "domain": "miscellaneous"
            }
        },
        {
            "id": "20250318214228D3",
            "name": "SST-2",
            "type": "Dataset",
            "attributes": {
                "size": "67k train, 1.8k test",
                "task": "sentiment analysis",
                "metrics": "accuracy",
                "domain": "movie reviews"
            }
        },
        {
            "id": "20250318214228D4",
            "name": "MRPC",
            "type": "Dataset",
            "attributes": {
                "size": "3.7k train, 1.7k test",
                "task": "paraphrase detection",
                "metrics": "accuracy/F1",
                "domain": "news"
            }
        },
        {
            "id": "20250318214228D5",
            "name": "STS-B (Semantic Textual Similarity Benchmark)",
            "type": "Dataset",
            "attributes": {
                "size": "7k train, 1.4k test",
                "task": "sentence similarity",
                "metrics": "Pearson/Spearman correlation",
                "domain": "miscellaneous"
            }
        },
        {
            "id": "20250318214228D6",
            "name": "QQP (Quora Question Pairs)",
            "type": "Dataset",
            "attributes": {
                "size": "364k train, 391k test",
                "task": "paraphrase detection",
                "metrics": "accuracy/F1",
                "domain": "social"
            }
        },
        {
            "id": "20250318214228D7",
            "name": "MNLI (Multi-Genre Natural Language Inference Corpus)",
            "type": "Dataset",
            "attributes": {
                "size": "393k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "multiple"
            }
        },
        {
            "id": "20250318214228D8",
            "name": "QNLI (Question-answering NLI)",
            "type": "Dataset",
            "attributes": {
                "size": "105k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "Wikipedia"
            }
        },
        {
            "id": "20250318214228D9",
            "name": "RTE (Recognizing Textual Entailment)",
            "type": "Dataset",
            "attributes": {
                "size": "2.5k train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "news, Wikipedia"
            }
        },
        {
            "id": "20250318214228D10",
            "name": "WNLI (Winograd NLI)",
            "type": "Dataset",
            "attributes": {
                "size": "634 train",
                "task": "textual entailment",
                "metrics": "accuracy",
                "domain": "fiction"
            }
        },
        {
            "id": "20250318214228D11",
            "name": "SNLI (Stanford Natural Language Inference)",
            "type": "Dataset",
            "attributes": {
                "size": "550k examples",
                "task": "textual entailment"
            }
        },
        {
            "id": "20250318214228D12",
            "name": "GLUE Diagnostic Dataset",
            "type": "Dataset",
            "attributes": {
                "purpose": "linguistic analysis",
                "phenomena": [
                    "lexical semantics",
                    "predicate-argument structure",
                    "logic",
                    "knowledge"
                ]
            }
        },
        {
            "id": "20250318214228R1",
            "name": "https://gluebenchmark.com",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318214228T1",
            "name": "natural language understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T2",
            "name": "sentiment analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T3",
            "name": "textual entailment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T4",
            "name": "paraphrase detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T5",
            "name": "sentence similarity",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T6",
            "name": "acceptability classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T7",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318214228T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319084652P1",
            "name": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Richard Socher",
                    "Alex Perelygin",
                    "Jean Y. Wu",
                    "Jason Chuang",
                    "Christopher D. Manning",
                    "Andrew Y. Ng",
                    "Christopher Potts"
                ],
                "institution": "Stanford University"
            }
        },
        {
            "id": "20250319084652D1",
            "name": "Stanford Sentiment Treebank",
            "type": "Dataset",
            "attributes": {
                "size": "11,855 sentences",
                "phrases": "215,154 phrases",
                "annotation_method": "Amazon Mechanical Turk",
                "granularity": "5-class sentiment labels",
                "based_on": "Pang and Lee (2005) dataset"
            }
        },
        {
            "id": "20250319084652R1",
            "name": "http://nlp.stanford.edu/sentiment",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319084652T1",
            "name": "sentiment detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319084652T2",
            "name": "sentiment classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319084652T3",
            "name": "negation detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319084652T4",
            "name": "contrastive conjunction analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007P1",
            "name": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Adina Williams",
                    "Nikita Nangia",
                    "Samuel R. Bowman"
                ],
                "institution": "New York University"
            }
        },
        {
            "id": "20250318222007D1",
            "name": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "type": "Dataset",
            "attributes": {
                "size": "433k examples",
                "genres": "10 distinct genres",
                "comparison": "more diverse and difficult than SNLI",
                "license": "OANC’s license, Creative Commons licenses"
            }
        },
        {
            "id": "20250318222007D2",
            "name": "Stanford NLI Corpus (SNLI)",
            "type": "Dataset",
            "attributes": {
                "size": "570k examples",
                "source": "image captions"
            }
        },
        {
            "id": "20250318222007R1",
            "name": "https://nyu.edu/projects/bowman/multinli/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318222007L1",
            "name": "OANC’s license",
            "type": "License",
            "attributes": {
                "type": "permissive"
            }
        },
        {
            "id": "20250318222007L2",
            "name": "Creative Commons Attribution 3.0 Unported",
            "type": "License",
            "attributes": {
                "abbreviation": "CC BY 3.0"
            }
        },
        {
            "id": "20250318222007L3",
            "name": "Creative Commons Share-Alike 3.0 Unported",
            "type": "License",
            "attributes": {
                "abbreviation": "CC SA 3.0"
            }
        },
        {
            "id": "20250318222007T1",
            "name": "natural language inference (NLI)",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007T2",
            "name": "recognizing textual entailment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007T3",
            "name": "cross-genre domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007T4",
            "name": "transfer learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007T5",
            "name": "sentence understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318222007T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609P1",
            "name": "MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Dan Hendrycks",
                    "Collin Burns",
                    "Steven Basart",
                    "Andy Zou",
                    "Mantas Mazeika",
                    "Dawn Song",
                    "Jacob Steinhardt"
                ],
                "conference": "ICLR 2021"
            }
        },
        {
            "id": "20250318223609D1",
            "name": "Massive Multitask Test",
            "type": "Dataset",
            "attributes": {
                "tasks": 57,
                "subjects": [
                    "STEM",
                    "humanities",
                    "social sciences",
                    "law",
                    "ethics"
                ],
                "question_sources": [
                    "GRE",
                    "USMLE",
                    "Oxford University Press",
                    "Examination for Professional Practice in Psychology"
                ],
                "format": "multiple-choice"
            }
        },
        {
            "id": "20250318223609D2",
            "name": "HellaSwag",
            "type": "Dataset",
            "attributes": {
                "task_type": "commonsense reasoning"
            }
        },
        {
            "id": "20250318223609D3",
            "name": "Physical IQA",
            "type": "Dataset",
            "attributes": {
                "task_type": "physical commonsense reasoning"
            }
        },
        {
            "id": "20250318223609D4",
            "name": "Cosmos QA",
            "type": "Dataset",
            "attributes": {
                "task_type": "reading comprehension"
            }
        },
        {
            "id": "20250318223609D5",
            "name": "ETHICS dataset",
            "type": "Dataset",
            "attributes": {
                "focus": "moral intuitions"
            }
        },
        {
            "id": "20250318223609D6",
            "name": "GLUE",
            "type": "Dataset",
            "attributes": {
                "purpose": "general language understanding evaluation"
            }
        },
        {
            "id": "20250318223609D7",
            "name": "SuperGLUE",
            "type": "Dataset",
            "attributes": {
                "purpose": "advanced language understanding evaluation"
            }
        },
        {
            "id": "20250318223609D8",
            "name": "Harvard Law Library case law corpus",
            "type": "Dataset",
            "attributes": {
                "content": "legal case summaries"
            }
        },
        {
            "id": "20250318223609R1",
            "name": "github.com/hendrycks/test",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318223609T1",
            "name": "massive multitask language understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T2",
            "name": "zero-shot learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T3",
            "name": "few-shot learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T4",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T5",
            "name": "legal understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T6",
            "name": "moral intuition prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T7",
            "name": "history question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318223609T8",
            "name": "mathematics problem solving",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612P1",
            "name": "Natural Questions: A Benchmark for Question Answering Research",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Tom Kwiatkowski",
                    "Jennimaria Palomaki",
                    "Olivia Redfield",
                    "Michael Collins",
                    "Ankur Parikh",
                    "Chris Alberti",
                    "Danielle Epstein",
                    "Illia Polosukhin",
                    "Jacob Devlin",
                    "Kenton Lee",
                    "Kristina Toutanova",
                    "Llion Jones",
                    "Matthew Kelcey",
                    "Ming-Wei Chang",
                    "Andrew M. Dai",
                    "Jakob Uszkoreit",
                    "Quoc Le",
                    "Slav Petrov"
                ],
                "institution": "Google Research"
            }
        },
        {
            "id": "20250318225612D1",
            "name": "Natural Questions (NQ)",
            "type": "Dataset",
            "attributes": {
                "size": "307,373 training examples",
                "annotations": "5-way annotations",
                "components": [
                    "7,830 development examples",
                    "7,842 test examples"
                ],
                "task": "open-domain question answering"
            }
        },
        {
            "id": "20250318225612R1",
            "name": "https://ai.google.com/research/NaturalQuestions",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318225612T1",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T2",
            "name": "machine reading comprehension",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T3",
            "name": "answer extraction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T4",
            "name": "boolean question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T5",
            "name": "conversational QA",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T6",
            "name": "supporting facts identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612T7",
            "name": "Cloze-style tasks",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318225612D2",
            "name": "SQuAD",
            "type": "Dataset",
            "attributes": {
                "version": "1.0"
            }
        },
        {
            "id": "20250318225612D3",
            "name": "SQuAD 2.0",
            "type": "Dataset",
            "attributes": {
                "characteristic": "unanswerable questions"
            }
        },
        {
            "id": "20250318225612D4",
            "name": "NarrativeQA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250318225612D5",
            "name": "HotpotQA",
            "type": "Dataset",
            "attributes": {
                "purpose": "multi-hop reasoning"
            }
        },
        {
            "id": "20250318225612D6",
            "name": "QuAC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250318225612D7",
            "name": "CoQA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250318225612D8",
            "name": "WikiQA",
            "type": "Dataset",
            "attributes": {
                "size": "3,047 questions"
            }
        },
        {
            "id": "20250318225612D9",
            "name": "MS Marco",
            "type": "Dataset",
            "attributes": {
                "size": "100,000 questions"
            }
        },
        {
            "id": "20250318225612D10",
            "name": "DuReader",
            "type": "Dataset",
            "attributes": {
                "language": "Chinese"
            }
        },
        {
            "id": "20250318225612D11",
            "name": "TriviaQA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250318230205P1",
            "name": "A large annotated corpus for learning natural language inference",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Samuel R. Bowman",
                    "Gabor Angeli",
                    "Christopher Potts",
                    "Christopher D. Manning"
                ],
                "institution": "Stanford University"
            }
        },
        {
            "id": "20250318230205D1",
            "name": "Stanford Natural Language Inference (SNLI) corpus",
            "type": "Dataset",
            "attributes": {
                "size": "570,152 sentence pairs",
                "labels": [
                    "entailment",
                    "contradiction",
                    "neutral"
                ],
                "collection_method": "Amazon Mechanical Turk",
                "validation": "5 annotations per example",
                "public_availability": "freely available"
            }
        },
        {
            "id": "20250318230205D2",
            "name": "Recognizing Textual Entailment (RTE) challenge tasks",
            "type": "Dataset",
            "attributes": {
                "size": "fewer than a thousand examples each"
            }
        },
        {
            "id": "20250318230205D3",
            "name": "Sentences Involving Compositional Knowledge (SICK)",
            "type": "Dataset",
            "attributes": {
                "size": "4,500 training examples"
            }
        },
        {
            "id": "20250318230205D4",
            "name": "Denotation Graph",
            "type": "Dataset",
            "attributes": {
                "size": "millions of examples",
                "quality": "noisy"
            }
        },
        {
            "id": "20250318230205D5",
            "name": "Paraphrase Database",
            "type": "Dataset",
            "attributes": {
                "content": "entailment annotations over pairs of words/phrases"
            }
        },
        {
            "id": "20250318230205T1",
            "name": "natural language inference (NLI)",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T2",
            "name": "entailment detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T3",
            "name": "contradiction detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T4",
            "name": "semantic parsing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T5",
            "name": "commonsense reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T6",
            "name": "transfer learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T8",
            "name": "machine learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318230205T9",
            "name": "information retrieval",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318231601P1",
            "name": "Pointer Sentinel Mixture Models",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Stephen Merity",
                    "Caiming Xiong",
                    "James Bradbury",
                    "Richard Socher"
                ],
                "institution": "MetaMind - A Salesforce Company"
            }
        },
        {
            "id": "20250318231601D1",
            "name": "WikiText-2",
            "type": "Dataset",
            "attributes": {
                "size": "2 times Penn Treebank",
                "vocabulary": "larger than PTB",
                "structure": "articles with original casing/punctuation"
            }
        },
        {
            "id": "20250318231601D2",
            "name": "WikiText-103",
            "type": "Dataset",
            "attributes": {
                "size": "103 million words",
                "vocabulary": "extensive long-tail coverage",
                "structure": "full Wikipedia articles"
            }
        },
        {
            "id": "20250318231601D3",
            "name": "Penn Treebank (PTB)",
            "type": "Dataset",
            "attributes": {
                "preprocessing": "lower-cased, numbers replaced",
                "vocabulary_size": 10000
            }
        },
        {
            "id": "20250318231601R1",
            "name": "WikiText dataset site",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318231601T1",
            "name": "language modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318233629P1",
            "name": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Payal Bajaj",
                    "Daniel Campos",
                    "Nick Craswell",
                    "Li Deng",
                    "Jianfeng Gao",
                    "Xiaodong Liu",
                    "Rangan Majumder",
                    "Andrew McNamara",
                    "Bhaskar Mitra",
                    "Tri Nguyen",
                    "Mir Rosenberg",
                    "Xia Song",
                    "Alina Stoica",
                    "Saurabh Tiwary",
                    "Tong Wang"
                ],
                "institution": "Microsoft AI & Research"
            }
        },
        {
            "id": "20250318233629D1",
            "name": "MS MARCO",
            "type": "Dataset",
            "attributes": {
                "size": "1,010,916 questions, 8,841,823 passages",
                "answers": "human generated + 182,669 rewritten answers",
                "versions": [
                    "v1.0",
                    "v1.1",
                    "v2.0",
                    "v2.1"
                ],
                "source": "Bing/Cortana query logs",
                "question_types": [
                    "NUMERIC",
                    "ENTITY",
                    "LOCATION",
                    "PERSON",
                    "DESCRIPTION"
                ]
            }
        },
        {
            "id": "20250318233629D2",
            "name": "SQuAD (Stanford Question Answering Dataset)",
            "type": "Dataset",
            "attributes": {
                "size": "107,785 question-answer pairs",
                "answer_type": "text spans"
            }
        },
        {
            "id": "20250318233629D3",
            "name": "NewsQA",
            "type": "Dataset",
            "attributes": {
                "size": "100,000+ question-answer pairs",
                "source": "CNN news articles"
            }
        },
        {
            "id": "20250318233629D4",
            "name": "DuReader",
            "type": "Dataset",
            "attributes": {
                "language": "Chinese",
                "size": "200,000 questions"
            }
        },
        {
            "id": "20250318233629D5",
            "name": "NarrativeQA",
            "type": "Dataset",
            "attributes": {
                "content_type": "movie scripts/books",
                "size": "45,000 question-answer pairs"
            }
        },
        {
            "id": "20250318233629D6",
            "name": "SearchQA",
            "type": "Dataset",
            "attributes": {
                "source": "Jeopardy! questions",
                "size": "140K+ question-answer pairs"
            }
        },
        {
            "id": "20250318233629D7",
            "name": "RACE",
            "type": "Dataset",
            "attributes": {
                "language": "English",
                "question_type": "multiple choice"
            }
        },
        {
            "id": "20250318233629D8",
            "name": "ReCoRD",
            "type": "Dataset",
            "attributes": {
                "task": "Cloze-style QA",
                "size": "12,000 question-passage pairs"
            }
        },
        {
            "id": "20250318233629D9",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "1.5 million labeled examples",
                "categories": 1000
            }
        },
        {
            "id": "20250318233629T1",
            "name": "answerability prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318233629T2",
            "name": "natural language answer generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318233629T3",
            "name": "passage ranking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155P1",
            "name": "Evaluating Large Language Models Trained on Code",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Mark Chen",
                    "Jerry Tworek",
                    "Heewoo Jun",
                    "Qiming Yuan",
                    "Henrique Ponde de Oliveira Pinto",
                    "Jared Kaplan",
                    "et al."
                ],
                "institution": "OpenAI"
            }
        },
        {
            "id": "20250318235155D1",
            "name": "HumanEval",
            "type": "Dataset",
            "attributes": {
                "size": "164 problems",
                "tests_per_problem": "average 7.7",
                "purpose": "measuring functional correctness for program synthesis"
            }
        },
        {
            "id": "20250318235155D2",
            "name": "APPS",
            "type": "Dataset",
            "attributes": {
                "size": "5000 training and 5000 test examples",
                "content": "coding problems from Codeforces"
            }
        },
        {
            "id": "20250318235155D3",
            "name": "The Pile",
            "type": "Dataset",
            "attributes": {
                "size": "800GB",
                "content": "diverse text including 8% GitHub code"
            }
        },
        {
            "id": "20250318235155D4",
            "name": "CodeSearchNet",
            "type": "Dataset",
            "attributes": {
                "content": "multi-language code corpus from GitHub"
            }
        },
        {
            "id": "20250318235155D5",
            "name": "CodeXGLUE",
            "type": "Dataset",
            "attributes": {
                "purpose": "aggregated programming benchmarks"
            }
        },
        {
            "id": "20250318235155D6",
            "name": "FlashFill",
            "type": "Dataset",
            "attributes": {
                "domain": "program synthesis benchmarks"
            }
        },
        {
            "id": "20250318235155R1",
            "name": "https://www.github.com/openai/human-eval",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318235155T1",
            "name": "program synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155T2",
            "name": "code generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155T3",
            "name": "functional correctness evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155T4",
            "name": "docstring generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155T5",
            "name": "code autocompletion",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235155T6",
            "name": "code understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921P1",
            "name": "Measuring Mathematical Problem Solving With the MATH Dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Dan Hendrycks",
                    "Collin Burns",
                    "Saurav Kadavath",
                    "Akul Arora",
                    "Steven Basart",
                    "Eric Tang",
                    "Dawn Song",
                    "Jacob Steinhardt"
                ],
                "institutions": [
                    "UC Berkeley",
                    "UChicago"
                ],
                "conference": "NeurIPS 2021"
            }
        },
        {
            "id": "20250318235921D1",
            "name": "MATH",
            "type": "Dataset",
            "attributes": {
                "size": "12,500 problems",
                "subjects": [
                    "geometry",
                    "algebra",
                    "number theory",
                    "counting & probability",
                    "intermediate algebra",
                    "precalculus",
                    "prealgebra"
                ],
                "difficulty_levels": 5,
                "answer_normalization": "unique after normalization",
                "step-by-step_solutions": "included"
            }
        },
        {
            "id": "20250318235921D2",
            "name": "AMPS (Auxiliary Mathematics Problems and Solutions)",
            "type": "Dataset",
            "attributes": {
                "size": "23GB",
                "sources": [
                    "Khan Academy",
                    "Mathematica scripts"
                ],
                "problems": "over 5 million",
                "step-by-step_solutions": "included"
            }
        },
        {
            "id": "20250318235921D3",
            "name": "DeepMind Mathematics Dataset",
            "type": "Dataset",
            "attributes": {
                "content": "algorithmically generated plug-and-chug problems"
            }
        },
        {
            "id": "20250318235921R1",
            "name": "https://github.com/hendrycks/apps",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250318235921L1",
            "name": "MIT License",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250318235921T1",
            "name": "mathematical problem solving",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T2",
            "name": "theorem proving",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T3",
            "name": "answer generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T4",
            "name": "pretraining models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T5",
            "name": "automatic answer assessment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T6",
            "name": "step-by-step solution generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250318235921T8",
            "name": "plug-and-chug calculations",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713P1",
            "name": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Mandar Joshi",
                    "Eunsol Choi",
                    "Daniel S. Weld",
                    "Luke Zettlemoyer"
                ],
                "institution": "University of Washington, Allen Institute for Artificial Intelligence"
            }
        },
        {
            "id": "20250319001713D1",
            "name": "TriviaQA",
            "type": "Dataset",
            "attributes": {
                "size": "650K question-answer-evidence triples",
                "questions": "95K question-answer pairs",
                "evidence_documents_per_question": 6,
                "answer_types": [
                    "Wikipedia titles",
                    "numerical expressions",
                    "noun phrases",
                    "verb phrases"
                ],
                "coverage": "diverse topics via WordNet synsets"
            }
        },
        {
            "id": "20250319001713D2",
            "name": "SQuAD (Rajpurkar et al., 2016)",
            "type": "Dataset",
            "attributes": {
                "size": "100K questions"
            }
        },
        {
            "id": "20250319001713D3",
            "name": "MS Marco (Nguyen et al., 2016)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D4",
            "name": "NewsQA (Trischler et al., 2016)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D5",
            "name": "WikiQA (Yang et al., 2015)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D6",
            "name": "TREC (Voorhees and Tice, 2000)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D7",
            "name": "SearchQA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D8",
            "name": "WebQA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713D9",
            "name": "MCTest",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319001713R1",
            "name": "http://nlp.cs.washington.edu/triviaqa/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319001713T1",
            "name": "reading comprehension",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T2",
            "name": "open domain question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T3",
            "name": "answer sentence selection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T4",
            "name": "answer phrase extraction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T5",
            "name": "knowledge base question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T6",
            "name": "IR-style question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T7",
            "name": "machine reading",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319001713T8",
            "name": "training machine reading systems",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031P1",
            "name": "From Image Descriptions to Visual Denotations: New Similarity Metrics for Semantic Inference over Event Descriptions",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Peter Young",
                    "Alice Lai",
                    "Micah Hodosh",
                    "Julia Hockenmaier"
                ],
                "institution": "University of Illinois at Urbana-Champaign"
            }
        },
        {
            "id": "20250319002031D1",
            "name": "Image Description Corpus",
            "type": "Dataset",
            "attributes": {
                "size": "31,783 images, 158,915 captions",
                "collection_method": "crowdsourcing",
                "license": "Creative Commons",
                "extends": "Hodosh et al. (2013) Corpus"
            }
        },
        {
            "id": "20250319002031D2",
            "name": "Hodosh et al. (2013) Corpus",
            "type": "Dataset",
            "attributes": {
                "size": "8,092 images"
            }
        },
        {
            "id": "20250319002031D3",
            "name": "MSR Video Description Corpus",
            "type": "Dataset",
            "attributes": {
                "size": "1500 sentence pairs"
            }
        },
        {
            "id": "20250319002031D4",
            "name": "SBU Captioned Photo Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1 million images"
            }
        },
        {
            "id": "20250319002031D5",
            "name": "IAPR TC-12 dataset",
            "type": "Dataset",
            "attributes": {
                "description": "longer descriptions"
            }
        },
        {
            "id": "20250319002031R1",
            "name": "http://nlp.cs.illinois.edu/Denotation.html",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319002031L1",
            "name": "Creative Commons",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319002031T1",
            "name": "semantic inference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T2",
            "name": "approximate entailment recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T3",
            "name": "Semantic Textual Similarity (STS)",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T4",
            "name": "paraphrase detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T5",
            "name": "image understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T6",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T7",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T8",
            "name": "automatic object clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T9",
            "name": "object localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T10",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T11",
            "name": "part models learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T12",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T13",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002031T14",
            "name": "image search",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611P1",
            "name": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Robyn Speer",
                    "Joshua Chin",
                    "Catherine Havasi"
                ],
                "institutions": [
                    "Luminoso Technologies, Inc.",
                    "Union College"
                ]
            }
        },
        {
            "id": "20250319002611D1",
            "name": "ConceptNet 5.5",
            "type": "Dataset",
            "attributes": {
                "size": "21 million edges, 8 million nodes",
                "languages": 83,
                "sources": [
                    "Open Mind Common Sense",
                    "Wiktionary",
                    "Open Multilingual WordNet",
                    "DBPedia",
                    "JMDict",
                    "OpenCyc"
                ],
                "structure": "knowledge graph"
            }
        },
        {
            "id": "20250319002611D2",
            "name": "ConceptNet 5.2",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D3",
            "name": "WordNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D4",
            "name": "Open Multilingual WordNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D5",
            "name": "DBPedia",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D6",
            "name": "OpenCyc",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D7",
            "name": "JMDict",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D8",
            "name": "Wiktionary",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D9",
            "name": "Open Mind Common Sense (OMCS)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319002611D10",
            "name": "ConceptNet Numberbatch 16.09",
            "type": "Dataset",
            "attributes": {
                "version": "16.09",
                "components": [
                    "ConceptNet 5.5",
                    "word2vec",
                    "GloVe"
                ]
            }
        },
        {
            "id": "20250319002611R1",
            "name": "http://conceptnet.io",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319002611R2",
            "name": "https://github.com/commonsense/conceptnet5",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319002611R3",
            "name": "https://github.com/commonsense/conceptnet-numberbatch",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319002611T1",
            "name": "word relatedness evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T2",
            "name": "solving SAT-style analogies",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T3",
            "name": "natural language processing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T4",
            "name": "machine learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T5",
            "name": "semantic space construction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T6",
            "name": "multilingual embedding propagation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T7",
            "name": "training word embeddings",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319002611T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319003755P1",
            "name": "HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Zhilin Yang",
                    "Peng Qi",
                    "Saizheng Zhang",
                    "Yoshua Bengio",
                    "William W. Cohen",
                    "Ruslan Salakhutdinov",
                    "Christopher D. Manning"
                ],
                "institutions": [
                    "Carnegie Mellon University",
                    "Stanford University",
                    "Mila, Université de Montréal",
                    "Google AI"
                ]
            }
        },
        {
            "id": "20250319003755D1",
            "name": "HOTPOTQA",
            "type": "Dataset",
            "attributes": {
                "size": "113k question-answer pairs",
                "features": [
                    "multi-hop reasoning",
                    "diverse question types",
                    "sentence-level supporting facts",
                    "factoid comparison questions"
                ],
                "context_source": "Wikipedia articles",
                "answer_types": [
                    "entities",
                    "dates",
                    "numbers",
                    "adjectives",
                    "yes/no comparisons"
                ]
            }
        },
        {
            "id": "20250319003755R1",
            "name": "https://HotpotQA.github.io",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319003755T1",
            "name": "multi-hop question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319003755T2",
            "name": "explainable reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319003755T3",
            "name": "factoid comparison questions",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319003755D2",
            "name": "SQuAD",
            "type": "Dataset",
            "attributes": {
                "context_type": "single paragraph",
                "reasoning_type": "single-hop"
            }
        },
        {
            "id": "20250319003755D3",
            "name": "TriviaQA",
            "type": "Dataset",
            "attributes": {
                "context_source": "information retrieval documents"
            }
        },
        {
            "id": "20250319003755D4",
            "name": "SearchQA",
            "type": "Dataset",
            "attributes": {
                "context_source": "Jeopardy! questions and answers"
            }
        },
        {
            "id": "20250319003755D5",
            "name": "QAngaroo",
            "type": "Dataset",
            "attributes": {
                "base": "knowledge bases",
                "reasoning_type": "multi-hop"
            }
        },
        {
            "id": "20250319003755D6",
            "name": "ComplexWebQuestions",
            "type": "Dataset",
            "attributes": {
                "base": "knowledge bases"
            }
        },
        {
            "id": "20250319003755D7",
            "name": "MS MARCO",
            "type": "Dataset",
            "attributes": {
                "answer_type": "free-form generation"
            }
        },
        {
            "id": "20250319004155P1",
            "name": "Automatically Constructing a Corpus of Sentential Paraphrases",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "William B. Dolan",
                    "Chris Brockett"
                ],
                "institution": "Microsoft Research"
            }
        },
        {
            "id": "20250319004155D1",
            "name": "Microsoft Research Paraphrase Corpus (MSRP)",
            "type": "Dataset",
            "attributes": {
                "size": "5801 sentence pairs",
                "labeling": "human-judged binary paraphrase judgments",
                "collection_method": "heuristic extraction + SVM classifier",
                "lexical_overlap": "mean 0.7"
            }
        },
        {
            "id": "20250319004155D2",
            "name": "ATR English-Chinese paraphrase corpus",
            "type": "Dataset",
            "attributes": {
                "domain": "travel phrases",
                "content_type": "short handcrafted predicates"
            }
        },
        {
            "id": "20250319004155D3",
            "name": "Multiple-Translation Chinese Corpus",
            "type": "Dataset",
            "attributes": {
                "publisher": "Linguistic Data Consortium",
                "quality_note": "translation quality issues"
            }
        },
        {
            "id": "20250319004155D4",
            "name": "WordNet",
            "type": "Dataset",
            "attributes": {
                "content": "314,924 word synonyms/hypernym pairs"
            }
        },
        {
            "id": "20250319004155R1",
            "name": "http://research.microsoft.com/research/nlp/msr_paraphrase.htm",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319004155T1",
            "name": "paraphrase identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004155T2",
            "name": "paraphrase generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004155T3",
            "name": "training machine learning models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004155T4",
            "name": "evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004350P1",
            "name": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Erik F. Tjong Kim Sang",
                    "Fien De Meulder"
                ],
                "institution": "University of Antwerp"
            }
        },
        {
            "id": "20250319004350T1",
            "name": "language-independent named entity recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004350T2",
            "name": "named entity recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004350D1",
            "name": "CoNLL-2003 English Dataset",
            "type": "Dataset",
            "attributes": {
                "components": "training, development, test, unannotated",
                "unannotated_data_size": "17 million tokens",
                "annotation_scheme": "IOB with PER, ORG, LOC, MISC",
                "preprocessing": "tokenized, POS tagged, chunked using MBT tagger",
                "source": "Reuters Corpus"
            }
        },
        {
            "id": "20250319004350D2",
            "name": "CoNLL-2003 German Dataset",
            "type": "Dataset",
            "attributes": {
                "components": "training, development, test, unannotated",
                "unannotated_data_size": "14 million tokens",
                "annotation_scheme": "IOB with PER, ORG, LOC, MISC",
                "preprocessing": "lemmatized, tagged, chunked using TreeTagger",
                "source": "ECI Multilingual Text Corpus"
            }
        },
        {
            "id": "20250319004350D3",
            "name": "Reuters Corpus",
            "type": "Dataset",
            "attributes": {
                "content": "Reuters news stories between August 1996 and August 1997"
            }
        },
        {
            "id": "20250319004350D4",
            "name": "ECI Multilingual Text Corpus",
            "type": "Dataset",
            "attributes": {
                "content": "German newspaper Frankfurter Rundshau articles from August 1992"
            }
        },
        {
            "id": "20250319004350D5",
            "name": "CoNLL-2002 Dataset",
            "type": "Dataset",
            "attributes": {
                "languages": "Spanish, Dutch",
                "task": "named entity recognition"
            }
        },
        {
            "id": "20250319004913P1",
            "name": "Neural Network Acceptability Judgments",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Alex Warstadt",
                    "Amanpreet Singh",
                    "Samuel R. Bowman"
                ],
                "institution": "New York University"
            }
        },
        {
            "id": "20250319004913D1",
            "name": "Corpus of Linguistic Acceptability (CoLA)",
            "type": "Dataset",
            "attributes": {
                "size": "10,657 sentences",
                "labels": "grammatical/ungrammatical",
                "sources": "linguistics literature",
                "splits": "in-domain, out-of-domain"
            }
        },
        {
            "id": "20250319004913D2",
            "name": "British National Corpus (BNC)",
            "type": "Dataset",
            "attributes": {
                "size": "100 million tokens",
                "language": "English"
            }
        },
        {
            "id": "20250319004913R1",
            "name": "https://nyu-mll.github.io/CoLA/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319004913T1",
            "name": "acceptability classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T2",
            "name": "grammatical knowledge evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T3",
            "name": "unsupervised language modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T4",
            "name": "transfer learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T5",
            "name": "syntactic and semantic phenomena analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T6",
            "name": "real/fake sentence discrimination",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319004913T7",
            "name": "language model pretraining",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248P1",
            "name": "PIQA: Reasoning about Physical Commonsense in Natural Language",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Yonatan Bisk",
                    "Rowan Zellers",
                    "Ronan Le Bras",
                    "Jianfeng Gao",
                    "Yejin Choi"
                ],
                "institutions": [
                    "Allen Institute for Artificial Intelligence",
                    "Microsoft Research AI",
                    "University of Washington"
                ]
            }
        },
        {
            "id": "20250319005248D1",
            "name": "PIQA",
            "type": "Dataset",
            "attributes": {
                "size": "16,000 training QA pairs",
                "purpose": "physical commonsense reasoning",
                "collection_method": "instructables.com inspiration + Amazon Mechanical Turk",
                "validation": "AFLite adversarial filtering",
                "metrics": "human accuracy: 95%, model accuracy: ~77%"
            }
        },
        {
            "id": "20250319005248R1",
            "name": "http://yonatanbisk.com/piqa",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319005248T1",
            "name": "physical commonsense reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248T2",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248T3",
            "name": "problem solving",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248T4",
            "name": "natural language understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248T5",
            "name": "tool usage understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005248T6",
            "name": "benchmarking language models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543P1",
            "name": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Drew A. Hudson",
                    "Christopher D. Manning"
                ],
                "institution": "Stanford University"
            }
        },
        {
            "id": "20250319005543D1",
            "name": "GQA",
            "type": "Dataset",
            "attributes": {
                "size": "22M questions",
                "images": "113,018",
                "composition": "Visual Genome scene graphs",
                "features": "functional programs, balanced answer distribution",
                "metrics": [
                    "consistency",
                    "validity",
                    "plausibility",
                    "grounding",
                    "distribution"
                ]
            }
        },
        {
            "id": "20250319005543D2",
            "name": "Visual Genome",
            "type": "Dataset",
            "attributes": {
                "description": "scene graph annotations",
                "source": "COCO and Flickr images"
            }
        },
        {
            "id": "20250319005543D3",
            "name": "COCO",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319005543D4",
            "name": "Flickr",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319005543D5",
            "name": "CLEVR",
            "type": "Dataset",
            "attributes": {
                "description": "synthetic images with compositional questions"
            }
        },
        {
            "id": "20250319005543D6",
            "name": "VQA 2.0",
            "type": "Dataset",
            "attributes": {
                "description": "real-world images with unbalanced answer distribution"
            }
        },
        {
            "id": "20250319005543R1",
            "name": "visualreasoning.net",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319005543T1",
            "name": "visual reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T2",
            "name": "compositional question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T3",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T4",
            "name": "attribute recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T5",
            "name": "spatial reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T6",
            "name": "logical inference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T7",
            "name": "comparisons",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T9",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319005543T10",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018P1",
            "name": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Justin Johnson",
                    "Li Fei-Fei",
                    "Bharath Hariharan",
                    "C. Lawrence Zitnick",
                    "Laurens van der Maaten",
                    "Ross Girshick"
                ],
                "institutions": [
                    "Stanford University",
                    "Facebook AI Research"
                ]
            }
        },
        {
            "id": "20250319010018D1",
            "name": "CLEVR",
            "type": "Dataset",
            "attributes": {
                "size": "100,000 images",
                "questions": "1 million (853k unique)",
                "content": "3D shapes (cube, sphere, cylinder)",
                "attributes": [
                    "size",
                    "color",
                    "material",
                    "spatial relationships"
                ],
                "synthetic": "true",
                "question_types": [
                    "attribute query",
                    "counting",
                    "comparison",
                    "logical operations"
                ]
            }
        },
        {
            "id": "20250319010018D2",
            "name": "VQA",
            "type": "Dataset",
            "attributes": {
                "description": "Visual Question Answering dataset",
                "content": "natural images",
                "question_types": "natural language questions"
            }
        },
        {
            "id": "20250319010018D3",
            "name": "SHAPES",
            "type": "Dataset",
            "attributes": {
                "questions": "15,616 total (244 unique)",
                "complexity": "lower than CLEVR"
            }
        },
        {
            "id": "20250319010018D4",
            "name": "DAQUAR",
            "type": "Dataset",
            "attributes": {
                "questions": "420 synthetic questions",
                "templates": "8 text templates"
            }
        },
        {
            "id": "20250319010018D5",
            "name": "SHRDLU",
            "type": "Dataset",
            "attributes": {
                "domain": "block world manipulation"
            }
        },
        {
            "id": "20250319010018D6",
            "name": "bAbI",
            "type": "Dataset",
            "attributes": {
                "focus": "text-based question answering"
            }
        },
        {
            "id": "20250319010018T1",
            "name": "visual question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T2",
            "name": "compositional reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T3",
            "name": "attribute comparison",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T4",
            "name": "counting",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T5",
            "name": "logical reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T6",
            "name": "image captioning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T7",
            "name": "referring to objects",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T8",
            "name": "relational graph prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010018T9",
            "name": "visual Turing tests",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509P1",
            "name": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Christopher Clark",
                    "Kenton Lee",
                    "Ming-Wei Chang",
                    "Tom Kwiatkowski",
                    "Michael Collins",
                    "Kristina Toutanova"
                ],
                "institution": "Google AI Language, University of Washington"
            }
        },
        {
            "id": "20250319010509D1",
            "name": "BoolQ",
            "type": "Dataset",
            "attributes": {
                "size": "16,000 questions",
                "source": "Wikipedia",
                "annotation_method": "Amazon Mechanical Turk",
                "answer_accuracy": "90% human accuracy"
            }
        },
        {
            "id": "20250319010509D2",
            "name": "MultiNLI",
            "type": "Dataset",
            "attributes": {
                "purpose": "natural language inference"
            }
        },
        {
            "id": "20250319010509D3",
            "name": "SNLI",
            "type": "Dataset",
            "attributes": {
                "purpose": "natural language inference"
            }
        },
        {
            "id": "20250319010509D4",
            "name": "SQuAD 1.1",
            "type": "Dataset",
            "attributes": {
                "type": "extractive QA"
            }
        },
        {
            "id": "20250319010509D5",
            "name": "SQuAD 2.0",
            "type": "Dataset",
            "attributes": {
                "type": "adversarial extractive QA"
            }
        },
        {
            "id": "20250319010509D6",
            "name": "RACE",
            "type": "Dataset",
            "attributes": {
                "type": "multiple-choice QA"
            }
        },
        {
            "id": "20250319010509D7",
            "name": "QQP",
            "type": "Dataset",
            "attributes": {
                "purpose": "paraphrase detection"
            }
        },
        {
            "id": "20250319010509D8",
            "name": "MS Marco",
            "type": "Dataset",
            "attributes": {
                "class_balance": "80% yes answers"
            }
        },
        {
            "id": "20250319010509D9",
            "name": "QuAC",
            "type": "Dataset",
            "attributes": {
                "focus": "conversational QA"
            }
        },
        {
            "id": "20250319010509D10",
            "name": "CoQA",
            "type": "Dataset",
            "attributes": {
                "focus": "conversational QA"
            }
        },
        {
            "id": "20250319010509D11",
            "name": "HotPotQA",
            "type": "Dataset",
            "attributes": {
                "focus": "multi-step reasoning"
            }
        },
        {
            "id": "20250319010509D12",
            "name": "ShARC",
            "type": "Dataset",
            "attributes": {
                "focus": "conversational QA"
            }
        },
        {
            "id": "20250319010509R1",
            "name": "https://goo.gl/boolq",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319010509T1",
            "name": "yes/no question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T2",
            "name": "natural language inference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T3",
            "name": "entailment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T4",
            "name": "paraphrasing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T5",
            "name": "extractive QA",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T6",
            "name": "multiple-choice QA",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T7",
            "name": "adversarial question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T8",
            "name": "reading comprehension",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T9",
            "name": "conversational QA",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010509T10",
            "name": "multi-step reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919P1",
            "name": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jun Xu",
                    "Tao Mei",
                    "Ting Yao",
                    "Yong Rui"
                ],
                "institution": "Microsoft Research"
            }
        },
        {
            "id": "20250319010919D1",
            "name": "MSR-VTT-10K",
            "type": "Dataset",
            "attributes": {
                "size": "10K web video clips",
                "duration": "41.2 hours",
                "clip-sentence pairs": "200K",
                "categories": 20,
                "sentences per clip": "~20",
                "annotation method": "Amazon Mechanical Turk (1,327 workers)",
                "content": "diverse video content from 20 categories",
                "audio": "includes audio channel"
            }
        },
        {
            "id": "20250319010919D2",
            "name": "YouCook",
            "type": "Dataset",
            "attributes": {
                "domain": "cooking",
                "annotation": "human-annotated descriptions"
            }
        },
        {
            "id": "20250319010919D3",
            "name": "TACoS",
            "type": "Dataset",
            "attributes": {
                "domain": "cooking",
                "features": "temporal alignment"
            }
        },
        {
            "id": "20250319010919D4",
            "name": "TACoS Multi-Level",
            "type": "Dataset",
            "attributes": {
                "domain": "cooking",
                "features": "multi-level descriptions"
            }
        },
        {
            "id": "20250319010919D5",
            "name": "M-VAD",
            "type": "Dataset",
            "attributes": {
                "domain": "movie",
                "annotation": "Audio Descriptions (AD)",
                "availability": "public"
            }
        },
        {
            "id": "20250319010919D6",
            "name": "MPII-MD",
            "type": "Dataset",
            "attributes": {
                "domain": "movie",
                "annotation": "scripts and AD",
                "availability": "public"
            }
        },
        {
            "id": "20250319010919D7",
            "name": "MSVD",
            "type": "Dataset",
            "attributes": {
                "size": "1,970 videos",
                "annotation": "AMT workers",
                "categories": "multiple"
            }
        },
        {
            "id": "20250319010919T1",
            "name": "translating video to text",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T2",
            "name": "video description generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T3",
            "name": "video summarization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T4",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T5",
            "name": "emotion recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T6",
            "name": "video to language",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319010919T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011523P1",
            "name": "DBpedia: A Nucleus for a Web of Open Data",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Sören Auer",
                    "Christian Bizer",
                    "Georgi Kobilarov",
                    "Jens Lehmann",
                    "Richard Cyganiak",
                    "Zachary Ives"
                ],
                "institutions": [
                    "Universität Leipzig",
                    "Freie Universität Berlin",
                    "University of Pennsylvania"
                ],
                "year": 2007
            }
        },
        {
            "id": "20250319011523D1",
            "name": "DBpedia",
            "type": "Dataset",
            "attributes": {
                "size": "103 million RDF triples",
                "coverage": "1.95 million concepts",
                "interlinked_datasets": [
                    "Geonames",
                    "US Census",
                    "MusicBrainz",
                    "Project Gutenberg",
                    "DBLP",
                    "RDF Book Mashup"
                ],
                "access_methods": [
                    "Linked Data",
                    "SPARQL endpoint",
                    "RDF dumps"
                ]
            }
        },
        {
            "id": "20250319011523D2",
            "name": "Geonames",
            "type": "Dataset",
            "attributes": {
                "purpose": "geographical database"
            }
        },
        {
            "id": "20250319011523D3",
            "name": "MusicBrainz",
            "type": "Dataset",
            "attributes": {
                "purpose": "music metadata"
            }
        },
        {
            "id": "20250319011523D4",
            "name": "DBLP",
            "type": "Dataset",
            "attributes": {
                "purpose": "computer science bibliography"
            }
        },
        {
            "id": "20250319011523R1",
            "name": "http://dbpedia.org/sparql",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319011523R2",
            "name": "http://dbpedia.org/resource/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319011523L1",
            "name": "GNU Free Documentation License",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319011523T1",
            "name": "information extraction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011523T2",
            "name": "data interlinking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011523T3",
            "name": "SPARQL querying",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011523T4",
            "name": "Semantic Web browsing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829P1",
            "name": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Todor Mihaylov",
                    "Peter Clark",
                    "Tushar Khot",
                    "Ashish Sabharwal"
                ],
                "institution": "Allen Institute for Artificial Intelligence, Heidelberg University"
            }
        },
        {
            "id": "20250319011829D1",
            "name": "OpenBookQA",
            "type": "Dataset",
            "attributes": {
                "size": "5957 questions",
                "core_facts": 1326,
                "question_type": "multiple-choice",
                "knowledge_sources": "ConceptNet, Wikipedia"
            }
        },
        {
            "id": "20250319011829D2",
            "name": "ConceptNet",
            "type": "Dataset",
            "attributes": {
                "type": "commonsense knowledge base"
            }
        },
        {
            "id": "20250319011829D3",
            "name": "SciTail",
            "type": "Dataset",
            "attributes": {
                "task": "textual entailment"
            }
        },
        {
            "id": "20250319011829D4",
            "name": "MCTest",
            "type": "Dataset",
            "attributes": {
                "task": "machine comprehension"
            }
        },
        {
            "id": "20250319011829D5",
            "name": "QAngaroo",
            "type": "Dataset",
            "attributes": {
                "task": "multi-hop reading comprehension"
            }
        },
        {
            "id": "20250319011829D6",
            "name": "NarrativeQA",
            "type": "Dataset",
            "attributes": {
                "task": "story understanding"
            }
        },
        {
            "id": "20250319011829D7",
            "name": "MultiRC",
            "type": "Dataset",
            "attributes": {
                "task": "multi-sentence reasoning"
            }
        },
        {
            "id": "20250319011829D8",
            "name": "Story Cloze Test",
            "type": "Dataset",
            "attributes": {
                "task": "story ending prediction"
            }
        },
        {
            "id": "20250319011829D9",
            "name": "MCScript",
            "type": "Dataset",
            "attributes": {
                "task": "script knowledge understanding"
            }
        },
        {
            "id": "20250319011829D10",
            "name": "ProPara",
            "type": "Dataset",
            "attributes": {
                "task": "process paragraph comprehension"
            }
        },
        {
            "id": "20250319011829D11",
            "name": "ARC Reasoning Challenge",
            "type": "Dataset",
            "attributes": {
                "task": "science question answering"
            }
        },
        {
            "id": "20250319011829R1",
            "name": "http://data.allenai.org/OpenBookQA",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319011829T1",
            "name": "open book question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T2",
            "name": "multi-hop reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T3",
            "name": "reading comprehension",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T4",
            "name": "textual entailment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T5",
            "name": "plausible answer detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T6",
            "name": "information retrieval",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T7",
            "name": "question answering over structured knowledge-bases",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T8",
            "name": "answerability verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T9",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319011829T10",
            "name": "scientific question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144P1",
            "name": "VoxCeleb2: Deep Speaker Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joon Son Chung",
                    "Arsha Nagrani",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319012144D1",
            "name": "VoxCeleb2",
            "type": "Dataset",
            "attributes": {
                "size": "1,128,246 utterances",
                "speakers": 6112,
                "conditions": "noisy/unconstrained",
                "multilingual": "145 nationalities",
                "modality": "audio-visual"
            }
        },
        {
            "id": "20250319012144D2",
            "name": "VoxCeleb1",
            "type": "Dataset",
            "attributes": {
                "reference": "Previous version"
            }
        },
        {
            "id": "20250319012144D3",
            "name": "SITW (Speakers in the Wild)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319012144D4",
            "name": "VGGFace2",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319012144D5",
            "name": "MS-Celeb-1M",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319012144D6",
            "name": "NFI-FRITS",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319012144D7",
            "name": "POLYCOST",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319012144R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319012144T1",
            "name": "speaker recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T2",
            "name": "speaker verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T3",
            "name": "speaker identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T4",
            "name": "clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T5",
            "name": "diarisation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T6",
            "name": "visual speech synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T7",
            "name": "speech separation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T8",
            "name": "cross-modal transfer",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T9",
            "name": "face recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012144T10",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012420P1",
            "name": "Pointer Sentinel Mixture Models",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Stephen Merity",
                    "Caiming Xiong",
                    "James Bradbury",
                    "Richard Socher"
                ],
                "institution": "MetaMind - A Salesforce Company"
            }
        },
        {
            "id": "20250319012420D1",
            "name": "Penn Treebank (PTB)",
            "type": "Dataset",
            "attributes": {
                "size": "929k training words",
                "vocabulary": "10k words",
                "preprocessing": "lower-cased, numbers replaced, punctuation removed"
            }
        },
        {
            "id": "20250319012420D2",
            "name": "WikiText-2",
            "type": "Dataset",
            "attributes": {
                "size": "2x Penn Treebank",
                "vocabulary": "larger than PTB",
                "structure": "articles with original casing/punctuation"
            }
        },
        {
            "id": "20250319012420D3",
            "name": "WikiText-103",
            "type": "Dataset",
            "attributes": {
                "size": "103 million words",
                "vocabulary": "full Wikipedia vocabulary",
                "structure": "articles with long-range dependencies"
            }
        },
        {
            "id": "20250319012420R1",
            "name": "WikiText dataset site",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319012420T1",
            "name": "language modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012420T2",
            "name": "word-level prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012420T3",
            "name": "handling rare or unseen words",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012630P1",
            "name": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Ramesh Nallapati",
                    "Bowen Zhou",
                    "Cicero dos Santos",
                    "Çağlar Gülçehre",
                    "Bing Xiang"
                ],
                "institutions": [
                    "IBM Watson",
                    "Université de Montréal"
                ]
            }
        },
        {
            "id": "20250319012630T1",
            "name": "abstractive text summarization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012630D1",
            "name": "DUC-2003",
            "type": "Dataset",
            "attributes": {
                "description": "competition data with human reference summaries"
            }
        },
        {
            "id": "20250319012630D2",
            "name": "DUC-2004",
            "type": "Dataset",
            "attributes": {
                "description": "competition data with human reference summaries"
            }
        },
        {
            "id": "20250319012630D3",
            "name": "Gigaword Corpus",
            "type": "Dataset",
            "attributes": {
                "size": "3.8M training examples",
                "preprocessing": "scripts from Rush et al. (2015)"
            }
        },
        {
            "id": "20250319012630D4",
            "name": "CNN/Daily Mail dataset (anonymized)",
            "type": "Dataset",
            "attributes": {
                "size": "286,817 training pairs",
                "content": "multi-sentence summaries",
                "anonymization": "entity IDs replaced"
            }
        },
        {
            "id": "20250319012630D5",
            "name": "LCSTS (Large Scale Chinese Short Text Summarization dataset)",
            "type": "Dataset",
            "attributes": {
                "language": "Chinese",
                "scale": "large"
            }
        },
        {
            "id": "20250319012945P1",
            "name": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joakim Nivre",
                    "Marie-Catherine de Marneffe",
                    "Filip Ginter",
                    "Yoav Goldberg",
                    "Jan Hajič",
                    "Christopher D. Manning",
                    "Ryan McDonald",
                    "Slav Petrov",
                    "Sampo Pyysalo",
                    "Natalia Silveira",
                    "Reut Tsarfaty",
                    "Daniel Zeman"
                ],
                "institutions": [
                    "The Ohio State University",
                    "Uppsala University",
                    "Bar-Ilan University",
                    "Google Inc.",
                    "Charles University in Prague",
                    "University of Cambridge",
                    "University of Turku",
                    "Stanford University",
                    "The Open University of Israel"
                ]
            }
        },
        {
            "id": "20250319012945D1",
            "name": "Universal Dependencies v1.2",
            "type": "Dataset",
            "attributes": {
                "languages": 33,
                "annotation_layers": [
                    "morphological",
                    "syntactic"
                ],
                "format": "CoNLL-U",
                "treebanks": 37,
                "features": [
                    "lemmas",
                    "part-of-speech tags",
                    "dependency relations"
                ]
            }
        },
        {
            "id": "20250319012945D2",
            "name": "Google Universal Dependency Treebank (UDT)",
            "type": "Dataset",
            "attributes": {
                "languages": 11,
                "versions": [
                    "2013 release",
                    "2014 release"
                ]
            }
        },
        {
            "id": "20250319012945D3",
            "name": "HamleDT",
            "type": "Dataset",
            "attributes": {
                "languages": 30,
                "version": "3.0"
            }
        },
        {
            "id": "20250319012945D4",
            "name": "CoNLL-X",
            "type": "Dataset",
            "attributes": {
                "format": "CoNLL-X"
            }
        },
        {
            "id": "20250319012945D5",
            "name": "Stanford Dependencies",
            "type": "Dataset",
            "attributes": {
                "framework": "dependency-based"
            }
        },
        {
            "id": "20250319012945R1",
            "name": "http://universaldependencies.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319012945T1",
            "name": "dependency parsing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012945T2",
            "name": "part-of-speech tagging",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012945T3",
            "name": "cross-lingual learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012945T4",
            "name": "morphological annotation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319012945T5",
            "name": "syntactic analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228P1",
            "name": "FEVER: a large-scale dataset for Fact Extraction and VERification",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "James Thorne",
                    "Andreas Vlachos",
                    "Christos Christodoulopoulos",
                    "Arpit Mittal"
                ],
                "institution": "University of Sheffield, Amazon Research Cambridge"
            }
        },
        {
            "id": "20250319013228D1",
            "name": "FEVER",
            "type": "Dataset",
            "attributes": {
                "size": "185,445 claims",
                "classes": [
                    "SUPPORTED",
                    "REFUTED",
                    "NOTENOUGHINFO"
                ],
                "inter_annotator_agreement": "Fleiss κ 0.6841",
                "evidence_composition": "16.82% multi-sentence",
                "cross_page_evidence": "12.15%",
                "annotation_precision": "95.42%",
                "annotation_recall": "72.36%"
            }
        },
        {
            "id": "20250319013228D2",
            "name": "Fake News Challenge dataset",
            "type": "Dataset",
            "attributes": {
                "size": "50K labeled claim-article pairs",
                "claims": 300,
                "articles": 2582
            }
        },
        {
            "id": "20250319013228D3",
            "name": "“Liar, Liar Pants on Fire” dataset",
            "type": "Dataset",
            "attributes": {
                "size": "12.8K claims",
                "source": "PolitiFact API"
            }
        },
        {
            "id": "20250319013228D4",
            "name": "Fact checking dataset",
            "type": "Dataset",
            "attributes": {
                "size": "106 claims",
                "source": "PolitiFact"
            }
        },
        {
            "id": "20250319013228D5",
            "name": "Emergent dataset",
            "type": "Dataset",
            "attributes": {
                "task": "stance classification"
            }
        },
        {
            "id": "20250319013228D6",
            "name": "TREC Answer Validation Exercise dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1,000 instances per language"
            }
        },
        {
            "id": "20250319013228T1",
            "name": "Fact Extraction and Verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T2",
            "name": "claim verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T3",
            "name": "stance classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T4",
            "name": "natural logic inference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T5",
            "name": "question answering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T6",
            "name": "claim extraction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T7",
            "name": "answer validation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013228T8",
            "name": "fake news detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013919P1",
            "name": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Lianmin Zheng",
                    "Wei-Lin Chiang",
                    "Ying Sheng",
                    "Siyuan Zhuang",
                    "Zhanghao Wu",
                    "Yonghao Zhuang",
                    "Zi Lin",
                    "Zhuohan Li",
                    "Dacheng Li",
                    "Eric P. Xing",
                    "Hao Zhang",
                    "Joseph E. Gonzalez",
                    "Ion Stoica"
                ],
                "institutions": [
                    "UC Berkeley",
                    "UC San Diego",
                    "Carnegie Mellon University",
                    "Stanford",
                    "MBZUAI"
                ]
            }
        },
        {
            "id": "20250319013919D1",
            "name": "MT-bench",
            "type": "Dataset",
            "attributes": {
                "description": "Multi-turn benchmark with 80 questions",
                "categories": [
                    "writing",
                    "roleplay",
                    "extraction",
                    "reasoning",
                    "math",
                    "coding"
                ],
                "size": "3K expert votes"
            }
        },
        {
            "id": "20250319013919D2",
            "name": "Chatbot Arena",
            "type": "Dataset",
            "attributes": {
                "description": "Crowdsourced battle platform",
                "size": "30K conversations"
            }
        },
        {
            "id": "20250319013919R1",
            "name": "https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319013919D3",
            "name": "MMLU",
            "type": "Dataset",
            "attributes": {
                "description": "Massive Multitask Language Understanding benchmark"
            }
        },
        {
            "id": "20250319013919D4",
            "name": "HELM",
            "type": "Dataset",
            "attributes": {
                "description": "Holistic Evaluation of Language Models benchmark"
            }
        },
        {
            "id": "20250319013919T1",
            "name": "multi-turn conversation evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013919T2",
            "name": "instruction-following evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013919T3",
            "name": "human preference evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319013919T4",
            "name": "benchmarking language models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613P1",
            "name": "ImageNet: A Large-Scale Hierarchical Image Database",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jia Deng",
                    "Wei Dong",
                    "Richard Socher",
                    "Li-Jia Li",
                    "Kai Li",
                    "Li Fei-Fei"
                ],
                "institution": "Princeton University"
            }
        },
        {
            "id": "20250319014613D1",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "3.2 million images",
                "synsets": 5247,
                "resolution": "full resolution (average 400x350)",
                "accuracy": "99.7% precision",
                "structure": "WordNet hierarchy",
                "collection_method": "Amazon Mechanical Turk"
            }
        },
        {
            "id": "20250319014613D2",
            "name": "TinyImage",
            "type": "Dataset",
            "attributes": {
                "size": "80 million images",
                "resolution": "32x32",
                "noise_level": "high"
            }
        },
        {
            "id": "20250319014613D3",
            "name": "ESP dataset",
            "type": "Dataset",
            "attributes": {
                "labeling_method": "online game",
                "availability": "60,000 images public"
            }
        },
        {
            "id": "20250319014613D4",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "segmented_images": true,
                "size": "30,000 images"
            }
        },
        {
            "id": "20250319014613D5",
            "name": "Lotus Hill dataset",
            "type": "Dataset",
            "attributes": {
                "availability": "purchase required",
                "segmented_images": true
            }
        },
        {
            "id": "20250319014613D6",
            "name": "Caltech101",
            "type": "Dataset",
            "attributes": {
                "categories": 101
            }
        },
        {
            "id": "20250319014613D7",
            "name": "Caltech256",
            "type": "Dataset",
            "attributes": {
                "categories": 256
            }
        },
        {
            "id": "20250319014613D8",
            "name": "MSRC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319014613D9",
            "name": "PASCAL",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319014613R1",
            "name": "http://www.image-net.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319014613T1",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T2",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T3",
            "name": "automatic object clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T4",
            "name": "object localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T5",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T6",
            "name": "part models learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T7",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T9",
            "name": "image search",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014613T10",
            "name": "image understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853P1",
            "name": "Microsoft COCO: Common Objects in Context",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Tsung-Yi Lin",
                    "Michael Maire",
                    "Serge Belongie",
                    "Lubomir Bourdev",
                    "Ross Girshick",
                    "James Hays",
                    "Pietro Perona",
                    "Deva Ramanan",
                    "C. Lawrence Zitnick",
                    "Piotr Doll´ar"
                ],
                "institution": "Multiple institutions including Cornell, Facebook AI Research, Microsoft Research"
            }
        },
        {
            "id": "20250319014853D1",
            "name": "Microsoft COCO (MS COCO)",
            "type": "Dataset",
            "attributes": {
                "size": "328k images",
                "instances": "2.5 million",
                "categories": 91,
                "annotation type": "per-instance segmentations",
                "context": "non-iconic views, natural context",
                "average instances per image": 7.7
            }
        },
        {
            "id": "20250319014853D2",
            "name": "PASCAL VOC 2012",
            "type": "Dataset",
            "attributes": {
                "size": "11,000 images",
                "instances": "27,000",
                "categories": 20
            }
        },
        {
            "id": "20250319014853D3",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "14 million images",
                "categories": "22k"
            }
        },
        {
            "id": "20250319014853D4",
            "name": "SUN dataset",
            "type": "Dataset",
            "attributes": {
                "scene categories": 908,
                "object categories": 3819
            }
        },
        {
            "id": "20250319014853D5",
            "name": "Caltech 101",
            "type": "Dataset",
            "attributes": {
                "categories": 101
            }
        },
        {
            "id": "20250319014853D6",
            "name": "Caltech 256",
            "type": "Dataset",
            "attributes": {
                "categories": 256
            }
        },
        {
            "id": "20250319014853D7",
            "name": "CIFAR-10",
            "type": "Dataset",
            "attributes": {
                "size": "60,000 images",
                "resolution": "32x32",
                "categories": 10
            }
        },
        {
            "id": "20250319014853D8",
            "name": "CIFAR-100",
            "type": "Dataset",
            "attributes": {
                "size": "60,000 images",
                "resolution": "32x32",
                "categories": 100
            }
        },
        {
            "id": "20250319014853D9",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "segmented images": "yes",
                "size": "30,000 images"
            }
        },
        {
            "id": "20250319014853D10",
            "name": "Caltech Pedestrian Dataset",
            "type": "Dataset",
            "attributes": {
                "instances": "350,000"
            }
        },
        {
            "id": "20250319014853T1",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T2",
            "name": "semantic scene labeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T3",
            "name": "instance segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T4",
            "name": "bounding box detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T5",
            "name": "contextual reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T6",
            "name": "precise 2D localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T7",
            "name": "object classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319014853T8",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200P1",
            "name": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Marius Cordts",
                    "Mohamed Omran",
                    "Sebastian Ramos",
                    "Timo Rehfeld",
                    "Markus Enzweiler",
                    "Rodrigo Benenson",
                    "Uwe Franke",
                    "Stefan Roth",
                    "Bernt Schiele"
                ],
                "institutions": [
                    "Daimler AG R&D",
                    "TU Darmstadt",
                    "MPI Informatics",
                    "TU Dresden"
                ]
            }
        },
        {
            "id": "20250319015200D1",
            "name": "Cityscapes",
            "type": "Dataset",
            "attributes": {
                "size": "5000 fine, 20000 coarse images",
                "annotations": "pixel-level, instance-level",
                "modality": "stereo video",
                "scene_type": "urban street scenes",
                "cities": 50,
                "resolution": "high-resolution"
            }
        },
        {
            "id": "20250319015200D2",
            "name": "CamVid",
            "type": "Dataset",
            "attributes": {
                "annotations": "pixel-wise",
                "size": "700+ frames",
                "scene_type": "street scenes"
            }
        },
        {
            "id": "20250319015200D3",
            "name": "DUS (Daimler Urban Segmentation)",
            "type": "Dataset",
            "attributes": {
                "size": "500 annotated images",
                "scene_type": "urban"
            }
        },
        {
            "id": "20250319015200D4",
            "name": "KITTI Vision Benchmark Suite",
            "type": "Dataset",
            "attributes": {
                "focus": "suburban traffic scenes",
                "modality": "stereo, LiDAR"
            }
        },
        {
            "id": "20250319015200D5",
            "name": "Microsoft COCO",
            "type": "Dataset",
            "attributes": {
                "annotations": "instance-level"
            }
        },
        {
            "id": "20250319015200D6",
            "name": "PASCAL VOC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015200D7",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "annotation_type": "user-generated labels"
            }
        },
        {
            "id": "20250319015200D8",
            "name": "Caltech Pedestrian Dataset",
            "type": "Dataset",
            "attributes": {
                "focus": "pedestrian detection"
            }
        },
        {
            "id": "20250319015200R1",
            "name": "www.cityscapes-dataset.net",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319015200T1",
            "name": "semantic urban scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T2",
            "name": "pixel-level semantic labeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T3",
            "name": "instance-level semantic labeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T4",
            "name": "3D scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T5",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015200T7",
            "name": "cross-dataset evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448P1",
            "name": "Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Andreas Geiger",
                    "Philip Lenz",
                    "Raquel Urtasun"
                ],
                "institutions": [
                    "Karlsruhe Institute of Technology",
                    "Toyota Technological Institute at Chicago"
                ]
            }
        },
        {
            "id": "20250319015448D1",
            "name": "KITTI Vision Benchmark Suite",
            "type": "Dataset",
            "attributes": {
                "size": "389 stereo/optical flow pairs, 39.2 km visual odometry sequences, 200k 3D annotations",
                "resolution": "1240×376 pixels",
                "sensors": [
                    "PointGrey Flea2 cameras",
                    "Velodyne HDL-64E laser scanner",
                    "GPS/IMU localization"
                ],
                "ground_truth": "semi-dense (50%)",
                "environment": "urban, rural, highway"
            }
        },
        {
            "id": "20250319015448D2",
            "name": "Middlebury",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D3",
            "name": "Make3D Stereo",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D4",
            "name": "Ladicky",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D5",
            "name": "TUM RGB-D",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D6",
            "name": "New College",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D7",
            "name": "Malaga 2009",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D8",
            "name": "Ford Campus",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D9",
            "name": "Caltech 101",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D10",
            "name": "MIT StreetScenes",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D11",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D12",
            "name": "ETHZ Pedestrian",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D13",
            "name": "PASCAL 2011",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D14",
            "name": "Daimler",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D15",
            "name": "Caltech Pedestrian",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D16",
            "name": "COIL-100",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D17",
            "name": "EPFL Multi-View Car",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448D18",
            "name": "Caltech 3D Objects",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319015448R1",
            "name": "www.cvlibs.net/datasets/kitti",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319015448T1",
            "name": "stereo matching",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T2",
            "name": "optical flow estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T3",
            "name": "visual odometry/SLAM",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T4",
            "name": "3D object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T5",
            "name": "3D orientation estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T6",
            "name": "object tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015448T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825P1",
            "name": "Deep Learning Face Attributes in the Wild",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Ziwei Liu",
                    "Ping Luo",
                    "Xiaogang Wang",
                    "Xiaoou Tang"
                ],
                "institution": "The Chinese University of Hong Kong"
            }
        },
        {
            "id": "20250319015825D1",
            "name": "CelebFaces",
            "type": "Dataset",
            "attributes": {
                "size": "160,000 images",
                "identities": "8,000",
                "reference": "[27]"
            }
        },
        {
            "id": "20250319015825D2",
            "name": "LFW (Labeled Faces in the Wild)",
            "type": "Dataset",
            "attributes": {
                "size": "13,233 images",
                "identities": "5,749",
                "reference": "[12]"
            }
        },
        {
            "id": "20250319015825D3",
            "name": "CelebA",
            "type": "Dataset",
            "attributes": {
                "size": "200,000 images",
                "identities": "10,000",
                "attributes": "40"
            }
        },
        {
            "id": "20250319015825D4",
            "name": "LFWA",
            "type": "Dataset",
            "attributes": {
                "size": "13,233 images",
                "based_on": "LFW"
            }
        },
        {
            "id": "20250319015825D5",
            "name": "LFWA+",
            "type": "Dataset",
            "attributes": {
                "attributes": "30 additional",
                "based_on": "LFWA"
            }
        },
        {
            "id": "20250319015825D6",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "1.2 million training images",
                "reference": "[6]"
            }
        },
        {
            "id": "20250319015825D7",
            "name": "ILSVRC 2012",
            "type": "Dataset",
            "attributes": {
                "training_images": "1.2 million",
                "validation_images": "50,000"
            }
        },
        {
            "id": "20250319015825D8",
            "name": "SUN database",
            "type": "Dataset",
            "attributes": {
                "purpose": "scene recognition",
                "reference": "[29]"
            }
        },
        {
            "id": "20250319015825T1",
            "name": "face verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T2",
            "name": "face identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T3",
            "name": "face retrieval",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T4",
            "name": "attribute prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T5",
            "name": "face localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T6",
            "name": "attribute classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T7",
            "name": "face recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T8",
            "name": "attribute recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T9",
            "name": "part localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T10",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T11",
            "name": "alignment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T12",
            "name": "object classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T13",
            "name": "automatic part localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319015825T14",
            "name": "scene recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020328P1",
            "name": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Han Xiao",
                    "Kashif Rasul",
                    "Roland Vollgraf"
                ],
                "institution": "Zalando Research"
            }
        },
        {
            "id": "20250319020328D1",
            "name": "Fashion-MNIST",
            "type": "Dataset",
            "attributes": {
                "size": "70,000 images",
                "image_dimensions": "28x28 grayscale",
                "classes": 10,
                "training_split": "60,000 images",
                "test_split": "10,000 images",
                "data_format": "MNIST-compatible"
            }
        },
        {
            "id": "20250319020328D2",
            "name": "MNIST",
            "type": "Dataset",
            "attributes": {
                "description": "10-class handwritten digits"
            }
        },
        {
            "id": "20250319020328D3",
            "name": "CIFAR10",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020328D4",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020328D5",
            "name": "EMNIST",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020328R1",
            "name": "https://github.com/zalandoresearch/fashion-mnist",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319020328T1",
            "name": "benchmarking machine learning algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020328T2",
            "name": "machine learning classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020328T3",
            "name": "machine learning prototyping",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518P1",
            "name": "nuScenes: A multimodal dataset for autonomous driving",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Holger Caesar",
                    "Varun Bankiti",
                    "Alex H. Lang",
                    "Sourabh Vora",
                    "Venice Erin Liong",
                    "Qiang Xu",
                    "Anush Krishnan",
                    "Yu Pan",
                    "Giancarlo Baldan",
                    "Oscar Beijbom"
                ],
                "institution": "nuTonomy: an APTIV company"
            }
        },
        {
            "id": "20250319020518D1",
            "name": "nuScenes",
            "type": "Dataset",
            "attributes": {
                "size": "1000 scenes, 1.4M images",
                "sensors": "6 cameras, 5 radars, 1 lidar",
                "classes": 23,
                "annotation_frequency": "2Hz",
                "locations": [
                    "Boston",
                    "Singapore"
                ],
                "weather_conditions": [
                    "rain",
                    "night"
                ],
                "license": "CC BY-NC-SA 4.0"
            }
        },
        {
            "id": "20250319020518D2",
            "name": "KITTI",
            "type": "Dataset",
            "attributes": {
                "size": "22 scenes",
                "annotations": "200k 3D boxes"
            }
        },
        {
            "id": "20250319020518D3",
            "name": "H3D",
            "type": "Dataset",
            "attributes": {
                "size": "160 scenes",
                "annotations": "1.1M 3D boxes"
            }
        },
        {
            "id": "20250319020518D4",
            "name": "KAIST",
            "type": "Dataset",
            "attributes": {
                "modalities": "RGB, thermal camera, lidar"
            }
        },
        {
            "id": "20250319020518D5",
            "name": "Lyft L5",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D6",
            "name": "Waymo Open Dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D7",
            "name": "A*3D",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D8",
            "name": "Cityscapes",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D9",
            "name": "BDD100K",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D10",
            "name": "ApolloScape",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D11",
            "name": "D2-City",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D12",
            "name": "Mapillary Vistas",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D13",
            "name": "CamVid",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D14",
            "name": "Oxford RobotCar",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D15",
            "name": "Málaga Urban Dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D16",
            "name": "A2D2",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518D17",
            "name": "Woodscape",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319020518R1",
            "name": "http://www.nuscenes.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319020518L1",
            "name": "CC BY-NC-SA 4.0",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319020518T1",
            "name": "3D object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T2",
            "name": "object tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T3",
            "name": "behavior modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T4",
            "name": "pedestrian localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T5",
            "name": "moving pointcloud prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T6",
            "name": "sensor fusion",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T7",
            "name": "trajectory prediction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T8",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T9",
            "name": "semantic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T10",
            "name": "instance segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T11",
            "name": "depth estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020518T12",
            "name": "panoptic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902P1",
            "name": "ShapeNet: An Information-Rich 3D Model Repository",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Angel X. Chang",
                    "Thomas Funkhouser",
                    "Leonidas Guibas",
                    "Pat Hanrahan",
                    "Qixing Huang",
                    "Zimo Li",
                    "Silvio Savarese",
                    "Manolis Savva",
                    "Shuran Song",
                    "Hao Su",
                    "Jianxiong Xiao",
                    "Li Yi",
                    "Fisher Yu"
                ],
                "institutions": [
                    "Stanford University",
                    "Princeton University",
                    "Toyota Technological Institute at Chicago"
                ]
            }
        },
        {
            "id": "20250319020902D1",
            "name": "ShapeNet",
            "type": "Dataset",
            "attributes": {
                "size": "3,000,000 models",
                "synsets": "3,135 categories",
                "annotations": [
                    "rigid alignments",
                    "parts",
                    "symmetry planes",
                    "physical sizes",
                    "keywords"
                ]
            }
        },
        {
            "id": "20250319020902D2",
            "name": "ShapeNetCore",
            "type": "Dataset",
            "attributes": {
                "size": "51,300 models",
                "categories": "55"
            }
        },
        {
            "id": "20250319020902D3",
            "name": "ShapeNetSem",
            "type": "Dataset",
            "attributes": {
                "size": "12,000 models",
                "categories": "270",
                "annotations": [
                    "real-world dimensions",
                    "material composition",
                    "volume",
                    "weight"
                ]
            }
        },
        {
            "id": "20250319020902D4",
            "name": "Princeton Shape Benchmark",
            "type": "Dataset",
            "attributes": {
                "size": "1,800 models",
                "categories": "90"
            }
        },
        {
            "id": "20250319020902D5",
            "name": "SHREC 2014",
            "type": "Dataset",
            "attributes": {
                "size": "9,000 models",
                "categories": "171"
            }
        },
        {
            "id": "20250319020902D6",
            "name": "Benchmark for 3D Mesh Segmentation",
            "type": "Dataset",
            "attributes": {
                "size": "380 models",
                "categories": "19"
            }
        },
        {
            "id": "20250319020902D7",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "14M images",
                "categories": "20,000"
            }
        },
        {
            "id": "20250319020902D8",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "annotations": "segmentations",
                "size": "30,000 images"
            }
        },
        {
            "id": "20250319020902D9",
            "name": "SUN dataset",
            "type": "Dataset",
            "attributes": {
                "annotations": "3M object annotations",
                "categories": "4,000"
            }
        },
        {
            "id": "20250319020902D10",
            "name": "Protein Data Bank",
            "type": "Dataset",
            "attributes": {
                "size": "100K protein structures"
            }
        },
        {
            "id": "20250319020902D11",
            "name": "PASCAL 3D+",
            "type": "Dataset",
            "attributes": {
                "categories": "12"
            }
        },
        {
            "id": "20250319020902R1",
            "name": "http://www.shapenet.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319020902P2",
            "name": "ImageNet: A large-scale hierarchical image database",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jia Deng",
                    "Wei Dong",
                    "Richard Socher",
                    "Li-Jia Li",
                    "Kai Li",
                    "Li Fei-Fei"
                ],
                "venue": "CVPR 2009"
            }
        },
        {
            "id": "20250319020902P3",
            "name": "Princeton Shape Benchmark",
            "type": "Paper",
            "attributes": {}
        },
        {
            "id": "20250319020902P4",
            "name": "WordNet: a lexical database for English",
            "type": "Paper",
            "attributes": {}
        },
        {
            "id": "20250319020902T1",
            "name": "segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T2",
            "name": "alignment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T3",
            "name": "correspondence",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T4",
            "name": "shape retrieval",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T5",
            "name": "shape classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T6",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T7",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T8",
            "name": "part models learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T9",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319020902T10",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021337P1",
            "name": "ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Angela Dai",
                    "Angel X. Chang",
                    "Manolis Savva",
                    "Maciej Halber",
                    "Thomas Funkhouser",
                    "Matthias Nießner"
                ],
                "institutions": [
                    "Stanford University",
                    "Princeton University",
                    "Technical University of Munich"
                ]
            }
        },
        {
            "id": "20250319021337D1",
            "name": "ScanNet",
            "type": "Dataset",
            "attributes": {
                "size": "2.5M views in 1513 scenes",
                "annotations": [
                    "3D camera poses",
                    "surface reconstructions",
                    "semantic segmentations",
                    "CAD model alignments"
                ],
                "collection_method": "Amazon Mechanical Turk",
                "resolution": "RGB (1296×968), Depth (640×480)",
                "sensor": "Structure Sensor (iPad-mounted)"
            }
        },
        {
            "id": "20250319021337D2",
            "name": "NYUv2",
            "type": "Dataset",
            "attributes": {
                "size": "464 scans",
                "annotations": "2D polygons",
                "resolution": "RGB-D"
            }
        },
        {
            "id": "20250319021337D3",
            "name": "SUN3D",
            "type": "Dataset",
            "attributes": {
                "size": "415 sequences",
                "annotations": "Estimated camera poses"
            }
        },
        {
            "id": "20250319021337D4",
            "name": "SUNRGB-D",
            "type": "Dataset",
            "attributes": {
                "size": "10,335 frames",
                "annotations": "2D polygons + 3D bounding boxes"
            }
        },
        {
            "id": "20250319021337D5",
            "name": "SceneNN",
            "type": "Dataset",
            "attributes": {
                "size": "100 scans",
                "annotations": "Dense 3D expert annotations"
            }
        },
        {
            "id": "20250319021337D6",
            "name": "ShapeNetCore",
            "type": "Dataset",
            "attributes": {
                "content": "55K CAD models",
                "use_case": "3D model retrieval"
            }
        },
        {
            "id": "20250319021337R1",
            "name": "http://www.scan-net.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319021337T1",
            "name": "3D object classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021337T2",
            "name": "semantic voxel labeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021337T3",
            "name": "CAD model retrieval",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021337T4",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525P1",
            "name": "A Style-Based Generator Architecture for Generative Adversarial Networks",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Tero Karras",
                    "Samuli Laine",
                    "Timo Aila"
                ],
                "institution": "NVIDIA"
            }
        },
        {
            "id": "20250319021525D1",
            "name": "Flickr-Faces-HQ (FFHQ)",
            "type": "Dataset",
            "attributes": {
                "size": "70,000 images",
                "resolution": "1024x1024",
                "variation": "age, ethnicity, background, accessories",
                "collection_method": "Flickr crawling with Mechanical Turk pruning",
                "alignment": "automatic"
            }
        },
        {
            "id": "20250319021525D2",
            "name": "CELEBA-HQ",
            "type": "Dataset",
            "attributes": {
                "resolution": "1024x1024"
            }
        },
        {
            "id": "20250319021525D3",
            "name": "LSUN BEDROOM",
            "type": "Dataset",
            "attributes": {
                "resolution": "256x256"
            }
        },
        {
            "id": "20250319021525D4",
            "name": "LSUN CAR",
            "type": "Dataset",
            "attributes": {
                "resolution": "512x384"
            }
        },
        {
            "id": "20250319021525D5",
            "name": "LSUN CAT",
            "type": "Dataset",
            "attributes": {
                "resolution": "256x256"
            }
        },
        {
            "id": "20250319021525R1",
            "name": "https://github.com/NVlabs/ffhq-dataset",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319021525T1",
            "name": "image synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525T2",
            "name": "latent space interpolation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525T3",
            "name": "disentanglement of latent factors",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525T4",
            "name": "style transfer",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525T5",
            "name": "generative model training",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021525T6",
            "name": "image quality evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021738P1",
            "name": "Automated flower classification over a large number of classes",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Maria-Elena Nilsback",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319021738D1",
            "name": "103 class flower dataset",
            "type": "Dataset",
            "attributes": {
                "number of classes": 103,
                "number of images": 8189,
                "image resolution": "smallest dimension 500 pixels"
            }
        },
        {
            "id": "20250319021738D2",
            "name": "17 class flower dataset",
            "type": "Dataset",
            "attributes": {
                "number of classes": 17
            }
        },
        {
            "id": "20250319021738D3",
            "name": "Caltech-256",
            "type": "Dataset",
            "attributes": {
                "number of classes": 256
            }
        },
        {
            "id": "20250319021738D4",
            "name": "Caltech-101",
            "type": "Dataset",
            "attributes": {
                "number of classes": 101
            }
        },
        {
            "id": "20250319021738R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/flowers/index.html",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319021738T1",
            "name": "flower classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021738T2",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021738T3",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021738T4",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948P1",
            "name": "Places: A 10 Million Image Database for Scene Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Bolei Zhou",
                    "Agata Lapedriza",
                    "Aditya Khosla",
                    "Aude Oliva",
                    "Antonio Torralba"
                ],
                "institutions": [
                    "Massachusetts Institute of Technology",
                    "Universitat Oberta de Catalunya"
                ]
            }
        },
        {
            "id": "20250319021948D1",
            "name": "Places Database",
            "type": "Dataset",
            "attributes": {
                "size": "10 million images",
                "number_of_categories": 434,
                "versions": [
                    "Places205",
                    "Places365"
                ],
                "resolution": "at least 200x200 pixels",
                "diversity": "high"
            }
        },
        {
            "id": "20250319021948D2",
            "name": "SUN database",
            "type": "Dataset",
            "attributes": {
                "number_of_categories": 397
            }
        },
        {
            "id": "20250319021948D3",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "1.2 million images"
            }
        },
        {
            "id": "20250319021948D4",
            "name": "COCO dataset",
            "type": "Dataset",
            "attributes": {
                "focus": "object instances in scene context"
            }
        },
        {
            "id": "20250319021948D5",
            "name": "PASCAL VOC dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D6",
            "name": "ADE20K",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D7",
            "name": "Visual Genome dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D8",
            "name": "Cityscapes dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D9",
            "name": "Tiny Image dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D10",
            "name": "MIT Indoor67",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D11",
            "name": "Scene15",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D12",
            "name": "SUN Attribute",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D13",
            "name": "Caltech101",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D14",
            "name": "Caltech256",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D15",
            "name": "Stanford Action40",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948D16",
            "name": "UIUC Event8",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319021948T1",
            "name": "scene recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T2",
            "name": "scene classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T3",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T4",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T5",
            "name": "semantic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T6",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T7",
            "name": "visual recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T8",
            "name": "object localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T9",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319021948T10",
            "name": "transfer learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405P1",
            "name": "Deep Hashing Network for Unsupervised Domain Adaptation",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Hemanth Venkateswara",
                    "Jose Eusebio",
                    "Shayok Chakraborty",
                    "Sethuraman Panchanathan"
                ],
                "institution": "Arizona State University"
            }
        },
        {
            "id": "20250319022405D1",
            "name": "Office-Home",
            "type": "Dataset",
            "attributes": {
                "size": "15,500 images",
                "categories": 65,
                "domains": [
                    "Art",
                    "Clipart",
                    "Product",
                    "Real-World"
                ],
                "availability": "publicly available"
            }
        },
        {
            "id": "20250319022405R1",
            "name": "https://hemanthdv.github.io/officehome-dataset/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319022405D2",
            "name": "Office",
            "type": "Dataset",
            "attributes": {
                "size": "4,100 images",
                "categories": 31
            }
        },
        {
            "id": "20250319022405D3",
            "name": "Office-Caltech",
            "type": "Dataset",
            "attributes": {
                "size": "2,533 images",
                "categories": 10
            }
        },
        {
            "id": "20250319022405D4",
            "name": "ImageNet 2012",
            "type": "Dataset",
            "attributes": {
                "purpose": "pre-trained model for VGG-F network"
            }
        },
        {
            "id": "20250319022405T1",
            "name": "unsupervised domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405T2",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405T3",
            "name": "hashing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405T4",
            "name": "feature learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405T5",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022405T6",
            "name": "cross-modal hashing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022617P1",
            "name": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Tero Karras",
                    "Samuli Laine",
                    "Timo Aila",
                    "Jaakko Lehtinen"
                ],
                "institutions": [
                    "NVIDIA",
                    "Aalto University"
                ]
            }
        },
        {
            "id": "20250319022617D1",
            "name": "CELEBA-HQ",
            "type": "Dataset",
            "attributes": {
                "resolution": "1024x1024",
                "size": "30000 images",
                "description": "High-quality version of CELEBA",
                "source": "Based on CELEBA dataset"
            }
        },
        {
            "id": "20250319022617D2",
            "name": "CELEBA",
            "type": "Dataset",
            "attributes": {
                "size": "202599 images",
                "resolution": "Varied (43x55 to 6732x8984)"
            }
        },
        {
            "id": "20250319022617D3",
            "name": "LSUN BEDROOM",
            "type": "Dataset",
            "attributes": {
                "category": "Bedroom images"
            }
        },
        {
            "id": "20250319022617D4",
            "name": "CIFAR10",
            "type": "Dataset",
            "attributes": {
                "inception_score": "8.80 (unsupervised)"
            }
        },
        {
            "id": "20250319022617R1",
            "name": "https://github.com/tkarras/progressive_growing_of_gans",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319022617T1",
            "name": "high-resolution image generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022617T2",
            "name": "training generative adversarial networks",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022617T3",
            "name": "evaluating GAN results",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946P1",
            "name": "Scalable Person Re-identification: A Benchmark",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Liang Zheng",
                    "Liyue Shen",
                    "Lu Tian",
                    "Shengjin Wang",
                    "Jingdong Wang",
                    "Qi Tian"
                ],
                "institutions": [
                    "Tsinghua University",
                    "Microsoft Research",
                    "University of Texas at San Antonio"
                ]
            }
        },
        {
            "id": "20250319022946D1",
            "name": "Market-1501",
            "type": "Dataset",
            "attributes": {
                "size": "32,668 annotated bboxes + 500K distractors",
                "identities": 1501,
                "cameras": 6,
                "detector": "Deformable Part Model (DPM)",
                "evaluation_metrics": [
                    "mAP",
                    "CMC"
                ],
                "features": [
                    "multi-query",
                    "cross-camera search",
                    "open system"
                ]
            }
        },
        {
            "id": "20250319022946D2",
            "name": "VIPeR",
            "type": "Dataset",
            "attributes": {
                "identities": 632,
                "cameras": 2,
                "image_size": "128x48"
            }
        },
        {
            "id": "20250319022946D3",
            "name": "CUHK03",
            "type": "Dataset",
            "attributes": {
                "identities": 1467,
                "bboxes": 13164,
                "detector": "DPM"
            }
        },
        {
            "id": "20250319022946D4",
            "name": "i-LIDS",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319022946R1",
            "name": "http://www.liangzheng.com.cn",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319022946T1",
            "name": "person re-identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946T2",
            "name": "image search",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946T3",
            "name": "metric learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946T4",
            "name": "multiple query techniques",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946T5",
            "name": "search reranking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319022946T6",
            "name": "large-scale data analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144P1",
            "name": "LSUN: Construction of a Large-Scale Image Dataset using Deep Learning with Humans in the Loop",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Fisher Yu",
                    "Ari Seff",
                    "Yinda Zhang",
                    "Shuran Song",
                    "Thomas Funkhouser",
                    "Jianxiong Xiao"
                ],
                "institution": "Princeton University"
            }
        },
        {
            "id": "20250319023144D1",
            "name": "LSUN",
            "type": "Dataset",
            "attributes": {
                "size": "10 million scene images, 59 million object images",
                "categories": "10 scene, 20 object",
                "precision": "~90%",
                "collection_method": "iterative deep learning with Amazon Mechanical Turk",
                "image_sources": "Google Images",
                "resolution": "minimum dimension 256 pixels",
                "comparison": "10x denser than Places, 100x denser than ImageNet"
            }
        },
        {
            "id": "20250319023144D2",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "size": "1.4 million images (classification challenge)",
                "density": "1000 images per category",
                "age": "7 years old"
            }
        },
        {
            "id": "20250319023144D3",
            "name": "Places",
            "type": "Dataset",
            "attributes": {
                "density_comparison": "10x less dense than LSUN"
            }
        },
        {
            "id": "20250319023144D4",
            "name": "SUN database",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023144D5",
            "name": "PASCAL VOC 2012",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023144D6",
            "name": "MS COCO",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023144T1",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144T2",
            "name": "visual recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144T3",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144T4",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144T5",
            "name": "unsupervised image analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023144T6",
            "name": "object localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023346P1",
            "name": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Peter Young",
                    "Alice Lai",
                    "Micah Hodosh",
                    "Julia Hockenmaier"
                ],
                "institution": "University of Illinois at Urbana-Champaign"
            }
        },
        {
            "id": "20250319023346D1",
            "name": "Image Description Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "31,783 images",
                "captions": "158,915 captions",
                "collection_method": "crowdsourcing",
                "license": "Creative Commons license"
            }
        },
        {
            "id": "20250319023346D2",
            "name": "MSR Video Description Corpus",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023346D3",
            "name": "SBU Captioned Photo Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1 million images"
            }
        },
        {
            "id": "20250319023346R1",
            "name": "http://nlp.cs.illinois.edu/Denotation.html",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319023346L1",
            "name": "Creative Commons license",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319023346T1",
            "name": "semantic textual similarity",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023346T2",
            "name": "approximate entailment recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023346T3",
            "name": "paraphrase detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023346T4",
            "name": "semantic inference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023346T5",
            "name": "automatic image understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610P1",
            "name": "Describing Textures in the Wild",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Mircea Cimpoi",
                    "Subhransu Maji",
                    "Iasonas Kokkinos",
                    "Sammy Mohamed",
                    "Andrea Vedaldi"
                ],
                "institutions": [
                    "University of Oxford",
                    "Toyota Technological Institute, Chicago (TTIC)",
                    "Ecole Centrale Paris",
                    "Stony Brook University"
                ]
            }
        },
        {
            "id": "20250319023610D1",
            "name": "Describable Textures Dataset (DTD)",
            "type": "Dataset",
            "attributes": {
                "size": "5,640 images",
                "attributes": 47,
                "splits": "10 preset splits",
                "collection_method": "web images",
                "annotation_method": "crowd-sourced with co-occurrence statistics"
            }
        },
        {
            "id": "20250319023610D2",
            "name": "Flickr Material Dataset (FMD)",
            "type": "Dataset",
            "attributes": {
                "collection": "in the wild",
                "purpose": "material recognition"
            }
        },
        {
            "id": "20250319023610D3",
            "name": "KTH-TIPS-2b",
            "type": "Dataset",
            "attributes": {
                "purpose": "material recognition under variable conditions"
            }
        },
        {
            "id": "20250319023610D4",
            "name": "CUReT",
            "type": "Dataset",
            "attributes": {
                "purpose": "material recognition"
            }
        },
        {
            "id": "20250319023610D5",
            "name": "UIUC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023610D6",
            "name": "UMD",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023610D7",
            "name": "Outex",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023610D8",
            "name": "Drexel Texture Database",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023610T1",
            "name": "texture description",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T2",
            "name": "material recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T3",
            "name": "semantic search",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T4",
            "name": "learning from textual descriptions",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T5",
            "name": "image understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T6",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T7",
            "name": "texture classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023610T9",
            "name": "attribute-based clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915P1",
            "name": "Food-101 – Mining Discriminative Components with Random Forests",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Lukas Bossard",
                    "Matthieu Guillaumin",
                    "Luc Van Gool"
                ],
                "institution": "ETH Zurich, K.U. Leuven"
            }
        },
        {
            "id": "20250319023915D1",
            "name": "Food-101",
            "type": "Dataset",
            "attributes": {
                "size": "101,000 images",
                "classes": 101,
                "training_images_per_class": 750,
                "test_images_per_class": 250,
                "source": "foodspotting.com",
                "availability": "public",
                "noise": "training images contain noise"
            }
        },
        {
            "id": "20250319023915D2",
            "name": "PFID",
            "type": "Dataset",
            "attributes": {
                "description": "standardized fast-food images",
                "environment": "controlled laboratory conditions"
            }
        },
        {
            "id": "20250319023915D3",
            "name": "MIT-Indoor",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319023915D4",
            "name": "Pittsburgh food dataset",
            "type": "Dataset",
            "attributes": {
                "classes": 101,
                "instances_per_class": 3,
                "images_per_instance": 8
            }
        },
        {
            "id": "20250319023915R1",
            "name": "http://www.vision.ee.ethz.ch/datasets/food-101/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319023915T1",
            "name": "food recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915T2",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915T3",
            "name": "discriminative part mining",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915T4",
            "name": "component-based classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915T5",
            "name": "scene classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319023915T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401P1",
            "name": "3D Object Representations for Fine-Grained Categorization",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jonathan Krause",
                    "Michael Stark",
                    "Jia Deng",
                    "Li Fei-Fei"
                ],
                "institution": "Stanford University, Max Planck Institute for Informatics"
            }
        },
        {
            "id": "20250319024401D1",
            "name": "BMW-10",
            "type": "Dataset",
            "attributes": {
                "size": "512 images",
                "number of classes": 10,
                "granularity": "ultra-fine-grained"
            }
        },
        {
            "id": "20250319024401D2",
            "name": "car-197",
            "type": "Dataset",
            "attributes": {
                "size": "16,185 images",
                "number of classes": 197,
                "categories": [
                    "sedans",
                    "SUVs",
                    "coupes",
                    "convertibles",
                    "pickups",
                    "hatchbacks",
                    "station wagons"
                ]
            }
        },
        {
            "id": "20250319024401D3",
            "name": "3D Object Classes dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319024401R1",
            "name": "Amazon Mechanical Turk (AMT)",
            "type": "Repository",
            "attributes": {
                "usage": "data collection and annotation"
            }
        },
        {
            "id": "20250319024401T1",
            "name": "fine-grained categorization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T2",
            "name": "3D reconstruction",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T3",
            "name": "ultra-wide baseline matching",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T4",
            "name": "3D geometry estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T5",
            "name": "multi-view object class detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T6",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024401T7",
            "name": "synthetic training data generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024604P1",
            "name": "Moment Matching for Multi-Source Domain Adaptation",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Xingchao Peng",
                    "Qinxun Bai",
                    "Xide Xia",
                    "Zijun Huang",
                    "Kate Saenko",
                    "Bo Wang"
                ],
                "institutions": [
                    "Boston University",
                    "Horizon Robotics",
                    "Columbia University",
                    "Vector Institute & Peter Munk Cardiac Center"
                ]
            }
        },
        {
            "id": "20250319024604D1",
            "name": "DomainNet",
            "type": "Dataset",
            "attributes": {
                "size": "~0.6 million images",
                "categories": 345,
                "domains": 6,
                "domains_list": [
                    "clipart",
                    "infograph",
                    "painting",
                    "quickdraw",
                    "real",
                    "sketch"
                ],
                "collection_method": "Manual filtering via Amazon Mechanical Turk",
                "annotation_quality": "Dual-annotator agreement"
            }
        },
        {
            "id": "20250319024604D2",
            "name": "Office",
            "type": "Dataset",
            "attributes": {
                "domains": 3,
                "classes": 31,
                "description": "Office environment objects"
            }
        },
        {
            "id": "20250319024604D3",
            "name": "Office-Caltech10",
            "type": "Dataset",
            "attributes": {
                "domains": 4,
                "classes": 10
            }
        },
        {
            "id": "20250319024604D4",
            "name": "PACS",
            "type": "Dataset",
            "attributes": {
                "domains": 4,
                "classes": 7
            }
        },
        {
            "id": "20250319024604D5",
            "name": "Syn2Real",
            "type": "Dataset",
            "attributes": {
                "size": "280,157 images"
            }
        },
        {
            "id": "20250319024604D6",
            "name": "Digit-Five",
            "type": "Dataset",
            "attributes": {
                "components": [
                    "MNIST",
                    "MNIST-M",
                    "Synthetic Digits",
                    "SVHN",
                    "USPS"
                ]
            }
        },
        {
            "id": "20250319024604R1",
            "name": "http://ai.bu.edu/M3SDA/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319024604T1",
            "name": "multi-source domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024604T2",
            "name": "domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024604T3",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024604T4",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024604T5",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024745P1",
            "name": "A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jitendra Malik",
                    "David Martin",
                    "Charless Fowlkes",
                    "Doron Tal"
                ],
                "institution": "University of California, Berkeley"
            }
        },
        {
            "id": "20250319024745D1",
            "name": "segmentation database",
            "type": "Dataset",
            "attributes": {
                "size": "1000 images (target)",
                "current_size": "800 images",
                "segmentations_per_image": "3-4",
                "image_resolution": "481x321",
                "source": "Corel image database",
                "content": "natural scenes with discernible objects"
            }
        },
        {
            "id": "20250319024745D2",
            "name": "Corel image database",
            "type": "Dataset",
            "attributes": {
                "size": "40,000 images",
                "usage": "widely used in computer vision"
            }
        },
        {
            "id": "20250319024745D3",
            "name": "MNIST handwritten digit dataset",
            "type": "Dataset",
            "attributes": {
                "content": "handwritten digits",
                "use_case": "digit recognition"
            }
        },
        {
            "id": "20250319024745D4",
            "name": "FERET face dataset",
            "type": "Dataset",
            "attributes": {
                "content": "face images",
                "use_case": "face recognition"
            }
        },
        {
            "id": "20250319024745D5",
            "name": "Sowerby image dataset",
            "type": "Dataset",
            "attributes": {
                "size": "small",
                "availability": "not publicly available",
                "segmentations_per_image": "1"
            }
        },
        {
            "id": "20250319024745T1",
            "name": "evaluating segmentation algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024745T2",
            "name": "measuring probability distributions associated with Gestalt grouping factors",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024745T3",
            "name": "measuring statistics of image region properties",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319024745T4",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051P1",
            "name": "The Kinetics Human Action Video Dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Will Kay",
                    "João Carreira",
                    "Karen Simonyan",
                    "Brian Zhang",
                    "Chloe Hillier",
                    "Sudheendra Vijayanarasimhan",
                    "Fabio Viola",
                    "Tim Green",
                    "Trevor Back",
                    "Paul Natsev",
                    "Mustafa Suleyman",
                    "Andrew Zisserman"
                ],
                "institution": "DeepMind"
            }
        },
        {
            "id": "20250319025051D1",
            "name": "Kinetics",
            "type": "Dataset",
            "attributes": {
                "number of classes": 400,
                "clips per class": "400-1150",
                "total clips": 306245,
                "clip duration": "~10s",
                "splits": "train/val/test",
                "collection method": "Amazon Mechanical Turk (AMT)",
                "resolution": "variable",
                "frame rate": "variable",
                "non-exhaustive annotation": "yes"
            }
        },
        {
            "id": "20250319025051D2",
            "name": "HMDB-51",
            "type": "Dataset",
            "attributes": {
                "number of actions": 51,
                "total clips": 6766
            }
        },
        {
            "id": "20250319025051D3",
            "name": "UCF-101",
            "type": "Dataset",
            "attributes": {
                "number of actions": 101,
                "total clips": 13320,
                "distinct videos": 2500
            }
        },
        {
            "id": "20250319025051D4",
            "name": "ActivityNet-200",
            "type": "Dataset",
            "attributes": {
                "number of actions": 200,
                "average clips per class": 141,
                "total clips": 28108
            }
        },
        {
            "id": "20250319025051D5",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "purpose": "image classification",
                "use case": "pre-training for other tasks"
            }
        },
        {
            "id": "20250319025051D6",
            "name": "Caltech 256",
            "type": "Dataset",
            "attributes": {
                "number of categories": 256
            }
        },
        {
            "id": "20250319025051D7",
            "name": "PASCAL VOC",
            "type": "Dataset",
            "attributes": {
                "purpose": "benchmarking"
            }
        },
        {
            "id": "20250319025051R1",
            "name": "http://deepmind.com/kinetics",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319025051T1",
            "name": "human action classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T2",
            "name": "temporal localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T3",
            "name": "multi-modal analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T4",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T5",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T6",
            "name": "image segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T7",
            "name": "video modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T8",
            "name": "temporal aggregation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T9",
            "name": "gender imbalance analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T10",
            "name": "training action classification networks",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025051T11",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025545P1",
            "name": "Adapting Visual Category Models to New Domains",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Kate Saenko",
                    "Brian Kulis",
                    "Mario Fritz",
                    "Trevor Darrell"
                ],
                "institution": "UC Berkeley EECS and ICSI"
            }
        },
        {
            "id": "20250319025545D1",
            "name": "amazon",
            "type": "Dataset",
            "attributes": {
                "source": "online merchants",
                "categories": 31,
                "images_per_category": "~90"
            }
        },
        {
            "id": "20250319025545D2",
            "name": "dslr",
            "type": "Dataset",
            "attributes": {
                "resolution": "4288x2848",
                "environment": "office",
                "objects_per_category": 5
            }
        },
        {
            "id": "20250319025545D3",
            "name": "webcam",
            "type": "Dataset",
            "attributes": {
                "resolution": "640x480",
                "noise_level": "significant"
            }
        },
        {
            "id": "20250319025545D4",
            "name": "amazonINS",
            "type": "Dataset",
            "attributes": {
                "instances": 17,
                "images_per_instance": 2
            }
        },
        {
            "id": "20250319025545D5",
            "name": "dslrINS",
            "type": "Dataset",
            "attributes": {
                "instances": "same as dslr"
            }
        },
        {
            "id": "20250319025545T1",
            "name": "domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025545T2",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025545T3",
            "name": "k-nearest neighbor classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025545T4",
            "name": "metric learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025545T5",
            "name": "instance classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025924P1",
            "name": "Deeper, Broader and Artier Domain Generalization",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Da Li",
                    "Yongxin Yang",
                    "Yi-Zhe Song",
                    "Timothy M. Hospedales"
                ],
                "institution": "Queen Mary University of London, University of Edinburgh"
            }
        },
        {
            "id": "20250319025924D1",
            "name": "PACS",
            "type": "Dataset",
            "attributes": {
                "domains": [
                    "Photo",
                    "Art painting",
                    "Cartoon",
                    "Sketch"
                ],
                "size": "9991 images",
                "categories": [
                    "dog",
                    "guitar",
                    "horse",
                    "house",
                    "person",
                    "elephant",
                    "giraffe"
                ],
                "composition": "Intersection of Caltech256, Sketchy, TU-Berlin, and Google Images"
            }
        },
        {
            "id": "20250319025924D2",
            "name": "VLCS",
            "type": "Dataset",
            "attributes": {
                "domains": [
                    "Caltech",
                    "LabelMe",
                    "Pascal VOC 2007",
                    "SUN09"
                ],
                "categories": [
                    "bird",
                    "car",
                    "chair",
                    "dog",
                    "person"
                ]
            }
        },
        {
            "id": "20250319025924D3",
            "name": "OfficeCaltech",
            "type": "Dataset",
            "attributes": {
                "domains": [
                    "Amazon",
                    "Webcam",
                    "DSLR",
                    "Caltech 101"
                ]
            }
        },
        {
            "id": "20250319025924D4",
            "name": "Caltech256",
            "type": "Dataset",
            "attributes": {
                "number_of_categories": 256
            }
        },
        {
            "id": "20250319025924D5",
            "name": "Sketchy",
            "type": "Dataset",
            "attributes": {
                "domains": [
                    "Photo",
                    "Sketch"
                ],
                "source": "Intersection with TU-Berlin and Google Images"
            }
        },
        {
            "id": "20250319025924D6",
            "name": "TU-Berlin",
            "type": "Dataset",
            "attributes": {
                "content_type": "Sketch images"
            }
        },
        {
            "id": "20250319025924R1",
            "name": "http://sketchx.eecs.qmul.ac.uk/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319025924T1",
            "name": "domain generalization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025924T2",
            "name": "domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025924T3",
            "name": "instance-level matching",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025924T4",
            "name": "transferring object recognizers",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319025924T5",
            "name": "non-photorealistic image analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030126P1",
            "name": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Patrick Helber",
                    "Benjamin Bischke",
                    "Andreas Dengel",
                    "Damian Borth"
                ],
                "institution": "TU Kaiserslautern, German Research Center for Artificial Intelligence (DFKI)"
            }
        },
        {
            "id": "20250319030126D1",
            "name": "EuroSAT",
            "type": "Dataset",
            "attributes": {
                "size": "27,000 images",
                "classes": 10,
                "resolution": "10 meters per pixel",
                "spectral_bands": 13,
                "image_size": "64x64 pixels",
                "geo-referenced": "yes",
                "source": "Sentinel-2 satellite images"
            }
        },
        {
            "id": "20250319030126R1",
            "name": "https://github.com/phelber/eurosat",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319030126T1",
            "name": "land use and land cover classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030126T2",
            "name": "detecting land use and land cover changes",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030126T3",
            "name": "improving geographical maps",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030126D2",
            "name": "UC Merced (UCM) land use dataset",
            "type": "Dataset",
            "attributes": {
                "classes": 21,
                "images_per_class": 100,
                "resolution": "30 cm per pixel"
            }
        },
        {
            "id": "20250319030126D3",
            "name": "PatternNet",
            "type": "Dataset",
            "attributes": {
                "resolution": "30 cm per pixel"
            }
        },
        {
            "id": "20250319030126D4",
            "name": "NWPU-RESISC45",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030126D5",
            "name": "AID (Aerial Image Dataset)",
            "type": "Dataset",
            "attributes": {
                "classes": 30,
                "images_per_class": "200-400",
                "image_size": "600x600 pixels"
            }
        },
        {
            "id": "20250319030126D6",
            "name": "SAT-6",
            "type": "Dataset",
            "attributes": {
                "classes": 6,
                "image_size": "28x28 pixels",
                "bands": [
                    "red",
                    "green",
                    "blue",
                    "near-infrared"
                ]
            }
        },
        {
            "id": "20250319030126D7",
            "name": "BCS (Brazillian Coffee Scene)",
            "type": "Dataset",
            "attributes": {
                "classes": 2,
                "images_per_class": 1423,
                "bands": [
                    "red",
                    "green",
                    "near-infrared"
                ]
            }
        },
        {
            "id": "20250319030126D8",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "segmented_images": "yes",
                "size": "30,000 images"
            }
        },
        {
            "id": "20250319030126D9",
            "name": "Lotus Hill dataset",
            "type": "Dataset",
            "attributes": {
                "segmented_images": "yes",
                "availability": "purchase required"
            }
        },
        {
            "id": "20250319030126D10",
            "name": "ILSVRC-2012",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328P1",
            "name": "NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Eirikur Agustsson",
                    "Radu Timofte"
                ],
                "institutions": [
                    "CVL, ETH Zurich, Switzerland",
                    "Merantix GmbH"
                ]
            }
        },
        {
            "id": "20250319030328D1",
            "name": "DIV2K",
            "type": "Dataset",
            "attributes": {
                "size": "1000 images",
                "resolution": "2K",
                "partitions": "800 train, 100 validation, 100 test",
                "diversity": "covers large diversity of contents",
                "collection_method": "manually crawled from Internet",
                "purpose": "research"
            }
        },
        {
            "id": "20250319030328D2",
            "name": "Set5",
            "type": "Dataset",
            "attributes": {
                "size": "5 images"
            }
        },
        {
            "id": "20250319030328D3",
            "name": "Set14",
            "type": "Dataset",
            "attributes": {
                "size": "14 images"
            }
        },
        {
            "id": "20250319030328D4",
            "name": "B100",
            "type": "Dataset",
            "attributes": {
                "size": "100 images"
            }
        },
        {
            "id": "20250319030328D5",
            "name": "Urban100",
            "type": "Dataset",
            "attributes": {
                "size": "100 images"
            }
        },
        {
            "id": "20250319030328D6",
            "name": "Train91",
            "type": "Dataset",
            "attributes": {
                "size": "91 images"
            }
        },
        {
            "id": "20250319030328D7",
            "name": "LIVE1",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328D8",
            "name": "L20",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328D9",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328D10",
            "name": "Kodak",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328D11",
            "name": "SuperTex136",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030328R1",
            "name": "https://data.vision.ee.ethz.ch/cvl/DIV2K/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319030328T1",
            "name": "single image super-resolution",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030328T2",
            "name": "image restoration",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030328T3",
            "name": "image quality assessment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030328T4",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030328T5",
            "name": "perceptual quality assessment",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744P1",
            "name": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jeremy Irvin",
                    "Pranav Rajpurkar",
                    "Michael Ko",
                    "Yifan Yu",
                    "Silviana Ciurea-Ilcus",
                    "Chris Chute",
                    "Henrik Marklund",
                    "Behzad Haghgoo",
                    "Robyn Ball",
                    "Katie Shpanskaya",
                    "Jayne Seekins",
                    "David A. Mong",
                    "Safwan S. Halabi",
                    "Jesse K. Sandberg",
                    "Ricky Jones",
                    "David B. Larson",
                    "Curtis P. Langlotz",
                    "Bhavik N. Patel",
                    "Matthew P. Lungren",
                    "Andrew Y. Ng"
                ],
                "institution": "Stanford University"
            }
        },
        {
            "id": "20250319030744D1",
            "name": "CheXpert",
            "type": "Dataset",
            "attributes": {
                "size": "224,316 chest radiographs",
                "patients": "65,240",
                "labels": 14,
                "uncertainty_labels": "present",
                "modality": "chest radiography"
            }
        },
        {
            "id": "20250319030744D2",
            "name": "ChestX-ray14",
            "type": "Dataset",
            "attributes": {
                "description": "Hospital-Scale Chest X-Ray Database",
                "label_type": "weakly-supervised"
            }
        },
        {
            "id": "20250319030744D3",
            "name": "MIMIC-CXR",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319030744D4",
            "name": "OpenI",
            "type": "Dataset",
            "attributes": {
                "size": "7,470 frontal-view radiographs"
            }
        },
        {
            "id": "20250319030744D5",
            "name": "PLCO Lung",
            "type": "Dataset",
            "attributes": {
                "size": "185,421 images",
                "purpose": "lung cancer screening"
            }
        },
        {
            "id": "20250319030744R1",
            "name": "https://stanfordmlgroup.github.io/competitions/chexpert",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319030744T1",
            "name": "automated chest radiograph interpretation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T2",
            "name": "pathology detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T3",
            "name": "medical diagnosis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T4",
            "name": "screening",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T5",
            "name": "management of diseases",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T6",
            "name": "training convolutional neural networks",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T8",
            "name": "uncertainty detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319030744T9",
            "name": "radiology report labeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035P1",
            "name": "The iNaturalist Species Classification and Detection Dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Grant Van Horn",
                    "Oisin Mac Aodha",
                    "Yang Song",
                    "Yin Cui",
                    "Chen Sun",
                    "Alex Shepard",
                    "Hartwig Adam",
                    "Pietro Perona",
                    "Serge Belongie"
                ],
                "institutions": [
                    "Caltech",
                    "Google",
                    "Cornell Tech",
                    "iNaturalist"
                ]
            }
        },
        {
            "id": "20250319031035D1",
            "name": "iNat2017",
            "type": "Dataset",
            "attributes": {
                "size": "859,000 images",
                "species_count": "5,000+",
                "class_imbalance": "long-tail distribution",
                "bounding_boxes": "560,000+",
                "verification": "citizen scientist consensus",
                "split": "579,184 train, 95,986 validation, 182,707 test"
            }
        },
        {
            "id": "20250319031035D2",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "fine_grained_classes": "bird species, dog breeds"
            }
        },
        {
            "id": "20250319031035D3",
            "name": "CUB 200-2011",
            "type": "Dataset",
            "attributes": {
                "domain": "bird species"
            }
        },
        {
            "id": "20250319031035D4",
            "name": "Caltech-ucsd birds-200-2011",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031035D5",
            "name": "MS-COCO",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031035D6",
            "name": "OpenImages",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031035R1",
            "name": "www.inaturalist.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319031035T1",
            "name": "species classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035T2",
            "name": "species detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035T3",
            "name": "fine-grained image categorization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035T4",
            "name": "biodiversity monitoring",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035T5",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031035T6",
            "name": "low-shot learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406P1",
            "name": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Dan Hendrycks",
                    "Thomas Dietterich"
                ],
                "conference": "ICLR 2019"
            }
        },
        {
            "id": "20250319031406D1",
            "name": "IMAGENET-C",
            "type": "Dataset",
            "attributes": {
                "corruption_types": 15,
                "categories": [
                    "noise",
                    "blur",
                    "weather",
                    "digital"
                ],
                "severity_levels": 5,
                "base_dataset": "ImageNet validation images"
            }
        },
        {
            "id": "20250319031406D2",
            "name": "IMAGENET-P",
            "type": "Dataset",
            "attributes": {
                "perturbation_types": 10,
                "sequence_frames": "more than 30",
                "base_dataset": "ImageNet validation images"
            }
        },
        {
            "id": "20250319031406D3",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "reference": "Deng et al., 2009"
            }
        },
        {
            "id": "20250319031406D4",
            "name": "CIFAR-10-C",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031406D5",
            "name": "TINY IMAGENET-C",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031406D6",
            "name": "IMAGENET 64×64-C",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031406D7",
            "name": "ImageNet-22K",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031406D8",
            "name": "ImageNet-1K",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319031406R1",
            "name": "https://github.com/hendrycks/robustness",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319031406T1",
            "name": "corruption robustness",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T2",
            "name": "perturbation robustness",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T3",
            "name": "subtype robustness",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T4",
            "name": "adversarial robustness",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T5",
            "name": "speech recognition robustness",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T6",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T7",
            "name": "image classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031406T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319031816P1",
            "name": "Single Image Super-resolution from Transformed Self-Exemplars",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jia-Bin Huang",
                    "Abhishek Singh",
                    "Narendra Ahuja"
                ],
                "institution": "University of Illinois, Urbana-Champaign"
            }
        },
        {
            "id": "20250319031816D1",
            "name": "Urban 100",
            "type": "Dataset",
            "attributes": {
                "size": "100 HR images",
                "content": "urban scenes"
            }
        },
        {
            "id": "20250319031816D2",
            "name": "BSD 100",
            "type": "Dataset",
            "attributes": {
                "size": "100 test images",
                "content": "natural scenes",
                "source": "Berkeley Segmentation Dataset"
            }
        },
        {
            "id": "20250319031816D3",
            "name": "Berkeley Segmentation Dataset",
            "type": "Dataset",
            "attributes": {
                "segmented images": "yes",
                "purpose": "evaluating segmentation algorithms"
            }
        },
        {
            "id": "20250319031816T1",
            "name": "single image super-resolution",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136P1",
            "name": "VoxCeleb2: Deep Speaker Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joon Son Chung",
                    "Arsha Nagrani",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319032136D1",
            "name": "VoxCeleb2",
            "type": "Dataset",
            "attributes": {
                "size": "1,128,246 utterances",
                "speakers": "6,112",
                "gender_balance": "61% male",
                "nationalities": 145,
                "collection_method": "automated YouTube pipeline",
                "audio_visual": true,
                "noise_conditions": [
                    "background chatter",
                    "laughter",
                    "overlapping speech"
                ]
            }
        },
        {
            "id": "20250319032136D2",
            "name": "VoxCeleb1",
            "type": "Dataset",
            "attributes": {
                "usage": "speaker identification",
                "reference": "INTERSPEECH 2017"
            }
        },
        {
            "id": "20250319032136D3",
            "name": "SITW (Speakers in the Wild)",
            "type": "Dataset",
            "attributes": {
                "environment": "in the wild"
            }
        },
        {
            "id": "20250319032136D4",
            "name": "VGGFace2",
            "type": "Dataset",
            "attributes": {
                "purpose": "face recognition across pose and age"
            }
        },
        {
            "id": "20250319032136D5",
            "name": "MS-Celeb-1M",
            "type": "Dataset",
            "attributes": {
                "purpose": "large-scale face recognition"
            }
        },
        {
            "id": "20250319032136D6",
            "name": "POLYCOST",
            "type": "Dataset",
            "attributes": {
                "domain": "telephone speech"
            }
        },
        {
            "id": "20250319032136D7",
            "name": "NFI-FRITS",
            "type": "Dataset",
            "attributes": {
                "domain": "forensic speaker recognition"
            }
        },
        {
            "id": "20250319032136R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319032136T1",
            "name": "speaker verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T2",
            "name": "speaker identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T3",
            "name": "speaker diarisation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T4",
            "name": "speaker clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T5",
            "name": "visual speech synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T6",
            "name": "speech separation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T7",
            "name": "cross-modal transfer",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032136T8",
            "name": "face recognition training",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408P1",
            "name": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "German Ros",
                    "Laura Sellart",
                    "Joanna Materzynska",
                    "David Vazquez",
                    "Antonio M. Lopez"
                ],
                "institution": "Computer Vision Center, Universitat Autonoma de Barcelona"
            }
        },
        {
            "id": "20250319032408D1",
            "name": "SYNTHIA",
            "type": "Dataset",
            "attributes": {
                "size": "213,400 synthetic images",
                "classes": "13 (sky, building, road, sidewalk, fence, vegetation, lane-marking, pole, car, traffic signs, pedestrians, cyclists, miscellaneous)",
                "resolution": "960×720",
                "features": "multiple viewpoints, seasons, dynamic lighting, depth maps"
            }
        },
        {
            "id": "20250319032408D2",
            "name": "SYNTHIA-Rand",
            "type": "Dataset",
            "attributes": {
                "size": "13,400 frames",
                "purpose": "training data"
            }
        },
        {
            "id": "20250319032408D3",
            "name": "SYNTHIA-Seqs",
            "type": "Dataset",
            "attributes": {
                "size": "200,000 frames",
                "purpose": "video sequences across seasons"
            }
        },
        {
            "id": "20250319032408D4",
            "name": "CamVid",
            "type": "Dataset",
            "attributes": {
                "size": "701 images",
                "classes": "32 categories (11 commonly used)",
                "annotations": "pixel-level"
            }
        },
        {
            "id": "20250319032408D5",
            "name": "KITTI",
            "type": "Dataset",
            "attributes": {
                "size": "430 labeled images"
            }
        },
        {
            "id": "20250319032408D6",
            "name": "Urban LabelMe (U-LabelMe)",
            "type": "Dataset",
            "attributes": {
                "size": "1,000 annotated, 3,000 partial",
                "annotations": "noisy"
            }
        },
        {
            "id": "20250319032408D7",
            "name": "CBCL StreetScenes",
            "type": "Dataset",
            "attributes": {
                "size": "3,547 images",
                "annotations": "noisy"
            }
        },
        {
            "id": "20250319032408D8",
            "name": "CityScapes",
            "type": "Dataset",
            "attributes": {
                "size": "5,000 fine, 20,000 coarse annotations",
                "classes": "30"
            }
        },
        {
            "id": "20250319032408R1",
            "name": "adas.cvc.uab.es/synthia",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319032408T1",
            "name": "semantic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T2",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T3",
            "name": "traffic sign recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T4",
            "name": "road segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T5",
            "name": "pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T6",
            "name": "part models learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T8",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032408T9",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706P1",
            "name": "Learning Deep Features for Scene Recognition using Places Database",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Bolei Zhou",
                    "Agata Lapedriza",
                    "Jianxiong Xiao",
                    "Antonio Torralba",
                    "Aude Oliva"
                ],
                "institutions": [
                    "MIT",
                    "Princeton University",
                    "Universitat Oberta de Catalunya"
                ]
            }
        },
        {
            "id": "20250319032706D1",
            "name": "Places",
            "type": "Dataset",
            "attributes": {
                "size": "7 million images",
                "categories": 476,
                "subsets": [
                    "Places 205",
                    "Places 88"
                ],
                "collection_method": "Image search engines with adjective queries, AMT annotation",
                "diversity": "Higher than SUN and ImageNet",
                "resolution": "200x200 pixels or larger"
            }
        },
        {
            "id": "20250319032706D2",
            "name": "SUN database",
            "type": "Dataset",
            "attributes": {
                "categories": 397,
                "images_per_category": "100+"
            }
        },
        {
            "id": "20250319032706D3",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "type": "object-centric",
                "size": "1.2 million images (ILSVRC 2012)"
            }
        },
        {
            "id": "20250319032706D4",
            "name": "MIT Indoor67",
            "type": "Dataset",
            "attributes": {
                "categories": 67,
                "focus": "indoor places"
            }
        },
        {
            "id": "20250319032706D5",
            "name": "Scene15",
            "type": "Dataset",
            "attributes": {
                "categories": 15
            }
        },
        {
            "id": "20250319032706D6",
            "name": "SUN Attribute Database",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319032706D7",
            "name": "Caltech101",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319032706D8",
            "name": "Caltech256",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319032706D9",
            "name": "Stanford Action40",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319032706D10",
            "name": "UIUC Event8",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319032706R1",
            "name": "http://places.csail.mit.edu",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319032706T1",
            "name": "scene recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T2",
            "name": "scene classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T3",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T4",
            "name": "visual recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T5",
            "name": "training CNNs",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T7",
            "name": "cross-dataset generalization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T8",
            "name": "visualization of CNN layers",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319032706T9",
            "name": "dataset comparison",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053P1",
            "name": "VGGFace2: A dataset for recognising faces across pose and age",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Qiong Cao",
                    "Li Shen",
                    "Weidi Xie",
                    "Omkar M. Parkhi",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319033053D1",
            "name": "VGGFace2",
            "type": "Dataset",
            "attributes": {
                "size": "3.31 million images",
                "subjects": 9131,
                "variations": [
                    "pose",
                    "age",
                    "illumination",
                    "ethnicity"
                ],
                "annotations": [
                    "bounding boxes",
                    "fiducial keypoints",
                    "pose",
                    "age"
                ],
                "collection_method": "Google Image Search with automated and manual filtering"
            }
        },
        {
            "id": "20250319033053D2",
            "name": "MS-Celeb-1M",
            "type": "Dataset",
            "attributes": {
                "size": "10 million images",
                "subjects": 100000
            }
        },
        {
            "id": "20250319033053D3",
            "name": "IJB-A",
            "type": "Dataset",
            "attributes": {
                "subjects": 500,
                "content": "5712 images, 2085 videos"
            }
        },
        {
            "id": "20250319033053D4",
            "name": "IJB-B",
            "type": "Dataset",
            "attributes": {
                "subjects": 1845,
                "content": "21,800 still images, 55,000 video frames"
            }
        },
        {
            "id": "20250319033053D5",
            "name": "IJB-C",
            "type": "Dataset",
            "attributes": {
                "subjects": 3531,
                "content": "31,334 images, 117,500 video frames"
            }
        },
        {
            "id": "20250319033053D6",
            "name": "LFW (Labelled Faces in the Wild)",
            "type": "Dataset",
            "attributes": {
                "subjects": 5749,
                "images": 13233
            }
        },
        {
            "id": "20250319033053D7",
            "name": "CelebFaces+",
            "type": "Dataset",
            "attributes": {
                "subjects": 10177,
                "images": 202599
            }
        },
        {
            "id": "20250319033053D8",
            "name": "CASIA-WebFace",
            "type": "Dataset",
            "attributes": {
                "subjects": 10575,
                "images": 494414
            }
        },
        {
            "id": "20250319033053D9",
            "name": "VGGFace",
            "type": "Dataset",
            "attributes": {
                "size": "2.6 million images",
                "subjects": 2622
            }
        },
        {
            "id": "20250319033053D10",
            "name": "MegaFace",
            "type": "Dataset",
            "attributes": {
                "size": "4.7 million images",
                "subjects": 672057
            }
        },
        {
            "id": "20250319033053D11",
            "name": "UMDFaces",
            "type": "Dataset",
            "attributes": {
                "subjects": 8501,
                "images": 367920
            }
        },
        {
            "id": "20250319033053D12",
            "name": "UMDFaces-Videos",
            "type": "Dataset",
            "attributes": {
                "subjects": 3107,
                "videos": 22075
            }
        },
        {
            "id": "20250319033053R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319033053T1",
            "name": "face recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T2",
            "name": "face verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T3",
            "name": "face identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T4",
            "name": "age estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T5",
            "name": "pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T6",
            "name": "face detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T7",
            "name": "face clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033053T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447P1",
            "name": "Fine-Grained Visual Classification of Aircraft",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Subhransu Maji",
                    "Esa Rahtu",
                    "Juho Kannala",
                    "Matthew Blaschko",
                    "Andrea Vedaldi"
                ],
                "institutions": [
                    "TTI Chicago",
                    "University of Oulu",
                    "École Centrale Paris",
                    "University of Oxford"
                ]
            }
        },
        {
            "id": "20250319033447D1",
            "name": "FGVC-Aircraft",
            "type": "Dataset",
            "attributes": {
                "size": "10,000 images",
                "variants": 100,
                "families": 70,
                "manufacturers": 30,
                "resolution": "1-2 Mpixels",
                "annotation": "bounding boxes",
                "splits": [
                    "training",
                    "validation",
                    "test"
                ],
                "collection_method": "Amazon Mechanical Turk (bounding boxes), Airliners.net"
            }
        },
        {
            "id": "20250319033447D2",
            "name": "Caltech-UCSD Birds-200-2011",
            "type": "Dataset",
            "attributes": {
                "reference": "[5]"
            }
        },
        {
            "id": "20250319033447R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319033447R2",
            "name": "http://www.airliners.net/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319033447L1",
            "name": "Non-commercial Research Use",
            "type": "License",
            "attributes": {
                "description": "Images available for non-commercial research only. Copyright retained by photographers. Other uses require explicit permission."
            }
        },
        {
            "id": "20250319033447T1",
            "name": "fine-grained visual classification (FGVC)",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T2",
            "name": "variant classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T3",
            "name": "family classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T4",
            "name": "manufacturer classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T5",
            "name": "aircraft model identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T6",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033447T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832P1",
            "name": "2D Human Pose Estimation: New Benchmark and State of the Art Analysis",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Mykhaylo Andriluka",
                    "Leonid Pishchulin",
                    "Peter Gehler",
                    "Bernt Schiele"
                ],
                "institutions": [
                    "Max Planck Institute for Informatics",
                    "Max Planck Institute for Intelligent Systems",
                    "Stanford University"
                ]
            }
        },
        {
            "id": "20250319033832D1",
            "name": "MPII Human Pose",
            "type": "Dataset",
            "attributes": {
                "size": "40,522 people",
                "activities": "over 800 human activities",
                "annotations": [
                    "body joints",
                    "3D torso/head orientation",
                    "occlusion labels"
                ],
                "collection_method": "YouTube videos + Amazon Mechanical Turk",
                "training_split": "28,821 images",
                "test_split": "11,701 images"
            }
        },
        {
            "id": "20250319033832R1",
            "name": "human-pose.mpi-inf.mpg.de",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319033832D2",
            "name": "Parse",
            "type": "Dataset",
            "attributes": {
                "size": "472 images"
            }
        },
        {
            "id": "20250319033832D3",
            "name": "LSP",
            "type": "Dataset",
            "attributes": {
                "focus": "sports scenes"
            }
        },
        {
            "id": "20250319033832D4",
            "name": "FashionPose",
            "type": "Dataset",
            "attributes": {
                "focus": "clothing variability"
            }
        },
        {
            "id": "20250319033832D5",
            "name": "Armlets",
            "type": "Dataset",
            "attributes": {
                "characteristics": "occlusions/truncations"
            }
        },
        {
            "id": "20250319033832D6",
            "name": "Human3.6M",
            "type": "Dataset",
            "attributes": {
                "modality": "3D poses",
                "environment": "controlled indoor"
            }
        },
        {
            "id": "20250319033832T1",
            "name": "human pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832T2",
            "name": "upper body pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832T3",
            "name": "multiple people pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832T4",
            "name": "pose estimation in image sequences",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832T5",
            "name": "3D pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319033832T6",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024P1",
            "name": "SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Shuran Song",
                    "Samuel P. Lichtenberg",
                    "Jianxiong Xiao"
                ],
                "institution": "Princeton University"
            }
        },
        {
            "id": "20250319034024D1",
            "name": "SUN RGB-D",
            "type": "Dataset",
            "attributes": {
                "size": "10,335 RGB-D images",
                "sensors": [
                    "Intel RealSense",
                    "Asus Xtion",
                    "Kinect v1",
                    "Kinect v2"
                ],
                "annotations": [
                    "146,617 2D polygons",
                    "64,595 3D bounding boxes",
                    "3D room layout",
                    "scene category"
                ]
            }
        },
        {
            "id": "20250319034024D2",
            "name": "NYU Depth v2",
            "type": "Dataset",
            "attributes": {
                "size": "1,449 images",
                "annotations": "2D semantic segmentation"
            }
        },
        {
            "id": "20250319034024D3",
            "name": "Berkeley B3DO Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "554 images"
            }
        },
        {
            "id": "20250319034024D4",
            "name": "SUN3D",
            "type": "Dataset",
            "attributes": {
                "size": "3,389 frames"
            }
        },
        {
            "id": "20250319034024D5",
            "name": "PASCAL VOC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034024D6",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034024D7",
            "name": "Cornell RGBD dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034024R1",
            "name": "http://rgbd.cs.princeton.edu",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319034024T1",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T2",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T3",
            "name": "semantic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T4",
            "name": "scene categorization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T5",
            "name": "context reasoning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T6",
            "name": "mid-level recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T7",
            "name": "surface orientation estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034024T8",
            "name": "room layout estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034224P1",
            "name": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Khurram Soomro",
                    "Amir Roshan Zamir",
                    "Mubarak Shah"
                ],
                "institution": "University of Central Florida"
            }
        },
        {
            "id": "20250319034224D1",
            "name": "UCF101",
            "type": "Dataset",
            "attributes": {
                "number of classes": 101,
                "number of clips": "over 13k",
                "duration": "27 hours",
                "resolution": "320x240",
                "frame rate": "25 FPS",
                "format": "DivX codec",
                "source": "YouTube",
                "challenges": [
                    "camera motion",
                    "cluttered background"
                ],
                "cross-validation": "25-fold",
                "audio": "preserved for new 51 actions",
                "action types": [
                    "Human-Object Interaction",
                    "Body-Motion Only",
                    "Human-Human Interaction",
                    "Playing Musical Instruments",
                    "Sports"
                ]
            }
        },
        {
            "id": "20250319034224D2",
            "name": "UCF50",
            "type": "Dataset",
            "attributes": {
                "number of classes": 50,
                "number of clips": 6681
            }
        },
        {
            "id": "20250319034224D3",
            "name": "HMDB51",
            "type": "Dataset",
            "attributes": {
                "number of classes": 51,
                "number of clips": 6766
            }
        },
        {
            "id": "20250319034224D4",
            "name": "KTH",
            "type": "Dataset",
            "attributes": {
                "number of classes": 6
            }
        },
        {
            "id": "20250319034224D5",
            "name": "Weizmann",
            "type": "Dataset",
            "attributes": {
                "number of classes": 9
            }
        },
        {
            "id": "20250319034224D6",
            "name": "UCF Sports",
            "type": "Dataset",
            "attributes": {
                "number of classes": 9
            }
        },
        {
            "id": "20250319034224D7",
            "name": "IXMAS",
            "type": "Dataset",
            "attributes": {
                "number of classes": 11
            }
        },
        {
            "id": "20250319034224D8",
            "name": "UCF11",
            "type": "Dataset",
            "attributes": {
                "number of classes": 11
            }
        },
        {
            "id": "20250319034224D9",
            "name": "HOHA",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034224D10",
            "name": "Olympic",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034224R1",
            "name": "http://crcv.ucf.edu/data/UCF101.php",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319034224T1",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034224T2",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533P1",
            "name": "The Kinetics Human Action Video Dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Will Kay",
                    "Jo˜ao Carreira",
                    "Karen Simonyan",
                    "Brian Zhang",
                    "Chloe Hillier",
                    "Sudheendra Vijayanarasimhan",
                    "Fabio Viola",
                    "Tim Green",
                    "Trevor Back",
                    "Paul Natsev",
                    "Mustafa Suleyman",
                    "Andrew Zisserman"
                ],
                "institution": "DeepMind/Google"
            }
        },
        {
            "id": "20250319034533D1",
            "name": "Kinetics",
            "type": "Dataset",
            "attributes": {
                "number of classes": 400,
                "total clips": 306245,
                "clip duration": "~10s",
                "splits": "train/val/test",
                "source": "YouTube",
                "resolution": "variable",
                "annotation": "non-exhaustive",
                "collection method": "Amazon Mechanical Turk"
            }
        },
        {
            "id": "20250319034533D2",
            "name": "HMDB-51",
            "type": "Dataset",
            "attributes": {
                "number of classes": 51,
                "total clips": 6766,
                "videos": 3312
            }
        },
        {
            "id": "20250319034533D3",
            "name": "UCF-101",
            "type": "Dataset",
            "attributes": {
                "number of classes": 101,
                "total clips": 13320,
                "videos": 2500
            }
        },
        {
            "id": "20250319034533D4",
            "name": "ActivityNet-200",
            "type": "Dataset",
            "attributes": {
                "number of classes": 200,
                "total clips": 28108,
                "videos": 19994
            }
        },
        {
            "id": "20250319034533D5",
            "name": "Caltech 256",
            "type": "Dataset",
            "attributes": {
                "number of categories": 256
            }
        },
        {
            "id": "20250319034533D6",
            "name": "PASCAL VOC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034533D7",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034533R1",
            "name": "http://deepmind.com/kinetics",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319034533T1",
            "name": "human action classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T2",
            "name": "temporal localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T3",
            "name": "multi-modal analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T4",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T5",
            "name": "training action classification models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T7",
            "name": "video modeling",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T8",
            "name": "spatio-temporal feature learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T9",
            "name": "temporal aggregation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T10",
            "name": "attention mechanisms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T11",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T12",
            "name": "image segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T13",
            "name": "non-visual modalities analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T14",
            "name": "pre-training",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T15",
            "name": "human pose estimation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034533T16",
            "name": "object category recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844P1",
            "name": "HMDB: A Large Video Database for Human Motion Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "H. Kuehne",
                    "H. Jhuang",
                    "E. Garrote",
                    "T. Poggio",
                    "T. Serre"
                ],
                "institutions": [
                    "Karlsruhe Institute of Technology",
                    "Massachusetts Institute of Technology",
                    "Brown University"
                ]
            }
        },
        {
            "id": "20250319034844D1",
            "name": "HMDB51",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 51,
                "number of clips": "6,766",
                "sources": [
                    "movies",
                    "YouTube"
                ],
                "annotations": [
                    "camera motion",
                    "viewpoint",
                    "video quality",
                    "number of people"
                ],
                "normalization": "scaled to 240p, 30fps",
                "stabilization": "performed using image stitching techniques"
            }
        },
        {
            "id": "20250319034844D2",
            "name": "KTH",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 6,
                "clips per category": 100
            }
        },
        {
            "id": "20250319034844D3",
            "name": "Weizmann",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 9,
                "clips per category": 9
            }
        },
        {
            "id": "20250319034844D4",
            "name": "IXMAS",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 11,
                "clips per category": 33
            }
        },
        {
            "id": "20250319034844D5",
            "name": "Hollywood",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 8,
                "clips per category": "30-129"
            }
        },
        {
            "id": "20250319034844D6",
            "name": "Hollywood2",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 12,
                "clips per category": "61-278"
            }
        },
        {
            "id": "20250319034844D7",
            "name": "UCFSports",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 9,
                "clips per category": "14-35"
            }
        },
        {
            "id": "20250319034844D8",
            "name": "UCFYouTube",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 11,
                "clips per category": 100
            }
        },
        {
            "id": "20250319034844D9",
            "name": "UCF50",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 50,
                "min clips per category": 100
            }
        },
        {
            "id": "20250319034844D10",
            "name": "Olympic Sports dataset",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 16,
                "clips per category": 50
            }
        },
        {
            "id": "20250319034844D11",
            "name": "LabelMe",
            "type": "Dataset",
            "attributes": {
                "number of categories": 200,
                "size": "30,000 images",
                "segmented images": "yes"
            }
        },
        {
            "id": "20250319034844D12",
            "name": "Lotus Hill dataset",
            "type": "Dataset",
            "attributes": {
                "size": "50,000 images",
                "segmented images": "yes",
                "availability": "purchase required"
            }
        },
        {
            "id": "20250319034844D13",
            "name": "Caltech101",
            "type": "Dataset",
            "attributes": {
                "number of categories": 101
            }
        },
        {
            "id": "20250319034844D14",
            "name": "Caltech256",
            "type": "Dataset",
            "attributes": {
                "number of categories": 256
            }
        },
        {
            "id": "20250319034844D15",
            "name": "MSRC",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034844D16",
            "name": "PASCAL",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319034844R1",
            "name": "http://serre-lab.clps.brown.edu/resources/HMDB/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319034844T1",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T2",
            "name": "human motion recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T3",
            "name": "video classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T4",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T5",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T6",
            "name": "scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T7",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T8",
            "name": "activity classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T9",
            "name": "image annotation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T10",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T11",
            "name": "part models learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319034844T12",
            "name": "biological motion perception",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231P1",
            "name": "ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Fabian Caba Heilbron",
                    "Victor Escorcia",
                    "Bernard Ghanem",
                    "Juan Carlos Niebles"
                ],
                "institutions": [
                    "Universidad del Norte, Colombia",
                    "King Abdullah University of Science and Technology (KAUST), Saudi Arabia"
                ]
            }
        },
        {
            "id": "20250319035231D1",
            "name": "ActivityNet",
            "type": "Dataset",
            "attributes": {
                "size": "849 video hours",
                "number of classes": 203,
                "average videos per class": 137,
                "activity instances per video": 1.41,
                "structure": "hierarchical taxonomy (4 levels)",
                "annotation type": "temporal boundaries",
                "collection method": "Amazon Mechanical Turk"
            }
        },
        {
            "id": "20250319035231D2",
            "name": "UCF101",
            "type": "Dataset",
            "attributes": {
                "number of categories": 101
            }
        },
        {
            "id": "20250319035231D3",
            "name": "HMDB51",
            "type": "Dataset",
            "attributes": {
                "number of categories": 51
            }
        },
        {
            "id": "20250319035231D4",
            "name": "Hollywood dataset",
            "type": "Dataset",
            "attributes": {
                "number of action categories": 12
            }
        },
        {
            "id": "20250319035231D5",
            "name": "Sports-1M",
            "type": "Dataset",
            "attributes": {
                "number of categories": 500,
                "annotation method": "automatic tagging",
                "noise level": "high"
            }
        },
        {
            "id": "20250319035231D6",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "description": "A Large-Scale Hierarchical Image Database"
            }
        },
        {
            "id": "20250319035231D7",
            "name": "TinyImages",
            "type": "Dataset",
            "attributes": {
                "size": "80 million images",
                "resolution": "32x32",
                "noise level": "high"
            }
        },
        {
            "id": "20250319035231R1",
            "name": "http://www.activity-net.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319035231T1",
            "name": "human activity understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T2",
            "name": "untrimmed video classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T3",
            "name": "trimmed activity classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T4",
            "name": "activity detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T5",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T6",
            "name": "object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T7",
            "name": "scene recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035231T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620P1",
            "name": "A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "F. Perazzi",
                    "J. Pont-Tuset",
                    "B. McWilliams",
                    "L. Van Gool",
                    "M. Gross",
                    "A. Sorkine-Hornung"
                ],
                "institution": "ETH Zurich, Disney Research"
            }
        },
        {
            "id": "20250319035620D1",
            "name": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "type": "Dataset",
            "attributes": {
                "resolution": "Full HD 1080p",
                "sequences": 50,
                "annotated_frames": 3455,
                "challenges": [
                    "occlusions",
                    "motion-blur",
                    "appearance changes"
                ],
                "content_classes": [
                    "humans",
                    "animals",
                    "vehicles",
                    "objects"
                ]
            }
        },
        {
            "id": "20250319035620D2",
            "name": "Freiburg-Berkeley Motion Segmentation dataset (MoSeg)",
            "type": "Dataset",
            "attributes": {
                "resolution": "low",
                "annotation_type": "sparse subset of frames"
            }
        },
        {
            "id": "20250319035620D3",
            "name": "Berkeley Video Segmentation Dataset (BVSD)",
            "type": "Dataset",
            "attributes": {
                "sequences": 100,
                "annotation_type": "fragmented segments"
            }
        },
        {
            "id": "20250319035620D4",
            "name": "SegTrack",
            "type": "Dataset",
            "attributes": {
                "sequences": 6,
                "resolution": "low",
                "content": [
                    "humans",
                    "animals"
                ]
            }
        },
        {
            "id": "20250319035620D5",
            "name": "VSB100",
            "type": "Dataset",
            "attributes": {
                "purpose": "over-segmentation and motion-segmentation tasks"
            }
        },
        {
            "id": "20250319035620T1",
            "name": "video object segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T2",
            "name": "motion segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T3",
            "name": "over-segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T4",
            "name": "salient object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T5",
            "name": "object tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T6",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T7",
            "name": "contour accuracy evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035620T8",
            "name": "temporal coherence evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846P1",
            "name": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jun Xu",
                    "Tao Mei",
                    "Ting Yao",
                    "Yong Rui"
                ],
                "institution": "Microsoft Research"
            }
        },
        {
            "id": "20250319035846D1",
            "name": "MSR-VTT",
            "type": "Dataset",
            "attributes": {
                "size": "10K video clips",
                "duration": "41.2 hours",
                "clip-sentence_pairs": "200K",
                "categories": 20,
                "annotation": "20 sentences per clip via AMT",
                "modalities": "video + audio"
            }
        },
        {
            "id": "20250319035846D2",
            "name": "MSVD",
            "type": "Dataset",
            "attributes": {
                "size": "1,970 videos",
                "annotation_method": "AMT workers"
            }
        },
        {
            "id": "20250319035846D3",
            "name": "YouCook",
            "type": "Dataset",
            "attributes": {
                "domain": "cooking"
            }
        },
        {
            "id": "20250319035846D4",
            "name": "TACoS",
            "type": "Dataset",
            "attributes": {
                "domain": "cooking"
            }
        },
        {
            "id": "20250319035846D5",
            "name": "M-VAD",
            "type": "Dataset",
            "attributes": {
                "domain": "movie",
                "annotation_source": "Audio Description (AD)"
            }
        },
        {
            "id": "20250319035846D6",
            "name": "MPII-MD",
            "type": "Dataset",
            "attributes": {
                "domain": "movie"
            }
        },
        {
            "id": "20250319035846D7",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {
                "usage": "pre-training visual models"
            }
        },
        {
            "id": "20250319035846T1",
            "name": "video to text",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846T2",
            "name": "video description generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846T3",
            "name": "video understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846T4",
            "name": "sentence generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846T5",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319035846T6",
            "name": "video summarization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048P1",
            "name": "VoxCeleb2: Deep Speaker Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joon Son Chung",
                    "Arsha Nagrani",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319040048D1",
            "name": "VoxCeleb2",
            "type": "Dataset",
            "attributes": {
                "size": "1,128,246 utterances",
                "speakers": 6112,
                "hours": 2442,
                "gender_ratio": "61% male",
                "nationalities": 145,
                "multilingual": "yes",
                "noise_conditions": [
                    "background chatter",
                    "laughter",
                    "music"
                ],
                "collection_method": "automated YouTube pipeline"
            }
        },
        {
            "id": "20250319040048D2",
            "name": "VoxCeleb1",
            "type": "Dataset",
            "attributes": {
                "speakers": 1251,
                "reference": "INTERSPEECH 2017"
            }
        },
        {
            "id": "20250319040048D3",
            "name": "SITW (Speakers in the Wild)",
            "type": "Dataset",
            "attributes": {
                "environment": "unconstrained",
                "use_case": "speaker recognition benchmark"
            }
        },
        {
            "id": "20250319040048D4",
            "name": "VGGFace2",
            "type": "Dataset",
            "attributes": {
                "content_type": "face images",
                "subjects": "over 9,000 identities"
            }
        },
        {
            "id": "20250319040048D5",
            "name": "MS-Celeb-1M",
            "type": "Dataset",
            "attributes": {
                "purpose": "large-scale face recognition",
                "scale": "1 million celebrities"
            }
        },
        {
            "id": "20250319040048D6",
            "name": "POLYCOST",
            "type": "Dataset",
            "attributes": {
                "source": "telephone speech",
                "language": "multiple"
            }
        },
        {
            "id": "20250319040048D7",
            "name": "NFI-FRITS",
            "type": "Dataset",
            "attributes": {
                "application": "forensic speaker recognition"
            }
        },
        {
            "id": "20250319040048R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319040048T1",
            "name": "speaker recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048T2",
            "name": "speaker verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048T3",
            "name": "speaker identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048T4",
            "name": "speaker diarisation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048T5",
            "name": "visual speech synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040048T6",
            "name": "cross-modal transfer",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311P1",
            "name": "NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Amir Shahroudy",
                    "Jun Liu",
                    "Tian-Tsong Ng",
                    "Gang Wang"
                ],
                "institution": "Nanyang Technological University, Institute for Infocomm Research",
                "year": "2016"
            }
        },
        {
            "id": "20250319040311D1",
            "name": "NTU RGB+D",
            "type": "Dataset",
            "attributes": {
                "samples": "56,880",
                "classes": 60,
                "subjects": 40,
                "views": 80,
                "sensor": "Microsoft Kinect v2",
                "modalities": [
                    "RGB",
                    "depth",
                    "skeleton (3D joints)",
                    "infrared"
                ],
                "year": "2016"
            }
        },
        {
            "id": "20250319040311D2",
            "name": "MSR-Action3D",
            "type": "Dataset",
            "attributes": {
                "subjects": 10,
                "views": 1,
                "sensor": "Kinect v1",
                "year": "2010"
            }
        },
        {
            "id": "20250319040311D3",
            "name": "CAD-60",
            "type": "Dataset",
            "attributes": {
                "samples": 60,
                "views": "multiple",
                "sensor": "Kinect v1",
                "year": "2011"
            }
        },
        {
            "id": "20250319040311D4",
            "name": "CAD-120",
            "type": "Dataset",
            "attributes": {
                "samples": 120,
                "sensor": "Kinect v1",
                "year": "2013"
            }
        },
        {
            "id": "20250319040311D5",
            "name": "RGBD-HuDaAct",
            "type": "Dataset",
            "attributes": {
                "samples": 1189,
                "classes": 12,
                "sensor": "Kinect v1",
                "year": "2011"
            }
        },
        {
            "id": "20250319040311D6",
            "name": "MSRDailyActivity3D",
            "type": "Dataset",
            "attributes": {
                "samples": 320,
                "classes": 16,
                "sensor": "Kinect v1",
                "year": "2012"
            }
        },
        {
            "id": "20250319040311D7",
            "name": "Act42",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2012"
            }
        },
        {
            "id": "20250319040311D8",
            "name": "3D Action Pairs",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2013"
            }
        },
        {
            "id": "20250319040311D9",
            "name": "Multiview 3D Event",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2013"
            }
        },
        {
            "id": "20250319040311D10",
            "name": "Northwestern-UCLA",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2014"
            }
        },
        {
            "id": "20250319040311D11",
            "name": "UWA3D Multiview",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2014"
            }
        },
        {
            "id": "20250319040311D12",
            "name": "Office Activity",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2014"
            }
        },
        {
            "id": "20250319040311D13",
            "name": "UTD-MHAD",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2015"
            }
        },
        {
            "id": "20250319040311D14",
            "name": "UWA3D Multiview II",
            "type": "Dataset",
            "attributes": {
                "sensor": "Kinect v1",
                "year": "2015"
            }
        },
        {
            "id": "20250319040311R1",
            "name": "http://rose1.ntu.edu.sg/datasets/actionrecognition.asp",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319040311T1",
            "name": "3D human activity analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T2",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T3",
            "name": "RGB+D human action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T4",
            "name": "3D action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T5",
            "name": "human activity analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T6",
            "name": "3D object recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T7",
            "name": "3D scene understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T8",
            "name": "depth-based action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T9",
            "name": "RGB+D-based action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T10",
            "name": "3D-based action analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T11",
            "name": "action classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040311T12",
            "name": "human action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622P1",
            "name": "BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Fisher Yu",
                    "Haofeng Chen",
                    "Xin Wang",
                    "Wenqi Xian",
                    "Yingying Chen",
                    "Fangchen Liu",
                    "Vashisht Madhavan",
                    "Trevor Darrell"
                ],
                "institutions": [
                    "UC Berkeley",
                    "Cornell University",
                    "UC San Diego",
                    "Element, Inc."
                ]
            }
        },
        {
            "id": "20250319040622D1",
            "name": "BDD100K",
            "type": "Dataset",
            "attributes": {
                "size": "100K videos",
                "resolution": "720p",
                "frame_rate": "30fps",
                "annotations": "10 tasks",
                "geographic_diversity": "New York, San Francisco Bay Area, and other regions",
                "weather_conditions": "diverse including snow and rain",
                "time_of_day": "day and night",
                "split": "70K training, 10K validation, 20K testing"
            }
        },
        {
            "id": "20250319040622R1",
            "name": "https://bdd-data.berkeley.edu",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319040622D2",
            "name": "Cityscapes",
            "type": "Dataset",
            "attributes": {
                "annotations": "instance-level semantic segmentation",
                "data_collection": "own vehicle",
                "diversity": "limited"
            }
        },
        {
            "id": "20250319040622P2",
            "name": "The cityscapes dataset for semantic urban scene understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "M. Cordts",
                    "M. Omran",
                    "S. Ramos",
                    "T. Rehfeld",
                    "M. Enzweiler",
                    "R. Benenson",
                    "U. Franke",
                    "S. Roth",
                    "B. Schiele"
                ]
            }
        },
        {
            "id": "20250319040622D3",
            "name": "KITTI",
            "type": "Dataset",
            "attributes": {
                "data_sources": "LiDAR scanned points",
                "focus": "autonomous driving"
            }
        },
        {
            "id": "20250319040622P3",
            "name": "Vision meets robotics: The kitti dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "A. Geiger",
                    "P. Lenz",
                    "C. Stiller",
                    "R. Urtasun"
                ]
            }
        },
        {
            "id": "20250319040622D4",
            "name": "Mapillary Vistas",
            "type": "Dataset",
            "attributes": {
                "annotations": "fine-grained",
                "collection_method": "crowdsourced",
                "structure": "one-off frames"
            }
        },
        {
            "id": "20250319040622P4",
            "name": "The mapillary vistas dataset for semantic understanding of street scenes",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "G. Neuhold",
                    "T. Ollmann",
                    "S. R. Bulò",
                    "P. Kontschieder"
                ]
            }
        },
        {
            "id": "20250319040622D5",
            "name": "Waymo Open Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1150 sequences, 230K frames",
                "annotations": "9.9M 2D boxes"
            }
        },
        {
            "id": "20250319040622P5",
            "name": "Scalability in perception for autonomous driving: Waymo open dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "P. Sun",
                    "H. Kretzschmar",
                    "X. Dotiwalla",
                    "A. Chouard",
                    "V. Patnaik",
                    "P. Tsui",
                    "J. Guo",
                    "Y. Zhou",
                    "Y. Chai",
                    "B. Caine",
                    "et al."
                ]
            }
        },
        {
            "id": "20250319040622D6",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319040622P6",
            "name": "ImageNet: A Large-Scale Hierarchical Image Database",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "J. Deng",
                    "W. Dong",
                    "R. Socher",
                    "L.-J. Li",
                    "K. Li",
                    "L. Fei-Fei"
                ]
            }
        },
        {
            "id": "20250319040622D7",
            "name": "Caltech Lanes Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1,224 images"
            }
        },
        {
            "id": "20250319040622D8",
            "name": "Road Marking Dataset",
            "type": "Dataset",
            "attributes": {
                "size": "1,443 images",
                "classes": "11 classes of lane markings"
            }
        },
        {
            "id": "20250319040622D9",
            "name": "VPGNet",
            "type": "Dataset",
            "attributes": {
                "size": "about 20,000 images",
                "location": "Seoul"
            }
        },
        {
            "id": "20250319040622T1",
            "name": "image tagging",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T2",
            "name": "lane detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T3",
            "name": "drivable area segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T4",
            "name": "road object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T5",
            "name": "semantic segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T6",
            "name": "instance segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T7",
            "name": "multi-object detection tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T8",
            "name": "multi-object segmentation tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T9",
            "name": "domain adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T10",
            "name": "imitation learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T11",
            "name": "object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T12",
            "name": "multiple object tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319040622T13",
            "name": "multiple object tracking and segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030P1",
            "name": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Gunnar A. Sigurdsson",
                    "Gül Varol",
                    "Xiaolong Wang",
                    "Ali Farhadi",
                    "Ivan Laptev",
                    "Abhinav Gupta"
                ],
                "institutions": [
                    "Carnegie Mellon University",
                    "Inria",
                    "University of Washington",
                    "The Allen Institute for AI"
                ]
            }
        },
        {
            "id": "20250319041030D1",
            "name": "Charades",
            "type": "Dataset",
            "attributes": {
                "size": "9,848 videos",
                "average_length": "30 seconds",
                "action_classes": 157,
                "object_classes": 46,
                "scenes": "15 indoor types",
                "collection_method": "Amazon Mechanical Turk",
                "annotations": [
                    "temporally localized actions",
                    "free-text descriptions",
                    "object interactions"
                ]
            }
        },
        {
            "id": "20250319041030D2",
            "name": "ActivityNet",
            "type": "Dataset",
            "attributes": {
                "size": "27,847 videos",
                "origin": "Internet videos"
            }
        },
        {
            "id": "20250319041030D3",
            "name": "UCF101",
            "type": "Dataset",
            "attributes": {
                "size": "13K videos"
            }
        },
        {
            "id": "20250319041030D4",
            "name": "HMDB51",
            "type": "Dataset",
            "attributes": {
                "size": "7K videos"
            }
        },
        {
            "id": "20250319041030D5",
            "name": "Sports1M",
            "type": "Dataset",
            "attributes": {
                "size": "1.1M videos"
            }
        },
        {
            "id": "20250319041030D6",
            "name": "MPII Cooking",
            "type": "Dataset",
            "attributes": {
                "action_classes": 78
            }
        },
        {
            "id": "20250319041030D7",
            "name": "ADL",
            "type": "Dataset",
            "attributes": {
                "size": "46 videos"
            }
        },
        {
            "id": "20250319041030D8",
            "name": "KTH action dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041030R1",
            "name": "http://allenai.org/plato/charades/",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319041030T1",
            "name": "action recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T2",
            "name": "automatic description generation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T3",
            "name": "video captioning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T4",
            "name": "object detection in videos",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T5",
            "name": "modeling context",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T6",
            "name": "learning object states",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T7",
            "name": "human-object interactions",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041030T9",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315P1",
            "name": "Object Tracking Benchmark",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Yi Wu",
                    "Jongwoo Lim",
                    "Ming-Hsuan Yang"
                ],
                "institution": "Nanjing University of Information Science and Technology, Hanyang University, University of California at Merced"
            }
        },
        {
            "id": "20250319041315D1",
            "name": "TB-100",
            "type": "Dataset",
            "attributes": {
                "size": "100 sequences",
                "description": "benchmark dataset for object tracking with full annotations",
                "content": "36 body, 26 face/head videos"
            }
        },
        {
            "id": "20250319041315D2",
            "name": "TB-50",
            "type": "Dataset",
            "attributes": {
                "size": "50 sequences",
                "description": "subset of TB-100 with more challenging sequences"
            }
        },
        {
            "id": "20250319041315D3",
            "name": "VIVID",
            "type": "Dataset",
            "attributes": {
                "application": "surveillance scenarios"
            }
        },
        {
            "id": "20250319041315D4",
            "name": "CAVIAR",
            "type": "Dataset",
            "attributes": {
                "application": "surveillance scenarios"
            }
        },
        {
            "id": "20250319041315D5",
            "name": "PETS",
            "type": "Dataset",
            "attributes": {
                "application": "surveillance scenarios"
            }
        },
        {
            "id": "20250319041315D6",
            "name": "Berkeley segmentation",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041315D7",
            "name": "FERET face recognition",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041315D8",
            "name": "optical flow dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041315D9",
            "name": "Pascal Visual Object Classes (VOC)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041315R1",
            "name": "http://pami.visual-tracking.net",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319041315T1",
            "name": "object tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T2",
            "name": "performance evaluation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T3",
            "name": "model update",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T4",
            "name": "semi-supervised learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T5",
            "name": "online boosting",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T6",
            "name": "template matching",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T7",
            "name": "ratio shift",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T8",
            "name": "peak difference",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T9",
            "name": "optical flow",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T10",
            "name": "face recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041315T11",
            "name": "segmentation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706P1",
            "name": "Argoverse: 3D Tracking and Forecasting with Rich Maps",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Ming-Fang Chang",
                    "John Lambert",
                    "Patsorn Sangkloy",
                    "Jagjeet Singh",
                    "Sławomir B ˛ak",
                    "Andrew Hartnett",
                    "De Wang",
                    "Peter Carr",
                    "Simon Lucey",
                    "Deva Ramanan",
                    "James Hays"
                ],
                "institutions": [
                    "Argo AI",
                    "Carnegie Mellon University",
                    "Georgia Institute of Technology"
                ]
            }
        },
        {
            "id": "20250319041706D1",
            "name": "Argoverse 3D Tracking",
            "type": "Dataset",
            "attributes": {
                "version": "v1.1",
                "release_date": "October 2019",
                "size": "113 logs, 11,052 tracked objects",
                "sensors": "LiDAR, 7 cameras, stereo cameras",
                "classes": 15,
                "locations": [
                    "Pittsburgh",
                    "Miami"
                ],
                "annotation": "3D cuboids",
                "frequency": "30fps (cameras), 10Hz (LiDAR)"
            }
        },
        {
            "id": "20250319041706D2",
            "name": "Argoverse Motion Forecasting",
            "type": "Dataset",
            "attributes": {
                "version": "v1.1",
                "release_date": "October 2019",
                "scenarios": 324557,
                "duration": "5 seconds",
                "focal_object": "vehicle",
                "mined_from": "320 hours"
            }
        },
        {
            "id": "20250319041706D3",
            "name": "KITTI",
            "type": "Dataset",
            "attributes": {
                "3D_annotations": "yes",
                "map_data": "no",
                "camera_FOV": "frontal"
            }
        },
        {
            "id": "20250319041706D4",
            "name": "nuScenes",
            "type": "Dataset",
            "attributes": {
                "map_type": "rasterized ROI",
                "2D_semantic_maps": "yes",
                "3D_annotations": "yes"
            }
        },
        {
            "id": "20250319041706D5",
            "name": "ApolloScape Tracking",
            "type": "Dataset",
            "attributes": {
                "duration": "155 minutes"
            }
        },
        {
            "id": "20250319041706D6",
            "name": "Lyft Dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D7",
            "name": "H3D",
            "type": "Dataset",
            "attributes": {
                "3D_annotations": "yes"
            }
        },
        {
            "id": "20250319041706D8",
            "name": "TorontoCity",
            "type": "Dataset",
            "attributes": {
                "purpose": "map construction",
                "3D_annotations": "no"
            }
        },
        {
            "id": "20250319041706D9",
            "name": "VIPER",
            "type": "Dataset",
            "attributes": {
                "simulated": "yes",
                "3D_annotations": "yes"
            }
        },
        {
            "id": "20250319041706D10",
            "name": "Waymo Open Dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D11",
            "name": "ApolloScape",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D12",
            "name": "Cityscapes",
            "type": "Dataset",
            "attributes": {
                "purpose": "semantic urban scene understanding"
            }
        },
        {
            "id": "20250319041706D13",
            "name": "Oxford RobotCar",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D14",
            "name": "PASCAL",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D15",
            "name": "PETS 2016",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319041706D16",
            "name": "CARLA",
            "type": "Dataset",
            "attributes": {
                "simulated": "yes"
            }
        },
        {
            "id": "20250319041706R1",
            "name": "https://www.argoverse.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319041706L1",
            "name": "Creative Commons",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319041706T1",
            "name": "3D tracking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T2",
            "name": "motion forecasting",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T3",
            "name": "trajectory forecasting",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T4",
            "name": "map automation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T5",
            "name": "3D object detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T6",
            "name": "object localization",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T7",
            "name": "automatic map creation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319041706T8",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130P1",
            "name": "AUDIOSET: AN ONTOLOGY AND HUMAN-LABELED DATASET FOR AUDIO EVENTS",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Jort F. Gemmeke",
                    "Daniel P.W. Ellis",
                    "Dylan Freedman",
                    "Aren Jansen",
                    "Wade Lawrence",
                    "R. Channing Moore",
                    "Manoj Plakal",
                    "Marvin Ritter"
                ],
                "institution": "Google, Inc."
            }
        },
        {
            "id": "20250319042130D1",
            "name": "AudioSet",
            "type": "Dataset",
            "attributes": {
                "size": "1,789,621 segments (4,971 hours)",
                "classes": 632,
                "ontology": "hierarchical",
                "format": "10-second YouTube segments",
                "labeling": "human-annotated"
            }
        },
        {
            "id": "20250319042130D2",
            "name": "UrbanSound taxonomy",
            "type": "Dataset",
            "attributes": {
                "size": "18.5 hours",
                "categories": 10,
                "temporal resolution": "fine"
            }
        },
        {
            "id": "20250319042130D3",
            "name": "DCASE2016 dataset",
            "type": "Dataset",
            "attributes": {
                "size": "90 minutes",
                "categories": 13,
                "environment": "real home and outdoor recordings"
            }
        },
        {
            "id": "20250319042130D4",
            "name": "AudioSentiBank",
            "type": "Dataset",
            "attributes": {
                "size": "1,267 hours",
                "tags": 1123,
                "content": "adjective-noun/verb-noun sentiment tags"
            }
        },
        {
            "id": "20250319042130D5",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042130R1",
            "name": "g.co/audioset",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319042130T1",
            "name": "audio event detection",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T2",
            "name": "audio event classification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T3",
            "name": "sound understanding",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T4",
            "name": "acoustic scene analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T5",
            "name": "automatic audio event recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T6",
            "name": "training audio event recognizers",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T7",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042130T8",
            "name": "audio content analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042506P1",
            "name": "VoxCeleb: a large-scale speaker identification dataset",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Arsha Nagrani",
                    "Joon Son Chung",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319042506D1",
            "name": "VoxCeleb",
            "type": "Dataset",
            "attributes": {
                "size": "over 100,000 utterances",
                "number of speakers": 1251,
                "gender balance": "55% male",
                "conditions": "real-world noise",
                "collection method": "automated pipeline from YouTube",
                "input features": "16kHz spectrograms"
            }
        },
        {
            "id": "20250319042506D2",
            "name": "SITW (Speakers in the Wild)",
            "type": "Dataset",
            "attributes": {
                "number of speakers": 299,
                "conditions": "unconstrained",
                "labeling method": "hand-annotated"
            }
        },
        {
            "id": "20250319042506D3",
            "name": "NIST SRE",
            "type": "Dataset",
            "attributes": {
                "availability": "not freely available"
            }
        },
        {
            "id": "20250319042506D4",
            "name": "VGG Face dataset",
            "type": "Dataset",
            "attributes": {
                "number of identities": 2622,
                "source": "Freebase and IMDB"
            }
        },
        {
            "id": "20250319042506D5",
            "name": "ELSDSR",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D6",
            "name": "MIT Mobile",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D7",
            "name": "SWB (Switchboard)",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D8",
            "name": "POLYCOST",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D9",
            "name": "ICSI Meeting Corpus",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D10",
            "name": "Forensic Comparison",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D11",
            "name": "ANDOSL",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D12",
            "name": "TIMIT",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D13",
            "name": "NTIMIT",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D14",
            "name": "CTIMIT",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506D15",
            "name": "ImageNet",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042506R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319042506T1",
            "name": "speaker identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042506T2",
            "name": "speaker verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813P1",
            "name": "VoxCeleb2: Deep Speaker Recognition",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joon Son Chung",
                    "Arsha Nagrani",
                    "Andrew Zisserman"
                ],
                "institution": "University of Oxford"
            }
        },
        {
            "id": "20250319042813D1",
            "name": "VoxCeleb2",
            "type": "Dataset",
            "attributes": {
                "size": "1,128,246 utterances",
                "speakers": 6112,
                "hours": 2442,
                "gender_balance": "61% male",
                "nationalities": 145,
                "conditions": "noisy and unconstrained",
                "multilingual": true
            }
        },
        {
            "id": "20250319042813D2",
            "name": "VoxCeleb1",
            "type": "Dataset",
            "attributes": {
                "usage": "testing dataset"
            }
        },
        {
            "id": "20250319042813D3",
            "name": "SITW",
            "type": "Dataset",
            "attributes": {
                "purpose": "speaker recognition benchmark"
            }
        },
        {
            "id": "20250319042813D4",
            "name": "VGGFace2",
            "type": "Dataset",
            "attributes": {
                "application": "face recognition"
            }
        },
        {
            "id": "20250319042813D5",
            "name": "MS-Celeb-1M",
            "type": "Dataset",
            "attributes": {
                "purpose": "large-scale face recognition"
            }
        },
        {
            "id": "20250319042813D6",
            "name": "NFI-FRITS",
            "type": "Dataset",
            "attributes": {
                "domain": "forensic speaker recognition"
            }
        },
        {
            "id": "20250319042813D7",
            "name": "POLYCOST",
            "type": "Dataset",
            "attributes": {
                "source": "telephone-speech"
            }
        },
        {
            "id": "20250319042813D8",
            "name": "DARPA speech recognition dataset",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319042813R1",
            "name": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319042813T1",
            "name": "speaker identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T2",
            "name": "speaker verification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T3",
            "name": "clustering",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T4",
            "name": "diarisation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T5",
            "name": "visual speech synthesis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T6",
            "name": "speech separation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T7",
            "name": "cross-modal transfer",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T8",
            "name": "face recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319042813T9",
            "name": "training speaker embedding systems",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109P1",
            "name": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Joakim Nivre",
                    "Marie-Catherine de Marneffe",
                    "Filip Ginter",
                    "Yoav Goldberg",
                    "Jan Hajič",
                    "Christopher D. Manning",
                    "Ryan McDonald",
                    "Slav Petrov",
                    "Sampo Pyysalo",
                    "Natalia Silveira",
                    "Reut Tsarfaty",
                    "Daniel Zeman"
                ],
                "institutions": [
                    "The Ohio State University",
                    "Uppsala University",
                    "Bar-Ilan University",
                    "Google Inc.",
                    "Charles University in Prague",
                    "University of Cambridge",
                    "University of Turku",
                    "Stanford University",
                    "The Open University of Israel"
                ]
            }
        },
        {
            "id": "20250319043109D1",
            "name": "Universal Dependencies (UD)",
            "type": "Dataset",
            "attributes": {
                "languages": 33,
                "annotation layers": "morphological, syntactic",
                "format": "CoNLL-U",
                "treebanks": 37,
                "releases": [
                    "v1.0 October 2014",
                    "v1.2 November 2015"
                ]
            }
        },
        {
            "id": "20250319043109D2",
            "name": "Google Universal Dependency Treebank (UDT)",
            "type": "Dataset",
            "attributes": {
                "languages": "6 initially, 11 in 2014",
                "annotation": "Stanford dependencies, Google POS tags"
            }
        },
        {
            "id": "20250319043109D3",
            "name": "HamleDT",
            "type": "Dataset",
            "attributes": {
                "languages": 30,
                "annotation": "automatically harmonized treebanks",
                "version": "3.0 uses UD standard"
            }
        },
        {
            "id": "20250319043109D4",
            "name": "CoNLL-X shared task data",
            "type": "Dataset",
            "attributes": {
                "purpose": "dependency parsing shared task"
            }
        },
        {
            "id": "20250319043109D5",
            "name": "Stanford Dependencies",
            "type": "Dataset",
            "attributes": {
                "origin": "Developed for English, adapted to multiple languages"
            }
        },
        {
            "id": "20250319043109R1",
            "name": "http://universaldependencies.org",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319043109T1",
            "name": "cross-lingual learning",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T2",
            "name": "multilingual parsing research",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T3",
            "name": "syntactic annotation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T4",
            "name": "morphological analysis",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T5",
            "name": "part-of-speech tagging",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T6",
            "name": "unsupervised part-of-speech tagging",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T7",
            "name": "delexicalized parser adaptation",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043109T8",
            "name": "dependency parsing",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043654P1",
            "name": "Common Voice: A Massively-Multilingual Speech Corpus",
            "type": "Paper",
            "attributes": {
                "authors": [
                    "Rosana Ardila",
                    "Megan Branson",
                    "Kelly Davis",
                    "Michael Henretty",
                    "Michael Kohler",
                    "Josh Meyer",
                    "Reuben Morais",
                    "Lindsay Saunders",
                    "Francis M. Tyers",
                    "Gregor Weber"
                ],
                "institutions": [
                    "Mozilla",
                    "Indiana University",
                    "Artie, Inc."
                ]
            }
        },
        {
            "id": "20250319043654D1",
            "name": "Common Voice",
            "type": "Dataset",
            "attributes": {
                "size": "2,500 hours",
                "languages": "29 released, 38 collecting",
                "participants": "50,000+",
                "format": "MPEG-3, 48kHz",
                "validation": "crowdsourced voting",
                "license": "CC0"
            }
        },
        {
            "id": "20250319043654D2",
            "name": "VoxForge",
            "type": "Dataset",
            "attributes": {
                "languages": 17,
                "license": "GNU General Public License",
                "validation": "none"
            }
        },
        {
            "id": "20250319043654D3",
            "name": "Babel",
            "type": "Dataset",
            "attributes": {
                "languages": 22,
                "license": "not open"
            }
        },
        {
            "id": "20250319043654D4",
            "name": "MAILABS",
            "type": "Dataset",
            "attributes": {
                "languages": 9,
                "license": "modified BSD 3-Clause License"
            }
        },
        {
            "id": "20250319043654R1",
            "name": "https://commonvoice.mozilla.org/en/datasets",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319043654L1",
            "name": "CC0",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319043654L2",
            "name": "GNU General Public License",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319043654L3",
            "name": "modified BSD 3-Clause License",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319043654T1",
            "name": "Automatic Speech Recognition",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043654T2",
            "name": "language identification",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043654T3",
            "name": "multilingual speech research",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043654T4",
            "name": "training speech recognition models",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043654T5",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043909P1",
            "name": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition",
            "type": "Paper",
            "attributes": {
                "author": "Pete Warden",
                "institution": "Google Brain"
            }
        },
        {
            "id": "20250319043909D1",
            "name": "Speech Commands v0.02",
            "type": "Dataset",
            "attributes": {
                "size": "105,829 utterances",
                "words": 35,
                "speakers": 2618,
                "format": "16 KHz WAV",
                "license": "Creative Commons BY 4.0"
            }
        },
        {
            "id": "20250319043909D2",
            "name": "Speech Commands v0.01",
            "type": "Dataset",
            "attributes": {
                "size": "64,727 utterances",
                "speakers": 1881,
                "license": "Creative Commons BY 4.0"
            }
        },
        {
            "id": "20250319043909D3",
            "name": "Common Voice",
            "type": "Dataset",
            "attributes": {
                "size": "500+ hours",
                "speakers": 20000,
                "license": "CC0"
            }
        },
        {
            "id": "20250319043909D4",
            "name": "TIDIGITS",
            "type": "Dataset",
            "attributes": {
                "content": "digit sequences",
                "license": "commercial license"
            }
        },
        {
            "id": "20250319043909D5",
            "name": "CHiME-5",
            "type": "Dataset",
            "attributes": {
                "size": "50 hours",
                "license": "restricted license"
            }
        },
        {
            "id": "20250319043909D6",
            "name": "UrbanSounds",
            "type": "Dataset",
            "attributes": {}
        },
        {
            "id": "20250319043909R1",
            "name": "http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319043909R2",
            "name": "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz",
            "type": "Repository",
            "attributes": {}
        },
        {
            "id": "20250319043909L1",
            "name": "Creative Commons BY 4.0",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319043909L2",
            "name": "CC0",
            "type": "License",
            "attributes": {}
        },
        {
            "id": "20250319043909T1",
            "name": "keyword spotting",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043909T2",
            "name": "training object detection algorithms",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043909T3",
            "name": "benchmarking",
            "type": "Task",
            "attributes": {}
        },
        {
            "id": "20250319043909T4",
            "name": "model evaluation",
            "type": "Task",
            "attributes": {}
        }
    ],
    "relations": [
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318214228R1",
            "tail": "https://gluebenchmark.com",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318214228P1",
            "tail": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D2",
            "tail": "CoLA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D3",
            "tail": "SST-2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D4",
            "tail": "MRPC",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D5",
            "tail": "STS-B (Semantic Textual Similarity Benchmark)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D6",
            "tail": "QQP (Quora Question Pairs)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D7",
            "tail": "MNLI (Multi-Genre Natural Language Inference Corpus)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D8",
            "tail": "QNLI (Question-answering NLI)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D9",
            "tail": "RTE (Recognizing Textual Entailment)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D10",
            "tail": "WNLI (Winograd NLI)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250318214228D12",
            "tail": "GLUE Diagnostic Dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D2",
            "head": "CoLA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T6",
            "tail": "acceptability classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D3",
            "head": "SST-2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T2",
            "tail": "sentiment analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D4",
            "head": "MRPC",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D5",
            "head": "STS-B (Semantic Textual Similarity Benchmark)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T5",
            "tail": "sentence similarity",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D6",
            "head": "QQP (Quora Question Pairs)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D7",
            "head": "MNLI (Multi-Genre Natural Language Inference Corpus)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T3",
            "tail": "textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D8",
            "head": "QNLI (Question-answering NLI)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T3",
            "tail": "textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D9",
            "head": "RTE (Recognizing Textual Entailment)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T3",
            "tail": "textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D10",
            "head": "WNLI (Winograd NLI)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T3",
            "tail": "textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D1",
            "head": "GLUE",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318214228T1",
            "tail": "natural language understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228D12",
            "head": "GLUE Diagnostic Dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318214228P1",
            "tail": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319084652R1",
            "tail": "http://nlp.stanford.edu/sentiment",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319084652P1",
            "tail": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319084652T1",
            "tail": "sentiment detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319084652T2",
            "tail": "sentiment classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319084652T3",
            "tail": "negation detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319084652D1",
            "head": "Stanford Sentiment Treebank",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319084652T4",
            "tail": "contrastive conjunction analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319084652T1",
            "head": "sentiment detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319084652T3",
            "tail": "negation detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318222007R1",
            "tail": "https://nyu.edu/projects/bowman/multinli/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250318222007L1",
            "tail": "OANC’s license",
            "tail_type": "License"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250318222007L2",
            "tail": "Creative Commons Attribution 3.0 Unported",
            "tail_type": "License"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250318222007L3",
            "tail": "Creative Commons Share-Alike 3.0 Unported",
            "tail_type": "License"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318222007P1",
            "tail": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T1",
            "tail": "natural language inference (NLI)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T2",
            "tail": "recognizing textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T3",
            "tail": "cross-genre domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T4",
            "tail": "transfer learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T5",
            "tail": "sentence understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318222007T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318223609R1",
            "tail": "github.com/hendrycks/test",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318223609P1",
            "tail": "MEASURING MASSIVE MULTITASK LANGUAGE UNDERSTANDING",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T1",
            "tail": "massive multitask language understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T5",
            "tail": "legal understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T6",
            "tail": "moral intuition prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T7",
            "tail": "history question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D1",
            "head": "Massive Multitask Test",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T8",
            "tail": "mathematics problem solving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609D5",
            "head": "ETHICS dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318223609T6",
            "tail": "moral intuition prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D1",
            "head": "Natural Questions (NQ)",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318225612R1",
            "tail": "https://ai.google.com/research/NaturalQuestions",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318225612D1",
            "head": "Natural Questions (NQ)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318225612P1",
            "tail": "Natural Questions: A Benchmark for Question Answering Research",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318225612D1",
            "head": "Natural Questions (NQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318225612T1",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D1",
            "head": "Natural Questions (NQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318225612T2",
            "tail": "machine reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D1",
            "head": "Natural Questions (NQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318225612T6",
            "tail": "supporting facts identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D3",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250318225612D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T4",
            "tail": "boolean question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318230205P1",
            "tail": "A large annotated corpus for learning natural language inference",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T1",
            "tail": "natural language inference (NLI)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T2",
            "tail": "entailment detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T3",
            "tail": "contradiction detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T4",
            "tail": "semantic parsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T5",
            "tail": "commonsense reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T6",
            "tail": "transfer learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T8",
            "tail": "machine learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205D1",
            "head": "Stanford Natural Language Inference (SNLI) corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318230205T9",
            "tail": "information retrieval",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601D1",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250318231601D2",
            "tail": "WikiText-103",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318231601D1",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318231601P1",
            "tail": "Pointer Sentinel Mixture Models",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318231601D2",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318231601P1",
            "tail": "Pointer Sentinel Mixture Models",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318231601D3",
            "head": "Penn Treebank (PTB)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318231601T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601D1",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318231601T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601D2",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318231601T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601D1",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318231601R1",
            "tail": "WikiText dataset site",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318231601D2",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318231601R1",
            "tail": "WikiText dataset site",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318233629D1",
            "head": "MS MARCO",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318233629P1",
            "tail": "MS MARCO: A Human Generated MAchine Reading COmprehension Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318233629D1",
            "head": "MS MARCO",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318233629T1",
            "tail": "answerability prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318233629D1",
            "head": "MS MARCO",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318233629T2",
            "tail": "natural language answer generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318233629D1",
            "head": "MS MARCO",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318233629T3",
            "tail": "passage ranking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D1",
            "head": "HumanEval",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318235155R1",
            "tail": "https://www.github.com/openai/human-eval",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318235155D1",
            "head": "HumanEval",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318235155P1",
            "tail": "Evaluating Large Language Models Trained on Code",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318235155D1",
            "head": "HumanEval",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T1",
            "tail": "program synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D1",
            "head": "HumanEval",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T2",
            "tail": "code generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D1",
            "head": "HumanEval",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T3",
            "tail": "functional correctness evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D2",
            "head": "APPS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T3",
            "tail": "functional correctness evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D3",
            "head": "The Pile",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T2",
            "tail": "code generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155D5",
            "head": "CodeXGLUE",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235155T6",
            "tail": "code understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250318235921R1",
            "tail": "https://github.com/hendrycks/apps",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250318235921L1",
            "tail": "MIT License",
            "tail_type": "License"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318235921P1",
            "tail": "Measuring Mathematical Problem Solving With the MATH Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T1",
            "tail": "mathematical problem solving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T2",
            "tail": "theorem proving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T3",
            "tail": "answer generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T5",
            "tail": "automatic answer assessment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T6",
            "tail": "step-by-step solution generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D1",
            "head": "MATH",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D2",
            "head": "AMPS (Auxiliary Mathematics Problems and Solutions)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250318235921P1",
            "tail": "Measuring Mathematical Problem Solving With the MATH Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318235921D2",
            "head": "AMPS (Auxiliary Mathematics Problems and Solutions)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T4",
            "tail": "pretraining models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921D3",
            "head": "DeepMind Mathematics Dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250318235921T8",
            "tail": "plug-and-chug calculations",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318235921T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T6",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T6",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318235921T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205T7",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318235921T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T7",
            "head": "question answering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318223609T4",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T7",
            "head": "question answering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612T1",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T4",
            "head": "question answering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612T1",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T1",
            "head": "natural language inference (NLI)",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205T1",
            "tail": "natural language inference (NLI)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T2",
            "tail": "zero-shot learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T3",
            "tail": "few-shot learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T4",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T5",
            "tail": "legal understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T6",
            "tail": "moral intuition prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T7",
            "tail": "history question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T1",
            "head": "massive multitask language understanding",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318223609T8",
            "tail": "mathematics problem solving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T2",
            "tail": "machine reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T3",
            "tail": "answer extraction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T4",
            "tail": "boolean question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T5",
            "tail": "conversational QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T6",
            "tail": "supporting facts identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T1",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318225612T7",
            "tail": "Cloze-style tasks",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T1",
            "head": "natural language inference (NLI)",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318230205T2",
            "tail": "entailment detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T1",
            "head": "natural language inference (NLI)",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318230205T3",
            "tail": "contradiction detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T2",
            "head": "sentiment analysis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319084652T1",
            "tail": "sentiment detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T2",
            "head": "sentiment analysis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319084652T2",
            "tail": "sentiment classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155T1",
            "head": "program synthesis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235155T2",
            "tail": "code generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155T1",
            "head": "program synthesis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235155T3",
            "tail": "functional correctness evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155T1",
            "head": "program synthesis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235155T4",
            "tail": "docstring generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155T1",
            "head": "program synthesis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235155T5",
            "tail": "code autocompletion",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235155T1",
            "head": "program synthesis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235155T6",
            "tail": "code understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921T1",
            "head": "mathematical problem solving",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235921T2",
            "tail": "theorem proving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921T1",
            "head": "mathematical problem solving",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235921T3",
            "tail": "answer generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921T1",
            "head": "mathematical problem solving",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235921T5",
            "tail": "automatic answer assessment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921T1",
            "head": "mathematical problem solving",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235921T6",
            "tail": "step-by-step solution generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318235921T1",
            "head": "mathematical problem solving",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318235921T8",
            "tail": "plug-and-chug calculations",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T4",
            "head": "transfer learning",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250318222007T3",
            "tail": "cross-genre domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D3",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250318225612D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318233629D2",
            "head": "SQuAD (Stanford Question Answering Dataset)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D11",
            "head": "SNLI (Stanford Natural Language Inference)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007D2",
            "tail": "Stanford NLI Corpus (SNLI)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D11",
            "head": "SNLI (Stanford Natural Language Inference)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205D1",
            "tail": "Stanford Natural Language Inference (SNLI) corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318222007D2",
            "head": "Stanford NLI Corpus (SNLI)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205D1",
            "tail": "Stanford Natural Language Inference (SNLI) corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D7",
            "head": "MNLI (Multi-Genre Natural Language Inference Corpus)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007D1",
            "tail": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D9",
            "head": "RTE (Recognizing Textual Entailment)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205D2",
            "tail": "Recognizing Textual Entailment (RTE) challenge tasks",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D10",
            "head": "DuReader",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318233629D4",
            "tail": "DuReader",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D4",
            "head": "NarrativeQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318233629D5",
            "tail": "NarrativeQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319001713R1",
            "tail": "http://nlp.cs.washington.edu/triviaqa/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319001713P1",
            "tail": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T1",
            "tail": "reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T2",
            "tail": "open domain question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T3",
            "tail": "answer sentence selection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T4",
            "tail": "answer phrase extraction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T5",
            "tail": "knowledge base question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T6",
            "tail": "IR-style question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T7",
            "tail": "machine reading",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713D1",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319001713T8",
            "tail": "training machine reading systems",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319002031P1",
            "tail": "From Image Descriptions to Visual Denotations: New Similarity Metrics for Semantic Inference over Event Descriptions",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319002031R1",
            "tail": "http://nlp.cs.illinois.edu/Denotation.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319002031L1",
            "tail": "Creative Commons",
            "tail_type": "License"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319002031D2",
            "tail": "Hodosh et al. (2013) Corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T1",
            "tail": "semantic inference",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T2",
            "tail": "approximate entailment recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T3",
            "tail": "Semantic Textual Similarity (STS)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T5",
            "tail": "image understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T6",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T7",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T8",
            "tail": "automatic object clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T9",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T11",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T12",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T13",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D1",
            "head": "Image Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T14",
            "tail": "image search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031D3",
            "head": "MSR Video Description Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002031T3",
            "tail": "Semantic Textual Similarity (STS)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319002611R1",
            "tail": "http://conceptnet.io",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319002611R2",
            "tail": "https://github.com/commonsense/conceptnet5",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319002611P1",
            "tail": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T1",
            "tail": "word relatedness evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T2",
            "tail": "solving SAT-style analogies",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T3",
            "tail": "natural language processing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T4",
            "tail": "machine learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T5",
            "tail": "semantic space construction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T6",
            "tail": "multilingual embedding propagation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T7",
            "tail": "training word embeddings",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319002611T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D3",
            "tail": "WordNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D4",
            "tail": "Open Multilingual WordNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D5",
            "tail": "DBPedia",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D6",
            "tail": "OpenCyc",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D7",
            "tail": "JMDict",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D8",
            "tail": "Wiktionary",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319002611D9",
            "tail": "Open Mind Common Sense (OMCS)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D2",
            "head": "ConceptNet 5.2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319002611D1",
            "tail": "ConceptNet 5.5",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D10",
            "head": "ConceptNet Numberbatch 16.09",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319002611R3",
            "tail": "https://github.com/commonsense/conceptnet-numberbatch",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319002611D10",
            "head": "ConceptNet Numberbatch 16.09",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319002611P1",
            "tail": "ConceptNet 5.5: An Open Multilingual Graph of General Knowledge",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319003755D1",
            "head": "HOTPOTQA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319003755P1",
            "tail": "HOTPOTQA: A Dataset for Diverse, Explainable Multi-hop Question Answering",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319003755D1",
            "head": "HOTPOTQA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319003755R1",
            "tail": "https://HotpotQA.github.io",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319003755D1",
            "head": "HOTPOTQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319003755T1",
            "tail": "multi-hop question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319003755D1",
            "head": "HOTPOTQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319003755T2",
            "tail": "explainable reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319003755D1",
            "head": "HOTPOTQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319003755T3",
            "tail": "factoid comparison questions",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319004155R1",
            "tail": "http://research.microsoft.com/research/nlp/msr_paraphrase.htm",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319004155P1",
            "tail": "Automatically Constructing a Corpus of Sentential Paraphrases",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004155T1",
            "tail": "paraphrase identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004155T2",
            "tail": "paraphrase generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004155T3",
            "tail": "training machine learning models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004155D1",
            "head": "Microsoft Research Paraphrase Corpus (MSRP)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004155T4",
            "tail": "evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004350D1",
            "head": "CoNLL-2003 English Dataset",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319004350D3",
            "tail": "Reuters Corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319004350D2",
            "head": "CoNLL-2003 German Dataset",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319004350D4",
            "tail": "ECI Multilingual Text Corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319004350D1",
            "head": "CoNLL-2003 English Dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319004350P1",
            "tail": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319004350D2",
            "head": "CoNLL-2003 German Dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319004350P1",
            "tail": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319004350T1",
            "head": "language-independent named entity recognition",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319004350P1",
            "tail": "Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319004350D1",
            "head": "CoNLL-2003 English Dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004350T1",
            "tail": "language-independent named entity recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004350D2",
            "head": "CoNLL-2003 German Dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004350T1",
            "tail": "language-independent named entity recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004913D1",
            "head": "Corpus of Linguistic Acceptability (CoLA)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319004913P1",
            "tail": "Neural Network Acceptability Judgments",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319004913D1",
            "head": "Corpus of Linguistic Acceptability (CoLA)",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319004913R1",
            "tail": "https://nyu-mll.github.io/CoLA/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319004913D1",
            "head": "Corpus of Linguistic Acceptability (CoLA)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004913T1",
            "tail": "acceptability classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004913D1",
            "head": "Corpus of Linguistic Acceptability (CoLA)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004913T2",
            "tail": "grammatical knowledge evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004913D2",
            "head": "British National Corpus (BNC)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004913T3",
            "tail": "unsupervised language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004913D2",
            "head": "British National Corpus (BNC)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319004913T7",
            "tail": "language model pretraining",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319005248P1",
            "tail": "PIQA: Reasoning about Physical Commonsense in Natural Language",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319005248R1",
            "tail": "http://yonatanbisk.com/piqa",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005248T1",
            "tail": "physical commonsense reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005248T2",
            "tail": "question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005248T3",
            "tail": "problem solving",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005248T4",
            "tail": "natural language understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005248D1",
            "head": "PIQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005248T6",
            "tail": "benchmarking language models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319005543R1",
            "tail": "visualreasoning.net",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319005543P1",
            "tail": "GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319005543D2",
            "tail": "Visual Genome",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319005543D2",
            "head": "Visual Genome",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319005543D3",
            "tail": "COCO",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319005543D2",
            "head": "Visual Genome",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319005543D4",
            "tail": "Flickr",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T1",
            "tail": "visual reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T2",
            "tail": "compositional question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T3",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T4",
            "tail": "attribute recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T5",
            "tail": "spatial reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T6",
            "tail": "logical inference",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T7",
            "tail": "comparisons",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543D1",
            "head": "GQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319005543T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319010018P1",
            "tail": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010018T1",
            "tail": "visual question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010018T2",
            "tail": "compositional reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010018T3",
            "tail": "attribute comparison",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010018T4",
            "tail": "counting",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010018D1",
            "head": "CLEVR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010018T5",
            "tail": "logical reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T4",
            "head": "paraphrase detection",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T6",
            "head": "acceptability classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319004913T1",
            "tail": "acceptability classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T7",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319001713T2",
            "tail": "open domain question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318214228T7",
            "head": "question answering",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319001713T5",
            "tail": "knowledge base question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T2",
            "head": "machine reading comprehension",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319001713T1",
            "tail": "reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T3",
            "head": "answer extraction",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319001713T4",
            "tail": "answer phrase extraction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T4",
            "head": "transfer learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319004913T4",
            "tail": "transfer learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318230205T8",
            "head": "machine learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002611T4",
            "tail": "machine learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T6",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T3",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T10",
            "head": "scene understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T12",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004350T2",
            "head": "named entity recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319004350T1",
            "tail": "language-independent named entity recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319004155T1",
            "head": "paraphrase identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713T7",
            "head": "machine reading",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319001713T8",
            "tail": "training machine reading systems",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T13",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002611T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D11",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D1",
            "tail": "TriviaQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D2",
            "head": "SQuAD",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D2",
            "tail": "SQuAD (Rajpurkar et al., 2016)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318233629D3",
            "head": "NewsQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D4",
            "tail": "NewsQA (Trischler et al., 2016)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D8",
            "head": "WikiQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D5",
            "tail": "WikiQA (Yang et al., 2015)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318233629D6",
            "head": "SearchQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D7",
            "tail": "SearchQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D2",
            "head": "SQuAD",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319003755D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D11",
            "head": "TriviaQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319003755D3",
            "tail": "TriviaQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318233629D6",
            "head": "SearchQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319003755D4",
            "tail": "SearchQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318233629D1",
            "head": "MS MARCO",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319003755D7",
            "tail": "MS MARCO",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319001713D2",
            "head": "SQuAD (Rajpurkar et al., 2016)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319003755D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002611D1",
            "head": "ConceptNet 5.5",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319002611D2",
            "tail": "ConceptNet 5.2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D3",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250318225612D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D1",
            "head": "BoolQ",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319010509R1",
            "tail": "https://goo.gl/boolq",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319010509D1",
            "head": "BoolQ",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319010509P1",
            "tail": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319010509D1",
            "head": "BoolQ",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T1",
            "tail": "yes/no question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D2",
            "head": "MultiNLI",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T3",
            "tail": "entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D3",
            "head": "SNLI",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T3",
            "tail": "entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D4",
            "head": "SQuAD 1.1",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319010509D5",
            "tail": "SQuAD 2.0",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D4",
            "head": "SQuAD 1.1",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T5",
            "tail": "extractive QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D5",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T5",
            "tail": "extractive QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D6",
            "head": "RACE",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T6",
            "tail": "multiple-choice QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D7",
            "head": "QQP",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T4",
            "tail": "paraphrasing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D8",
            "head": "MS Marco",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T1",
            "tail": "yes/no question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D9",
            "head": "QuAC",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T9",
            "tail": "conversational QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D10",
            "head": "CoQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T9",
            "tail": "conversational QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D11",
            "head": "HotPotQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010509T10",
            "tail": "multi-step reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319010919P1",
            "tail": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T1",
            "tail": "translating video to text",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T2",
            "tail": "video description generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T3",
            "tail": "video summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T4",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T5",
            "tail": "emotion recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T6",
            "tail": "video to language",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319010919T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319011523R1",
            "tail": "http://dbpedia.org/sparql",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319011523R2",
            "tail": "http://dbpedia.org/resource/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319011523L1",
            "tail": "GNU Free Documentation License",
            "tail_type": "License"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011523T1",
            "tail": "information extraction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011523T2",
            "tail": "data interlinking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011523T3",
            "tail": "SPARQL querying",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011523T4",
            "tail": "Semantic Web browsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319011523P1",
            "tail": "DBpedia: A Nucleus for a Web of Open Data",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319011523D2",
            "tail": "Geonames",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319011523D3",
            "tail": "MusicBrainz",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319011523D1",
            "head": "DBpedia",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319011523D4",
            "tail": "DBLP",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319011829R1",
            "tail": "http://data.allenai.org/OpenBookQA",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319011829P1",
            "tail": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T1",
            "tail": "open book question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T2",
            "tail": "multi-hop reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T3",
            "tail": "reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T4",
            "tail": "textual entailment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T5",
            "tail": "plausible answer detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T6",
            "tail": "information retrieval",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T7",
            "tail": "question answering over structured knowledge-bases",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T8",
            "tail": "answerability verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T9",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829D1",
            "head": "OpenBookQA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319011829T10",
            "tail": "scientific question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319012144R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319012144P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012144T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012144T3",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012144T4",
            "tail": "clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012144T5",
            "tail": "diarisation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012144D2",
            "tail": "VoxCeleb1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D4",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012144T9",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012420D2",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319012420P1",
            "tail": "Pointer Sentinel Mixture Models",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012420D3",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319012420P1",
            "tail": "Pointer Sentinel Mixture Models",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012420D1",
            "head": "Penn Treebank (PTB)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012420T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012420D2",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012420T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012420D3",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012420D2",
            "tail": "WikiText-2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012420D3",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319012420R1",
            "tail": "WikiText dataset site",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319012420D1",
            "head": "Penn Treebank (PTB)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012420T2",
            "tail": "word-level prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012630D1",
            "head": "DUC-2003",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012630T1",
            "tail": "abstractive text summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012630D2",
            "head": "DUC-2004",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012630T1",
            "tail": "abstractive text summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012630D3",
            "head": "Gigaword Corpus",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012630T1",
            "tail": "abstractive text summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012630D4",
            "head": "CNN/Daily Mail dataset (anonymized)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319012630P1",
            "tail": "Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012630D4",
            "head": "CNN/Daily Mail dataset (anonymized)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012630T1",
            "tail": "abstractive text summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012630D5",
            "head": "LCSTS (Large Scale Chinese Short Text Summarization dataset)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012630T1",
            "tail": "abstractive text summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319012945R1",
            "tail": "http://universaldependencies.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319012945P1",
            "tail": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012945T1",
            "tail": "dependency parsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012945T2",
            "tail": "part-of-speech tagging",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319012945T3",
            "tail": "cross-lingual learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319012945D5",
            "tail": "Stanford Dependencies",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012945D2",
            "tail": "Google Universal Dependency Treebank (UDT)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012945D1",
            "head": "Universal Dependencies v1.2",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319012945D4",
            "tail": "CoNLL-X",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319013228D1",
            "head": "FEVER",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319013228P1",
            "tail": "FEVER: a large-scale dataset for Fact Extraction and VERification",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319013228D1",
            "head": "FEVER",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T1",
            "tail": "Fact Extraction and Verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D1",
            "head": "FEVER",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T2",
            "tail": "claim verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D2",
            "head": "Fake News Challenge dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T3",
            "tail": "stance classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D3",
            "head": "“Liar, Liar Pants on Fire” dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T8",
            "tail": "fake news detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D4",
            "head": "Fact checking dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T2",
            "tail": "claim verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D5",
            "head": "Emergent dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T3",
            "tail": "stance classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013228D6",
            "head": "TREC Answer Validation Exercise dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013228T7",
            "tail": "answer validation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013919D1",
            "head": "MT-bench",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319013919P1",
            "tail": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319013919D2",
            "head": "Chatbot Arena",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319013919P1",
            "tail": "Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319013919D1",
            "head": "MT-bench",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319013919R1",
            "tail": "https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319013919D1",
            "head": "MT-bench",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013919T1",
            "tail": "multi-turn conversation evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013919D1",
            "head": "MT-bench",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013919T2",
            "tail": "instruction-following evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013919D2",
            "head": "Chatbot Arena",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013919T3",
            "tail": "human preference evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319013919D2",
            "head": "Chatbot Arena",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319013919T4",
            "tail": "benchmarking language models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601P1",
            "head": "Pointer Sentinel Mixture Models",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319012420P1",
            "tail": "Pointer Sentinel Mixture Models",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250318225612T4",
            "head": "boolean question answering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T1",
            "tail": "yes/no question answering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T1",
            "head": "natural language inference (NLI)",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T2",
            "tail": "natural language inference",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T3",
            "head": "answer extraction",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T5",
            "tail": "extractive QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319001713T1",
            "head": "reading comprehension",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T8",
            "tail": "reading comprehension",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612T5",
            "head": "conversational QA",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T9",
            "tail": "conversational QA",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318231601T1",
            "head": "language modeling",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319012420T1",
            "tail": "language modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945T5",
            "head": "syntactic analysis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319012945T1",
            "tail": "dependency parsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319013919T4",
            "tail": "benchmarking language models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319011829T2",
            "head": "multi-hop reasoning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509T10",
            "tail": "multi-step reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T1",
            "head": "speaker recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319012144T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T1",
            "head": "speaker recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319012144T3",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010509D2",
            "head": "MultiNLI",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007D1",
            "tail": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D3",
            "head": "SNLI",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007D2",
            "tail": "Stanford NLI Corpus (SNLI)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D5",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612D3",
            "tail": "SQuAD 2.0",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D8",
            "head": "MS Marco",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318233629D1",
            "tail": "MS MARCO",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D7",
            "head": "QQP",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228D6",
            "tail": "QQP (Quora Question Pairs)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D6",
            "head": "RACE",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318233629D7",
            "tail": "RACE",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D9",
            "head": "QuAC",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612D6",
            "tail": "QuAC",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D10",
            "head": "CoQA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318225612D7",
            "tail": "CoQA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012420D1",
            "head": "Penn Treebank (PTB)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318231601D3",
            "tail": "Penn Treebank (PTB)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012420D2",
            "head": "WikiText-2",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318231601D1",
            "tail": "WikiText-2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012420D3",
            "head": "WikiText-103",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318231601D2",
            "tail": "WikiText-103",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010509D5",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319010509D4",
            "tail": "SQuAD 1.1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319010919D1",
            "head": "MSR-VTT-10K",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319010919D7",
            "tail": "MSVD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012144D2",
            "tail": "VoxCeleb1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012630D2",
            "head": "DUC-2004",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012630D1",
            "tail": "DUC-2003",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318231601R1",
            "head": "WikiText dataset site",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319012420R1",
            "tail": "WikiText dataset site",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319014613R1",
            "tail": "http://www.image-net.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319014613P1",
            "tail": "ImageNet: A Large-Scale Hierarchical Image Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T1",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T2",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T3",
            "tail": "automatic object clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T4",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T5",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T6",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T7",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T9",
            "tail": "image search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014613T10",
            "tail": "image understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319014853P1",
            "tail": "Microsoft COCO: Common Objects in Context",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T1",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T2",
            "tail": "semantic scene labeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T3",
            "tail": "instance segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T4",
            "tail": "bounding box detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T5",
            "tail": "contextual reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T6",
            "tail": "precise 2D localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D1",
            "head": "Microsoft COCO (MS COCO)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T8",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D3",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T7",
            "tail": "object classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D2",
            "head": "PASCAL VOC 2012",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319014853T1",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319015200R1",
            "tail": "www.cityscapes-dataset.net",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319015200P1",
            "tail": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T1",
            "tail": "semantic urban scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T2",
            "tail": "pixel-level semantic labeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T3",
            "tail": "instance-level semantic labeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T4",
            "tail": "3D scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T5",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015200D1",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015200T7",
            "tail": "cross-dataset evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319015448R1",
            "tail": "www.cvlibs.net/datasets/kitti",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319015448P1",
            "tail": "Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T1",
            "tail": "stereo matching",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T2",
            "tail": "optical flow estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T3",
            "tail": "visual odometry/SLAM",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T4",
            "tail": "3D object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T5",
            "tail": "3D orientation estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T6",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015448D1",
            "head": "KITTI Vision Benchmark Suite",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015448T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D3",
            "head": "CelebA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319015825P1",
            "tail": "Deep Learning Face Attributes in the Wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015825D4",
            "head": "LFWA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319015825P1",
            "tail": "Deep Learning Face Attributes in the Wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015825D5",
            "head": "LFWA+",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319015825P1",
            "tail": "Deep Learning Face Attributes in the Wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015825D3",
            "head": "CelebA",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319015825D1",
            "tail": "CelebFaces",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319015825D4",
            "head": "LFWA",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319015825D2",
            "tail": "LFW (Labeled Faces in the Wild)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319015825D5",
            "head": "LFWA+",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319015825D4",
            "tail": "LFWA",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319015825D6",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T5",
            "tail": "face localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D6",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T12",
            "tail": "object classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D1",
            "head": "CelebFaces",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T7",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D2",
            "head": "LFW (Labeled Faces in the Wild)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T4",
            "tail": "attribute prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D8",
            "head": "SUN database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T5",
            "tail": "face localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D3",
            "head": "CelebA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T4",
            "tail": "attribute prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D4",
            "head": "LFWA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T4",
            "tail": "attribute prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825D5",
            "head": "LFWA+",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319015825T4",
            "tail": "attribute prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020328D1",
            "head": "Fashion-MNIST",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319020328R1",
            "tail": "https://github.com/zalandoresearch/fashion-mnist",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319020328D1",
            "head": "Fashion-MNIST",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020328P1",
            "tail": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020328D1",
            "head": "Fashion-MNIST",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020328T1",
            "tail": "benchmarking machine learning algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020328D1",
            "head": "Fashion-MNIST",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020328T2",
            "tail": "machine learning classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020328D2",
            "head": "MNIST",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020328T3",
            "tail": "machine learning prototyping",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020518P1",
            "tail": "nuScenes: A multimodal dataset for autonomous driving",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319020518R1",
            "tail": "http://www.nuscenes.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319020518L1",
            "tail": "CC BY-NC-SA 4.0",
            "tail_type": "License"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T1",
            "tail": "3D object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T2",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T3",
            "tail": "behavior modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T4",
            "tail": "pedestrian localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T5",
            "tail": "moving pointcloud prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T6",
            "tail": "sensor fusion",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T7",
            "tail": "trajectory prediction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T8",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T9",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T10",
            "tail": "instance segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T11",
            "tail": "depth estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020518D1",
            "head": "nuScenes",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020518T12",
            "tail": "panoptic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319020902R1",
            "tail": "http://www.shapenet.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020902P1",
            "tail": "ShapeNet: An Information-Rich 3D Model Repository",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020902D2",
            "head": "ShapeNetCore",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319020902D1",
            "tail": "ShapeNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319020902D3",
            "head": "ShapeNetSem",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319020902D1",
            "tail": "ShapeNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319020902D7",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020902P2",
            "tail": "ImageNet: A large-scale hierarchical image database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020902D4",
            "head": "Princeton Shape Benchmark",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020902P3",
            "tail": "Princeton Shape Benchmark",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020902D8",
            "head": "LabelMe",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319020902P4",
            "tail": "Building a database of 3D scenes from user annotations",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T1",
            "tail": "segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T2",
            "tail": "alignment",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T3",
            "tail": "correspondence",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T4",
            "tail": "shape retrieval",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T5",
            "tail": "shape classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T6",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T7",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T8",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020902D1",
            "head": "ShapeNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319020902T10",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319021337R1",
            "tail": "http://www.scan-net.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319021337P1",
            "tail": "ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021337T1",
            "tail": "3D object classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021337T2",
            "tail": "semantic voxel labeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021337T3",
            "tail": "CAD model retrieval",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021337D1",
            "head": "ScanNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021337T4",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319021525R1",
            "tail": "https://github.com/NVlabs/ffhq-dataset",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319021525P1",
            "tail": "A Style-Based Generator Architecture for Generative Adversarial Networks",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T1",
            "tail": "image synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T2",
            "tail": "latent space interpolation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T3",
            "tail": "disentanglement of latent factors",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T4",
            "tail": "style transfer",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T5",
            "tail": "generative model training",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021525D1",
            "head": "Flickr-Faces-HQ (FFHQ)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021525T6",
            "tail": "image quality evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T1",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T6",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T2",
            "head": "image classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T7",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T3",
            "head": "automatic object clustering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T8",
            "tail": "automatic object clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T4",
            "head": "object localization",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T9",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T5",
            "head": "scene understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T5",
            "head": "scene understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T6",
            "head": "part models learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T11",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T7",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T12",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T7",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318223609T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318235921T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T13",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010919T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319011829T9",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319012144T10",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319013919T4",
            "tail": "benchmarking language models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T9",
            "head": "image search",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T14",
            "tail": "image search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014613T10",
            "head": "image understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T5",
            "tail": "image understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T1",
            "head": "object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319014853T3",
            "tail": "instance segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T1",
            "head": "object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319014853T4",
            "tail": "bounding box detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T1",
            "head": "object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319014853T6",
            "tail": "precise 2D localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T1",
            "head": "object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319014853T7",
            "tail": "object classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319015825T1",
            "tail": "face verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319015825T2",
            "tail": "face identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319015825T5",
            "tail": "face localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319015825T8",
            "tail": "attribute recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318225612D2",
            "head": "SQuAD",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319001713D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318225612D3",
            "head": "SQuAD 2.0",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250318225612D2",
            "tail": "SQuAD",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014613D4",
            "head": "LabelMe",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014853D9",
            "tail": "LabelMe",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509D2",
            "tail": "MultiNLI",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D2",
            "head": "CoLA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319004913D1",
            "tail": "Corpus of Linguistic Acceptability (CoLA)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D9",
            "head": "RTE (Recognizing Textual Entailment)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250318230205D2",
            "tail": "Recognizing Textual Entailment (RTE) challenge tasks",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319012144D2",
            "tail": "VoxCeleb1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319021738R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/flowers/index.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319021738P1",
            "tail": "Automated flower classification over a large number of classes",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021738T1",
            "tail": "flower classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021738T2",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021738T3",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738D1",
            "head": "103 class flower dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021738T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738D2",
            "head": "17 class flower dataset",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319021738R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/flowers/index.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319021948P1",
            "tail": "Places: A 10 Million Image Database for Scene Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T1",
            "tail": "scene recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T2",
            "tail": "scene classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T3",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T4",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T5",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T6",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T7",
            "tail": "visual recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T8",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T9",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948D1",
            "head": "Places Database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319021948T10",
            "tail": "transfer learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022405D1",
            "head": "Office-Home",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319022405R1",
            "tail": "https://hemanthdv.github.io/officehome-dataset/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319022405D1",
            "head": "Office-Home",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319022405P1",
            "tail": "Deep Hashing Network for Unsupervised Domain Adaptation",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319022405D1",
            "head": "Office-Home",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022405T1",
            "tail": "unsupervised domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022405D1",
            "head": "Office-Home",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022405T2",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022405D4",
            "head": "ImageNet 2012",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022405T4",
            "tail": "feature learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022405D2",
            "head": "Office",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319022405D3",
            "tail": "Office-Caltech",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319022617D1",
            "head": "CELEBA-HQ",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319022617P1",
            "tail": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319022617D1",
            "head": "CELEBA-HQ",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319022617R1",
            "tail": "https://github.com/tkarras/progressive_growing_of_gans",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319022617D2",
            "head": "CELEBA",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319022617D1",
            "tail": "CELEBA-HQ",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319022617D1",
            "head": "CELEBA-HQ",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022617T1",
            "tail": "high-resolution image generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022617D1",
            "head": "CELEBA-HQ",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022617T2",
            "tail": "training generative adversarial networks",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022617D3",
            "head": "LSUN BEDROOM",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022617T2",
            "tail": "training generative adversarial networks",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022617D4",
            "head": "CIFAR10",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022617T3",
            "tail": "evaluating GAN results",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319022946R1",
            "tail": "http://www.liangzheng.com.cn",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319022946P1",
            "tail": "Scalable Person Re-identification: A Benchmark",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T1",
            "tail": "person re-identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T2",
            "tail": "image search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T3",
            "tail": "metric learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T4",
            "tail": "multiple query techniques",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T5",
            "tail": "search reranking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946D1",
            "head": "Market-1501",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319022946T6",
            "tail": "large-scale data analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319023144P1",
            "tail": "LSUN: Construction of a Large-Scale Image Dataset using Deep Learning with Humans in the Loop",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T1",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T2",
            "tail": "visual recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T3",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T5",
            "tail": "unsupervised image analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144D1",
            "head": "LSUN",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023144T6",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023346D1",
            "head": "Image Description Dataset",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319023346R1",
            "tail": "http://nlp.cs.illinois.edu/Denotation.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319023346D1",
            "head": "Image Description Dataset",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319023346L1",
            "tail": "Creative Commons license",
            "tail_type": "License"
        },
        {
            "head_id": "20250319023346D1",
            "head": "Image Description Dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023346T1",
            "tail": "semantic textual similarity",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023346D1",
            "head": "Image Description Dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023346T2",
            "tail": "approximate entailment recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023346D1",
            "head": "Image Description Dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319023346P1",
            "tail": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023346T1",
            "head": "semantic textual similarity",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319023346P1",
            "tail": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023346T2",
            "head": "approximate entailment recognition",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319023346P1",
            "tail": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319023610P1",
            "tail": "Describing Textures in the Wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T1",
            "tail": "texture description",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T2",
            "tail": "material recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T3",
            "tail": "semantic search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T4",
            "tail": "learning from textual descriptions",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T5",
            "tail": "image understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T6",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T7",
            "tail": "texture classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610D1",
            "head": "Describable Textures Dataset (DTD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023610T9",
            "tail": "attribute-based clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319023915R1",
            "tail": "http://www.vision.ee.ethz.ch/datasets/food-101/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319023915P1",
            "tail": "Food-101 – Mining Discriminative Components with Random Forests",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T1",
            "tail": "food recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T2",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T4",
            "tail": "component-based classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D1",
            "head": "Food-101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D3",
            "head": "MIT-Indoor",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T5",
            "tail": "scene classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D3",
            "head": "MIT-Indoor",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D4",
            "head": "Pittsburgh food dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T1",
            "tail": "food recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915D2",
            "head": "PFID",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319023915T1",
            "tail": "food recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401D1",
            "head": "BMW-10",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319024401P1",
            "tail": "3D Object Representations for Fine-Grained Categorization",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319024401D2",
            "head": "car-197",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319024401P1",
            "tail": "3D Object Representations for Fine-Grained Categorization",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319024401D1",
            "head": "BMW-10",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024401T1",
            "tail": "fine-grained categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401D2",
            "head": "car-197",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024401T1",
            "tail": "fine-grained categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401D2",
            "head": "car-197",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024401T2",
            "tail": "3D reconstruction",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401D3",
            "head": "3D Object Classes dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024401T3",
            "tail": "ultra-wide baseline matching",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401D1",
            "head": "BMW-10",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319024401R1",
            "tail": "Amazon Mechanical Turk (AMT)",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319024401D2",
            "head": "car-197",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319024401R1",
            "tail": "Amazon Mechanical Turk (AMT)",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319021738T2",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T3",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738T3",
            "head": "image classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T2",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738T4",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T6",
            "head": "scene understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T10",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T3",
            "head": "object detection",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014853T1",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T5",
            "head": "semantic segmentation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319020518T9",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T10",
            "head": "transfer learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318222007T4",
            "tail": "transfer learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T8",
            "head": "object localization",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T4",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319022946T2",
            "head": "image search",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T9",
            "tail": "image search",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023144T3",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319005543T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023346T3",
            "head": "paraphrase detection",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T4",
            "tail": "paraphrase detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023346T4",
            "head": "semantic inference",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T1",
            "tail": "semantic inference",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023610T5",
            "head": "image understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319002031T10",
            "tail": "image understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T1",
            "head": "scene recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948T2",
            "tail": "scene classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738T3",
            "head": "image classification",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319021738T1",
            "tail": "flower classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T7",
            "head": "visual recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319021948T4",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T3",
            "head": "object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319021948T8",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021738T3",
            "head": "image classification",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319023915T1",
            "tail": "food recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853D5",
            "head": "Caltech 101",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948D13",
            "tail": "Caltech-101",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014853D6",
            "head": "Caltech 256",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948D14",
            "tail": "Caltech-256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319015825D8",
            "head": "SUN database",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948D2",
            "tail": "SUN database",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021525D2",
            "head": "CELEBA-HQ",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319022617D1",
            "tail": "CELEBA-HQ",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021525D3",
            "head": "LSUN BEDROOM",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319022617D3",
            "tail": "LSUN BEDROOM",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318222007D2",
            "head": "Stanford NLI Corpus (SNLI)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509D3",
            "tail": "SNLI",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318222007D1",
            "head": "Multi-Genre Natural Language Inference (MultiNLI) corpus",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509D2",
            "tail": "MultiNLI",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D6",
            "head": "QQP (Quora Question Pairs)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319010509D7",
            "tail": "QQP",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D2",
            "head": "CoLA",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319004913D1",
            "tail": "Corpus of Linguistic Acceptability (CoLA)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318214228D4",
            "head": "MRPC",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319004155D1",
            "tail": "Microsoft Research Paraphrase Corpus (MSRP)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319002031R1",
            "head": "http://nlp.cs.illinois.edu/Denotation.html",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319023346R1",
            "tail": "http://nlp.cs.illinois.edu/Denotation.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319024604D1",
            "head": "DomainNet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319024604R1",
            "tail": "http://ai.bu.edu/M3SDA/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319024604D1",
            "head": "DomainNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319024604P1",
            "tail": "Moment Matching for Multi-Source Domain Adaptation",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319024604D1",
            "head": "DomainNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024604T1",
            "tail": "multi-source domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024604D1",
            "head": "DomainNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024604T5",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024604D2",
            "head": "Office",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024604T2",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024604D3",
            "head": "Office-Caltech10",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024604T2",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D1",
            "head": "segmentation database",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319024745P1",
            "tail": "A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Measuring Ecological Statistics",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319024745D1",
            "head": "segmentation database",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319024745D2",
            "tail": "Corel image database",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319024745D1",
            "head": "segmentation database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T1",
            "tail": "evaluating segmentation algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D1",
            "head": "segmentation database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T2",
            "tail": "measuring probability distributions associated with Gestalt grouping factors",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D1",
            "head": "segmentation database",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T3",
            "tail": "measuring statistics of image region properties",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D3",
            "head": "MNIST handwritten digit dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T4",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D4",
            "head": "FERET face dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T4",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024745D5",
            "head": "Sowerby image dataset",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319024745T1",
            "tail": "evaluating segmentation algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319025051R1",
            "tail": "http://deepmind.com/kinetics",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025051P1",
            "tail": "The Kinetics Human Action Video Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025051T1",
            "tail": "human action classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025051T3",
            "tail": "multi-modal analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025051T7",
            "tail": "video modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025051T8",
            "tail": "temporal aggregation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025051T11",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051D2",
            "head": "HMDB-51",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025051P2",
            "tail": "HMDB: a large video database for human motion recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025051D3",
            "head": "UCF-101",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025051P3",
            "tail": "UCF101: A dataset of 101 human actions classes from videos in the wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025051D5",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025051P4",
            "tail": "ImageNet: A Large-Scale Hierarchical Image Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D1",
            "head": "amazon",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025545P1",
            "tail": "Adapting Visual Category Models to New Domains",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D2",
            "head": "dslr",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025545P1",
            "tail": "Adapting Visual Category Models to New Domains",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D3",
            "head": "webcam",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025545P1",
            "tail": "Adapting Visual Category Models to New Domains",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D4",
            "head": "amazonINS",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025545P1",
            "tail": "Adapting Visual Category Models to New Domains",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D5",
            "head": "dslrINS",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025545P1",
            "tail": "Adapting Visual Category Models to New Domains",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025545D1",
            "head": "amazon",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D1",
            "head": "amazon",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T2",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D1",
            "head": "amazon",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T3",
            "tail": "k-nearest neighbor classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D1",
            "head": "amazon",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T4",
            "tail": "metric learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D2",
            "head": "dslr",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D2",
            "head": "dslr",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T2",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D2",
            "head": "dslr",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T3",
            "tail": "k-nearest neighbor classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D2",
            "head": "dslr",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T4",
            "tail": "metric learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D3",
            "head": "webcam",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D3",
            "head": "webcam",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T2",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D3",
            "head": "webcam",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T3",
            "tail": "k-nearest neighbor classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D3",
            "head": "webcam",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T4",
            "tail": "metric learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D4",
            "head": "amazonINS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D4",
            "head": "amazonINS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T5",
            "tail": "instance classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D5",
            "head": "dslrINS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545D5",
            "head": "dslrINS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025545T5",
            "tail": "instance classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025924D1",
            "head": "PACS",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319025924R1",
            "tail": "http://sketchx.eecs.qmul.ac.uk/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319025924D1",
            "head": "PACS",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319025924P1",
            "tail": "Deeper, Broader and Artier Domain Generalization",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319025924D1",
            "head": "PACS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319025924T1",
            "tail": "domain generalization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025924D1",
            "head": "PACS",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319025924D2",
            "tail": "VLCS",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025924D1",
            "head": "PACS",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319025924D3",
            "tail": "OfficeCaltech",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025924D2",
            "head": "VLCS",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319025924D4",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025924D3",
            "head": "OfficeCaltech",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319025924D4",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025924D5",
            "head": "Sketchy",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319025924D6",
            "tail": "TU-Berlin",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025924T1",
            "head": "domain generalization",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319025924T2",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025924T5",
            "head": "non-photorealistic image analysis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319025924T3",
            "tail": "instance-level matching",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025924T5",
            "head": "non-photorealistic image analysis",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319025924T4",
            "tail": "transferring object recognizers",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030126D1",
            "head": "EuroSAT",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319030126R1",
            "tail": "https://github.com/phelber/eurosat",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319030126D1",
            "head": "EuroSAT",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319030126P1",
            "tail": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319030126D1",
            "head": "EuroSAT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030126T1",
            "tail": "land use and land cover classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030126D1",
            "head": "EuroSAT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030126T2",
            "tail": "detecting land use and land cover changes",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030126D1",
            "head": "EuroSAT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030126T3",
            "tail": "improving geographical maps",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D1",
            "head": "DIV2K",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319030328R1",
            "tail": "https://data.vision.ee.ethz.ch/cvl/DIV2K/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319030328D1",
            "head": "DIV2K",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319030328P1",
            "tail": "NTIRE 2017 Challenge on Single Image Super-Resolution: Dataset and Study",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319030328D1",
            "head": "DIV2K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T1",
            "tail": "single image super-resolution",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D1",
            "head": "DIV2K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D2",
            "head": "Set5",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D3",
            "head": "Set14",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D4",
            "head": "B100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D5",
            "head": "Urban100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328D6",
            "head": "Train91",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030328T1",
            "tail": "single image super-resolution",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319030744R1",
            "tail": "https://stanfordmlgroup.github.io/competitions/chexpert",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319030744P1",
            "tail": "CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T1",
            "tail": "automated chest radiograph interpretation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T2",
            "tail": "pathology detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T3",
            "tail": "medical diagnosis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T4",
            "tail": "screening",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T5",
            "tail": "management of diseases",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T6",
            "tail": "training convolutional neural networks",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T8",
            "tail": "uncertainty detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030744D1",
            "head": "CheXpert",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319030744T9",
            "tail": "radiology report labeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319031035R1",
            "tail": "www.inaturalist.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319031035P1",
            "tail": "The iNaturalist Species Classification and Detection Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T1",
            "tail": "species classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T2",
            "tail": "species detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T3",
            "tail": "fine-grained image categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T4",
            "tail": "biodiversity monitoring",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T5",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D1",
            "head": "iNat2017",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T6",
            "tail": "low-shot learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031035D2",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031035T3",
            "tail": "fine-grained image categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D1",
            "head": "IMAGENET-C",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319031406P1",
            "tail": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319031406D2",
            "head": "IMAGENET-P",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319031406P1",
            "tail": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319031406D1",
            "head": "IMAGENET-C",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319031406R1",
            "tail": "https://github.com/hendrycks/robustness",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319031406D1",
            "head": "IMAGENET-C",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T1",
            "tail": "corruption robustness",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D1",
            "head": "IMAGENET-C",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D2",
            "head": "IMAGENET-P",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T2",
            "tail": "perturbation robustness",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D2",
            "head": "IMAGENET-P",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D1",
            "head": "IMAGENET-C",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319031406D3",
            "tail": "ImageNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319031406D2",
            "head": "IMAGENET-P",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319031406D3",
            "tail": "ImageNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319031406D7",
            "head": "ImageNet-22K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T3",
            "tail": "subtype robustness",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D3",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T6",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406D3",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031406T7",
            "tail": "image classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545T1",
            "head": "domain adaptation",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319022405T1",
            "tail": "unsupervised domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024604T3",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T1",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545T5",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T1",
            "head": "human action classification",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319025051T4",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545T4",
            "head": "metric learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319022946T3",
            "tail": "metric learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024604T1",
            "head": "multi-source domain adaptation",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025545T3",
            "head": "k-nearest neighbor classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319020328T2",
            "tail": "machine learning classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031406T6",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T1",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319030328T4",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025924T2",
            "head": "domain adaptation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025545T1",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319020328D2",
            "head": "MNIST",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319024745D3",
            "tail": "MNIST handwritten digit dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014853D7",
            "head": "CIFAR-10",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319022617D4",
            "tail": "CIFAR10",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014853D2",
            "head": "PASCAL VOC 2012",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025051D7",
            "tail": "PASCAL VOC",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021948D13",
            "head": "Caltech-101",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021738D4",
            "tail": "Caltech-101",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021948D14",
            "head": "Caltech-256",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025545D4",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021948D14",
            "head": "Caltech-256",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025924D4",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319021948D4",
            "head": "COCO dataset",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025051D6",
            "tail": "MS COCO",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025051D5",
            "tail": "ImageNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319014613D1",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319031406D3",
            "tail": "ImageNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025545D4",
            "head": "Caltech256",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319025924D4",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025051D5",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319031406D3",
            "tail": "ImageNet",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250318231601R1",
            "head": "WikiText dataset site",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319012420R1",
            "tail": "WikiText dataset site",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319002031R1",
            "head": "http://nlp.cs.illinois.edu/Denotation.html",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319023346R1",
            "tail": "http://nlp.cs.illinois.edu/Denotation.html",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319031816D1",
            "head": "Urban 100",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319031816P1",
            "tail": "Single Image Super-resolution from Transformed Self-Exemplars",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319031816D1",
            "head": "Urban 100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031816T1",
            "tail": "single image super-resolution",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031816D2",
            "head": "BSD 100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319031816T1",
            "tail": "single image super-resolution",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319031816D3",
            "head": "Berkeley Segmentation Dataset",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319031816D2",
            "tail": "BSD 100",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319032136R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032136P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T1",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T2",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T3",
            "tail": "speaker diarisation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T4",
            "tail": "speaker clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T5",
            "tail": "visual speech synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T6",
            "tail": "speech separation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T7",
            "tail": "cross-modal transfer",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032136T8",
            "tail": "face recognition training",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136D2",
            "head": "VoxCeleb1",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032136P2",
            "tail": "VoxCeleb: a large-scale speaker identification dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136D3",
            "head": "SITW (Speakers in the Wild)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032136P3",
            "tail": "The speakers in the wild (SITW) speaker recognition database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136D4",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032136P4",
            "tail": "VGGFace2: a dataset for recognising faces across pose and age",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136D5",
            "head": "MS-Celeb-1M",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032136P5",
            "tail": "MS-Celeb-1M: A dataset and benchmark for large-scale face recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319032408R1",
            "tail": "adas.cvc.uab.es/synthia",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032408P1",
            "tail": "The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T1",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T2",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T3",
            "tail": "traffic sign recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T4",
            "tail": "road segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T5",
            "tail": "pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T6",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T8",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032408T9",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319032408D2",
            "tail": "SYNTHIA-Rand",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319032408D1",
            "head": "SYNTHIA",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319032408D3",
            "tail": "SYNTHIA-Seqs",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319032706R1",
            "tail": "http://places.csail.mit.edu",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319032706P1",
            "tail": "Learning Deep Features for Scene Recognition using Places Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T1",
            "tail": "scene recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T2",
            "tail": "scene classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T3",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T4",
            "tail": "visual recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T5",
            "tail": "training CNNs",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T7",
            "tail": "cross-dataset generalization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T8",
            "tail": "visualization of CNN layers",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032706D1",
            "head": "Places",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319032706T9",
            "tail": "dataset comparison",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319033053R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319033053P1",
            "tail": "VGGFace2: A dataset for recognising faces across pose and age",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T1",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T2",
            "tail": "face verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T3",
            "tail": "face identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T4",
            "tail": "age estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T5",
            "tail": "pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T6",
            "tail": "face detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T7",
            "tail": "face clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033053T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319033447P1",
            "tail": "Fine-Grained Visual Classification of Aircraft",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319033447R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319033447L1",
            "tail": "Non-commercial Research Use",
            "tail_type": "License"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T1",
            "tail": "fine-grained visual classification (FGVC)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T2",
            "tail": "variant classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T3",
            "tail": "family classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T4",
            "tail": "manufacturer classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T5",
            "tail": "aircraft model identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T6",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447D1",
            "head": "FGVC-Aircraft",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033447T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447T1",
            "head": "fine-grained visual classification (FGVC)",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033447T2",
            "tail": "variant classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447T1",
            "head": "fine-grained visual classification (FGVC)",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033447T3",
            "tail": "family classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447T1",
            "head": "fine-grained visual classification (FGVC)",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033447T4",
            "tail": "manufacturer classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033447T2",
            "head": "variant classification",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319033447P1",
            "tail": "Fine-Grained Visual Classification of Aircraft",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033447T3",
            "head": "family classification",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319033447P1",
            "tail": "Fine-Grained Visual Classification of Aircraft",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033447T4",
            "head": "manufacturer classification",
            "head_type": "Task",
            "relation": "introduced_in",
            "tail_id": "20250319033447P1",
            "tail": "Fine-Grained Visual Classification of Aircraft",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033832D1",
            "head": "MPII Human Pose",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319033832R1",
            "tail": "human-pose.mpi-inf.mpg.de",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319033832D1",
            "head": "MPII Human Pose",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319033832P1",
            "tail": "2D Human Pose Estimation: New Benchmark and State of the Art Analysis",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319033832D1",
            "head": "MPII Human Pose",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033832T1",
            "tail": "human pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033832D1",
            "head": "MPII Human Pose",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319033832T2",
            "tail": "upper body pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033832T1",
            "head": "human pose estimation",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033832T2",
            "tail": "upper body pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033832T1",
            "head": "human pose estimation",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033832T3",
            "tail": "multiple people pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033832T1",
            "head": "human pose estimation",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319033832T4",
            "tail": "pose estimation in image sequences",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319034024R1",
            "tail": "http://rgbd.cs.princeton.edu",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319034024P1",
            "tail": "SUN RGB-D: A RGB-D Scene Understanding Benchmark Suite",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034024T1",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034024T2",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034024T3",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034024T4",
            "tail": "scene categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319034024D2",
            "tail": "NYU Depth v2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319034024D3",
            "tail": "Berkeley B3DO Dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034024D1",
            "head": "SUN RGB-D",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319034024D4",
            "tail": "SUN3D",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034224D1",
            "head": "UCF101",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319034224R1",
            "tail": "http://crcv.ucf.edu/data/UCF101.php",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319034224D1",
            "head": "UCF101",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319034224P1",
            "tail": "UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319034224D1",
            "head": "UCF101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034224T1",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034224D1",
            "head": "UCF101",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034224T2",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034224D2",
            "head": "UCF50",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319034224D1",
            "tail": "UCF101",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319034533R1",
            "tail": "http://deepmind.com/kinetics",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319034533P1",
            "tail": "The Kinetics Human Action Video Dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T1",
            "tail": "human action classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T2",
            "tail": "temporal localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T3",
            "tail": "multi-modal analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T4",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T5",
            "tail": "training action classification models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T7",
            "tail": "video modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T8",
            "tail": "spatio-temporal feature learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T9",
            "tail": "temporal aggregation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T10",
            "tail": "attention mechanisms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T11",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T12",
            "tail": "image segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T13",
            "tail": "non-visual modalities analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T14",
            "tail": "pre-training",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T15",
            "tail": "human pose estimation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034533D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034533T16",
            "tail": "object category recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319030328T1",
            "head": "single image super-resolution",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319031816T1",
            "tail": "single image super-resolution",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T2",
            "head": "speaker verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136T1",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T3",
            "head": "speaker identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136T2",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T6",
            "head": "visual speech synthesis",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136T5",
            "tail": "visual speech synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T7",
            "head": "speech separation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136T6",
            "tail": "speech separation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T8",
            "head": "cross-modal transfer",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136T7",
            "tail": "cross-modal transfer",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T5",
            "head": "semantic segmentation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032408T1",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T1",
            "head": "object detection",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032408T2",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T11",
            "head": "part models learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032408T6",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T1",
            "head": "scene recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032706T1",
            "tail": "scene recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319023915T5",
            "head": "scene classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032706T2",
            "tail": "scene classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T7",
            "head": "visual recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032706T4",
            "tail": "visual recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319033053T1",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T1",
            "head": "face verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319033053T2",
            "tail": "face verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T2",
            "head": "face identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319033053T3",
            "tail": "face identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319024401T1",
            "head": "fine-grained categorization",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319033447T1",
            "tail": "fine-grained visual classification (FGVC)",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T1",
            "head": "human action classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533T1",
            "tail": "human action classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T2",
            "head": "temporal localization",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533T2",
            "tail": "temporal localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T3",
            "head": "multi-modal analysis",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533T3",
            "tail": "multi-modal analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T7",
            "head": "video modeling",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533T7",
            "tail": "video modeling",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319025051T8",
            "head": "temporal aggregation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533T9",
            "tail": "temporal aggregation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319021948T2",
            "head": "scene classification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034024T4",
            "tail": "scene categorization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319014853T5",
            "head": "contextual reasoning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034024T5",
            "tail": "context reasoning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319032136T8",
            "tail": "face recognition training",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D1",
            "tail": "VoxCeleb2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D2",
            "head": "VoxCeleb1",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D2",
            "tail": "VoxCeleb1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D3",
            "head": "SITW (Speakers in the Wild)",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D3",
            "tail": "SITW (Speakers in the Wild)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D4",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D4",
            "tail": "VGGFace2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D5",
            "head": "MS-Celeb-1M",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D5",
            "tail": "MS-Celeb-1M",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D6",
            "head": "NFI-FRITS",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D7",
            "tail": "NFI-FRITS",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D7",
            "head": "POLYCOST",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136D6",
            "tail": "POLYCOST",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319025051D1",
            "head": "Kinetics",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533D1",
            "tail": "Kinetics",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319032136R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319025051R1",
            "head": "http://deepmind.com/kinetics",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034533R1",
            "tail": "http://deepmind.com/kinetics",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319034844R1",
            "tail": "http://serre-lab.clps.brown.edu/resources/HMDB/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319034844P1",
            "tail": "HMDB: A Large Video Database for Human Motion Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034844T1",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034844T2",
            "tail": "human motion recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034844T3",
            "tail": "video classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319034844T4",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844D9",
            "head": "UCF50",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319034844D8",
            "tail": "UCFYouTube",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319035231R1",
            "tail": "http://www.activity-net.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319035231P1",
            "tail": "ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T1",
            "tail": "human activity understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T2",
            "tail": "untrimmed video classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T3",
            "tail": "trimmed activity classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T4",
            "tail": "activity detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T5",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T6",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T7",
            "tail": "scene recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035231D1",
            "head": "ActivityNet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035231T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D1",
            "head": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319035620P1",
            "tail": "A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319035620D1",
            "head": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T1",
            "tail": "video object segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D1",
            "head": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T6",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D1",
            "head": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T7",
            "tail": "contour accuracy evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D1",
            "head": "DAVIS (Densely Annotated VIdeo Segmentation)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T8",
            "tail": "temporal coherence evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D2",
            "head": "Freiburg-Berkeley Motion Segmentation dataset (MoSeg)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T2",
            "tail": "motion segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D3",
            "head": "Berkeley Video Segmentation Dataset (BVSD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T3",
            "tail": "over-segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620D4",
            "head": "SegTrack",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035620T1",
            "tail": "video object segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035620T4",
            "head": "salient object detection",
            "head_type": "Task",
            "relation": "has_subtask",
            "tail_id": "20250319035620T5",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319035846P1",
            "tail": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T1",
            "tail": "video to text",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T2",
            "tail": "video description generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T3",
            "tail": "video understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T4",
            "tail": "sentence generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T5",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319035846D1",
            "head": "MSR-VTT",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319035846T6",
            "tail": "video summarization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319040048R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040048P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040048T1",
            "tail": "speaker recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040048T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040048T3",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040048T5",
            "tail": "visual speech synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319040048D2",
            "tail": "VoxCeleb1",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040048D4",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040048P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040048D5",
            "head": "MS-Celeb-1M",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040048P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319040311R1",
            "tail": "http://rose1.ntu.edu.sg/datasets/actionrecognition.asp",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040311P1",
            "tail": "NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T1",
            "tail": "3D human activity analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T2",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T3",
            "tail": "RGB+D human action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T4",
            "tail": "3D action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T5",
            "tail": "human activity analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T6",
            "tail": "3D object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T7",
            "tail": "3D scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T8",
            "tail": "depth-based action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T9",
            "tail": "RGB+D-based action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T10",
            "tail": "3D-based action analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T11",
            "tail": "action classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040311D1",
            "head": "NTU RGB+D",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040311T12",
            "tail": "human action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319040622R1",
            "tail": "https://bdd-data.berkeley.edu",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P1",
            "tail": "BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T1",
            "tail": "image tagging",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T2",
            "tail": "lane detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T3",
            "tail": "drivable area segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T4",
            "tail": "road object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T5",
            "tail": "semantic segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T6",
            "tail": "instance segmentation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T7",
            "tail": "multi-object detection tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T8",
            "tail": "multi-object segmentation tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T9",
            "tail": "domain adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319040622T10",
            "tail": "imitation learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040622D2",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P2",
            "tail": "The cityscapes dataset for semantic urban scene understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040622D3",
            "head": "KITTI",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P3",
            "tail": "Vision meets robotics: The kitti dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040622D4",
            "head": "Mapillary Vistas",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P4",
            "tail": "The mapillary vistas dataset for semantic understanding of street scenes",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040622D5",
            "head": "Waymo Open Dataset",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P5",
            "tail": "Scalability in perception for autonomous driving: Waymo open dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040622D6",
            "head": "ImageNet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319040622P6",
            "tail": "ImageNet: A Large-Scale Hierarchical Image Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319041030R1",
            "tail": "http://allenai.org/plato/charades/",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319041030P1",
            "tail": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T1",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T2",
            "tail": "automatic description generation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T3",
            "tail": "video captioning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T4",
            "tail": "object detection in videos",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T5",
            "tail": "modeling context",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T6",
            "tail": "learning object states",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T7",
            "tail": "human-object interactions",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041030D1",
            "head": "Charades",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041030T9",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D1",
            "head": "TB-100",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319041315R1",
            "tail": "http://pami.visual-tracking.net",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319041315D2",
            "head": "TB-50",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319041315R1",
            "tail": "http://pami.visual-tracking.net",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319041315D1",
            "head": "TB-100",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319041315P1",
            "tail": "Object Tracking Benchmark",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041315D2",
            "head": "TB-50",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319041315P1",
            "tail": "Object Tracking Benchmark",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041315D1",
            "head": "TB-100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T1",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D1",
            "head": "TB-100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T2",
            "tail": "performance evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D1",
            "head": "TB-100",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T3",
            "tail": "model update",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D3",
            "head": "VIVID",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T1",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D4",
            "head": "CAVIAR",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T1",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041315D5",
            "head": "PETS",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041315T1",
            "tail": "object tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319041706R1",
            "tail": "https://www.argoverse.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319041706R1",
            "tail": "https://www.argoverse.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319041706L1",
            "tail": "Creative Commons",
            "tail_type": "License"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319041706L1",
            "tail": "Creative Commons",
            "tail_type": "License"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319041706P1",
            "tail": "Argoverse: 3D Tracking and Forecasting with Rich Maps",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319041706P1",
            "tail": "Argoverse: 3D Tracking and Forecasting with Rich Maps",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T1",
            "tail": "3D tracking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T5",
            "tail": "3D object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T6",
            "tail": "object localization",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T2",
            "tail": "motion forecasting",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T3",
            "tail": "trajectory forecasting",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D1",
            "head": "Argoverse 3D Tracking",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319041706D2",
            "head": "Argoverse Motion Forecasting",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319041706T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319010919P1",
            "head": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319035846P1",
            "tail": "MSR-VTT: A Large Video Description Dataset for Bridging Video and Language",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012144P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040048P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040048P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319015200P1",
            "head": "The Cityscapes Dataset for Semantic Urban Scene Understanding",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040622P2",
            "tail": "The cityscapes dataset for semantic urban scene understanding",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319014613P1",
            "head": "ImageNet: A Large-Scale Hierarchical Image Database",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040622P6",
            "tail": "ImageNet: A Large-Scale Hierarchical Image Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319020902P2",
            "head": "ImageNet: A large-scale hierarchical image database",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040622P6",
            "tail": "ImageNet: A Large-Scale Hierarchical Image Database",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319034844T1",
            "head": "action recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224T1",
            "tail": "action recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T4",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250318214228T8",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T5",
            "head": "object recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T1",
            "tail": "object recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T6",
            "head": "scene understanding",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034024T1",
            "tail": "scene understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T7",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T7",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T10",
            "head": "object detection",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014853T1",
            "tail": "object detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844T11",
            "head": "part models learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613T6",
            "tail": "part models learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319034844D1",
            "head": "HMDB51",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D3",
            "tail": "HMDB51",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D2",
            "head": "KTH",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D4",
            "tail": "KTH",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D3",
            "head": "Weizmann",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D5",
            "tail": "Weizmann",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D4",
            "head": "IXMAS",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D7",
            "tail": "IXMAS",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D7",
            "head": "UCFSports",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D6",
            "tail": "UCF Sports",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D9",
            "head": "UCF50",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319035231D2",
            "tail": "UCF50",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D10",
            "head": "Olympic Sports dataset",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034224D10",
            "tail": "Olympic Sports dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D11",
            "head": "LabelMe",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319030126D8",
            "tail": "LabelMe",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D12",
            "head": "Lotus Hill dataset",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319030126D9",
            "tail": "Lotus Hill dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D13",
            "head": "Caltech101",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948D13",
            "tail": "Caltech101",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D14",
            "head": "Caltech256",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319021948D14",
            "tail": "Caltech256",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D15",
            "head": "MSRC",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319014613D8",
            "tail": "MSRC",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319034844D16",
            "head": "PASCAL",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319034024D5",
            "tail": "PASCAL",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040622D1",
            "head": "BDD100K",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319020518D9",
            "tail": "BDD100K",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040622D5",
            "head": "Waymo Open Dataset",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319020518D6",
            "tail": "Waymo Open Dataset",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040622D2",
            "head": "Cityscapes",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319015200D1",
            "tail": "Cityscapes",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040622D3",
            "head": "KITTI",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319015448D1",
            "tail": "KITTI Vision Benchmark Suite",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319040622D4",
            "head": "Mapillary Vistas",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319020518D12",
            "tail": "Mapillary Vistas",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040048R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319032136R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319040048R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319042130R1",
            "tail": "g.co/audioset",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319042130P1",
            "tail": "AUDIOSET: AN ONTOLOGY AND HUMAN-LABELED DATASET FOR AUDIO EVENTS",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T1",
            "tail": "audio event detection",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T2",
            "tail": "audio event classification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T3",
            "tail": "sound understanding",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T4",
            "tail": "acoustic scene analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T5",
            "tail": "automatic audio event recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T6",
            "tail": "training audio event recognizers",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T7",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042130D1",
            "head": "AudioSet",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042130T8",
            "tail": "audio content analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042506D1",
            "head": "VoxCeleb",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319042506R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319042506D1",
            "head": "VoxCeleb",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319042506P1",
            "tail": "VoxCeleb: a large-scale speaker identification dataset",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319042506D1",
            "head": "VoxCeleb",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042506T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042506D1",
            "head": "VoxCeleb",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042506T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042506D12",
            "head": "TIMIT",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319042506D13",
            "tail": "NTIMIT",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319042506D12",
            "head": "TIMIT",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319042506D14",
            "tail": "CTIMIT",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319042813R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319042813P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T3",
            "tail": "clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T4",
            "tail": "diarisation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T5",
            "tail": "visual speech synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T6",
            "tail": "speech separation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T7",
            "tail": "cross-modal transfer",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T8",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319042813D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319042813T9",
            "tail": "training speaker embedding systems",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319043109P1",
            "tail": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319043109R1",
            "tail": "http://universaldependencies.org",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319043109D2",
            "tail": "Google Universal Dependency Treebank (UDT)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319043109D3",
            "tail": "HamleDT",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319043109D4",
            "tail": "CoNLL-X shared task data",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "composed_of",
            "tail_id": "20250319043109D5",
            "tail": "Stanford Dependencies",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043109D2",
            "head": "Google Universal Dependency Treebank (UDT)",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319043109D1",
            "tail": "Universal Dependencies (UD)",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043109D4",
            "head": "CoNLL-X shared task data",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T6",
            "tail": "unsupervised part-of-speech tagging",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T1",
            "tail": "cross-lingual learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T2",
            "tail": "multilingual parsing research",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T3",
            "tail": "syntactic annotation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T4",
            "tail": "morphological analysis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T5",
            "tail": "part-of-speech tagging",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T7",
            "tail": "delexicalized parser adaptation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043109D1",
            "head": "Universal Dependencies (UD)",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043109T8",
            "tail": "dependency parsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319043654R1",
            "tail": "https://commonvoice.mozilla.org/en/datasets",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319043654L1",
            "tail": "CC0",
            "tail_type": "License"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319043654P1",
            "tail": "Common Voice: A Massively-Multilingual Speech Corpus",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043654T1",
            "tail": "Automatic Speech Recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043654T2",
            "tail": "language identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043654T3",
            "tail": "multilingual speech research",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043654T4",
            "tail": "training speech recognition models",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043654T5",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043654D2",
            "head": "VoxForge",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319043654L2",
            "tail": "GNU General Public License",
            "tail_type": "License"
        },
        {
            "head_id": "20250319043654D4",
            "head": "MAILABS",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319043654L3",
            "tail": "modified BSD 3-Clause License",
            "tail_type": "License"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319043909R1",
            "tail": "http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319043909D2",
            "head": "Speech Commands v0.01",
            "head_type": "Dataset",
            "relation": "stored_in",
            "tail_id": "20250319043909R2",
            "tail": "http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319043909L1",
            "tail": "Creative Commons BY 4.0",
            "tail_type": "License"
        },
        {
            "head_id": "20250319043909D3",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "licensed_under",
            "tail_id": "20250319043909L2",
            "tail": "CC0",
            "tail_type": "License"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043909T1",
            "tail": "keyword spotting",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043909T2",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043909T3",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "used_for",
            "tail_id": "20250319043909T4",
            "tail": "model evaluation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "introduced_in",
            "tail_id": "20250319043909P1",
            "tail": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319043909D2",
            "tail": "Speech Commands v0.01",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319032136P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319040048P1",
            "head": "VoxCeleb2: Deep Speaker Recognition",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813P1",
            "tail": "VoxCeleb2: Deep Speaker Recognition",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012945P1",
            "head": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "head_type": "Paper",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043109P1",
            "tail": "Universal Dependencies v1: A Multilingual Treebank Collection",
            "tail_type": "Paper"
        },
        {
            "head_id": "20250319012144T3",
            "head": "speaker identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T2",
            "head": "speaker identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136T2",
            "head": "speaker identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048T3",
            "head": "speaker identification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T1",
            "tail": "speaker identification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T2",
            "head": "speaker verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T1",
            "head": "speaker verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319032136T1",
            "head": "speaker verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319040048T2",
            "head": "speaker verification",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042506T2",
            "tail": "speaker verification",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T4",
            "head": "clustering",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T3",
            "tail": "clustering",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T5",
            "head": "diarisation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T4",
            "tail": "diarisation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T6",
            "head": "visual speech synthesis",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T5",
            "tail": "visual speech synthesis",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T7",
            "head": "speech separation",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T6",
            "tail": "speech separation",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144T8",
            "head": "cross-modal transfer",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T7",
            "tail": "cross-modal transfer",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319015825T7",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T8",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319033053T1",
            "head": "face recognition",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813T8",
            "tail": "face recognition",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945T3",
            "head": "cross-lingual learning",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043109T1",
            "tail": "cross-lingual learning",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945T2",
            "head": "part-of-speech tagging",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043109T5",
            "tail": "part-of-speech tagging",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012945T1",
            "head": "dependency parsing",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043109T8",
            "tail": "dependency parsing",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T6",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043654T5",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043654T5",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319002031T12",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043909T2",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319005543T9",
            "head": "training object detection algorithms",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043909T2",
            "tail": "training object detection algorithms",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318222007T6",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043909T3",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250318223609T8",
            "head": "benchmarking",
            "head_type": "Task",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043909T3",
            "tail": "benchmarking",
            "tail_type": "Task"
        },
        {
            "head_id": "20250319012144D1",
            "head": "VoxCeleb2",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D1",
            "tail": "VoxCeleb2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319033053D1",
            "head": "VGGFace2",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D4",
            "tail": "VGGFace2",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319033053D5",
            "head": "MS-Celeb-1M",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D5",
            "tail": "MS-Celeb-1M",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D7",
            "head": "POLYCOST",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D7",
            "tail": "POLYCOST",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D6",
            "head": "NFI-FRITS",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D6",
            "tail": "NFI-FRITS",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144D3",
            "head": "SITW",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813D3",
            "tail": "SITW",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043909D1",
            "head": "Speech Commands v0.02",
            "head_type": "Dataset",
            "relation": "has_new_version",
            "tail_id": "20250319043909D2",
            "tail": "Speech Commands v0.01",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319043654D1",
            "head": "Common Voice",
            "head_type": "Dataset",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043909D3",
            "tail": "Common Voice",
            "tail_type": "Dataset"
        },
        {
            "head_id": "20250319012144R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319032136R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319040048R1",
            "head": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319042813R1",
            "tail": "http://www.robots.ox.ac.uk/~vgg/data/voxceleb2",
            "tail_type": "Repository"
        },
        {
            "head_id": "20250319012945R1",
            "head": "http://universaldependencies.org",
            "head_type": "Repository",
            "relation": "is_equivalent_to",
            "tail_id": "20250319043109R1",
            "tail": "http://universaldependencies.org",
            "tail_type": "Repository"
        }
    ]
}